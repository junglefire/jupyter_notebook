{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# 导入matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 导入TF相关模块\n",
    "from tensorflow.keras import layers, losses, optimizers, Sequential\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. 循环神经网络\n",
    "卷积神经网络利用数据的局部相关性和权值共享的思想大大减少了网络的参数量，非常适合于图片这种具有空间(Spatial)局部相关性的数据。\n",
    "\n",
    "自然界的信号除了具有空间维度之外，还有一个时间(Temporal)维度，比如文本、语音信号、股市参数等。这类数据并不一定具有局部相关性，同时数据在时间维度上的长度也是可变的，卷积神经网络并不擅长处理此类数据。\n",
    "\n",
    "本章介绍的循环神经网络可以较好地解决此类问题。\n",
    "\n",
    "## 11.1 序列表示方法\n",
    "具有先后顺序的数据一般叫作`序列`(Sequence)，比如随时间而变化的商品价格数据。考虑某件商品A在1月到6月之间的价格变化趋势，我们记为一维向 量：$[x_1, x_2, x_3, x_4, x_5, x_6]$，它的`shape` 为$[6]$。如果要表示$b$件商品在1月到6月之间的价格变化趋势，可以记为2维张量：\n",
    "+ $\\bigg[\\big[x_1^{(1)}, x_2^{(1)}, x_3^{(1)}, x_4^{(1)}, x_5^{(1)}, x_6^{(1)}\\big], \\big[x_1^{(2)}, x_2^{(2)}, x_3^{(2)}, x_4^{(2)}, x_5^{(2)}, x_6^{(2)}\\big],\\dots,\\big[x_1^{(b)}, x_2^{(b)}, x_3^{(b)}, x_4^{(b)}, x_5^{(b)}, x_6^{(b)}\\big]\\bigg]$\n",
    "\n",
    "其中$b$表示商品的数量，张量`shape`为$[b, 6]$。\n",
    "\n",
    "这么看来，序列信号表示起来并不麻烦，只需要一个`shape`为$[b, s]$的张量即可，其中$b$为序列数量，$s$为序列长度。但是对于很多信号并不能直接用一个标量数值表示，比如每个时间戳产生长度为$n$的特征向量，则需要`shape`为$[b, s, n]$的张量才能表示。\n",
    "\n",
    "考虑更复杂的文本数据：句子。它在每个时间戳上面产生的单词是一个字符，并不是数值，不能直接用某个标量表示。神经网络不能够直接处理字符串类型的数据，需要把单词用`One-hot`编码。\n",
    "\n",
    "我们把文字编码为数值的过程叫作`Word Embedding`。`One-hot`编码是最简单的`Word Embedding`实现。但是`One-hot`编码的向量是高维度而且极其稀疏的，计算效率较低，也不利于神经网络的训练。从语义角度来讲，`One-hot`编码忽略了单词先天具有的语义相关性。举个例子，对于单词`like`、`dislike`、`Rome`、`Paris`来说，`like`和`dislike`在语义角度就强相关，它们都表示喜欢的程度；`Rome`和`Paris`同样也是强相关，他们都表示欧洲的两个地点。如果采用`One-hot`编码，得到的向量之间没有相关性，不能很好地体现原有文字的语义相关度。\n",
    "\n",
    "在自然语言处理领域，有专门的一个研究方向在探索如何学习到`单词表示向量`(Word Vector)，使得语义层面的相关性能够很好地通过`Word Vector`体现出来。一个衡量词向量之间相关度的方法就是`余弦相关度`(Cosine similarity)：\n",
    "+ $\\text{similarity}(a,b) \\triangleq \\cos(\\theta) = \\displaystyle\\frac{a\\cdot b}{\\lvert a\\rvert \\cdot \\lvert b\\rvert}$\n",
    "\n",
    "其中$a$和$b$代表了两个词向量。`图11.2`演示了单词`France`和`Italy`的相似度，以及单词`ball`和`crocodile`的相似度，可以看到$\\cos(\\theta)$较好地反映了语义相关性：\n",
    "\n",
    "<img src=\"images/11_02.png\" style=\"width:400px;\"/>\n",
    "\n",
    "### 11.1.1 Embedding层\n",
    "在神经网络中，单词的表示向量可以直接通过训练的方式得到，我们把单词的表示层叫作`Embedding`层。`Embedding`层负责把单词编码为某个词向量。\n",
    "\n",
    "`Embedding`层是可训练的，它可放置在神经网络之前，完成单词到向量的转换，得到的表示向量可以继续通过神经网络完成后续任务，并计算误差$\\mathcal{L}$，采用梯度下降算法来实现端到端(end-to-end)的训练。\n",
    "\n",
    "`TensorFlow`通过`layers.Embedding()`来定义一个`Word Embedding`层："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成10个单词的数字编码\n",
    "x = tf.range(10)\n",
    "# 打散\n",
    "x = tf.random.shuffle(x) \n",
    "# 创建共10个单词，每个单词用长度为4的向量表示的层\n",
    "net = layers.Embedding(10, 4)\n",
    "# 获取词向量\n",
    "out = net(x) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上述代码创建了10个单词的`Embedding`层，每个单词用长度为4的向量表示，可以传入数字编码为`0~9`的输入，得到这4个单词的词向量，这些词向量随机初始化的，尚未经过网络训练："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 4), dtype=float32, numpy=\n",
       "array([[ 4.0214393e-02, -2.1967782e-02,  4.7393624e-02,  1.1110533e-02],\n",
       "       [ 3.2366402e-03, -4.1588463e-02,  2.5682036e-02,  4.9591590e-02],\n",
       "       [ 3.2644879e-02, -4.7255468e-02,  4.3391395e-02,  3.0693617e-02],\n",
       "       [-2.1821786e-02,  2.1909241e-02, -4.8692118e-02, -6.8046153e-05],\n",
       "       [-3.2328416e-02,  4.5001898e-02, -1.7626155e-02,  3.7249122e-02],\n",
       "       [-1.2579404e-02,  1.7369416e-02, -4.5394577e-02,  1.6924527e-02],\n",
       "       [-4.6396293e-02,  3.6551487e-02,  5.2402169e-04,  1.7208304e-02],\n",
       "       [ 3.2751810e-02, -2.5065685e-02,  1.8287633e-02,  3.9330218e-02],\n",
       "       [-4.8573472e-02, -4.1269995e-02, -9.4405413e-03, -8.4045902e-03],\n",
       "       [-3.2385278e-02, -3.4621287e-02,  1.2773860e-02,  7.4205399e-03]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以直接查看`Embedding`层内部的查询表`table`。可以看到`net.embeddings`张量的可优化属性为`True`，即可以通过梯度下降算法优化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'embedding/embeddings:0' shape=(10, 4) dtype=float32, numpy=\n",
       "array([[ 3.2644879e-02, -4.7255468e-02,  4.3391395e-02,  3.0693617e-02],\n",
       "       [-4.8573472e-02, -4.1269995e-02, -9.4405413e-03, -8.4045902e-03],\n",
       "       [-3.2328416e-02,  4.5001898e-02, -1.7626155e-02,  3.7249122e-02],\n",
       "       [-4.6396293e-02,  3.6551487e-02,  5.2402169e-04,  1.7208304e-02],\n",
       "       [-1.2579404e-02,  1.7369416e-02, -4.5394577e-02,  1.6924527e-02],\n",
       "       [ 3.2751810e-02, -2.5065685e-02,  1.8287633e-02,  3.9330218e-02],\n",
       "       [ 4.0214393e-02, -2.1967782e-02,  4.7393624e-02,  1.1110533e-02],\n",
       "       [ 3.2366402e-03, -4.1588463e-02,  2.5682036e-02,  4.9591590e-02],\n",
       "       [-2.1821786e-02,  2.1909241e-02, -4.8692118e-02, -6.8046153e-05],\n",
       "       [-3.2385278e-02, -3.4621287e-02,  1.2773860e-02,  7.4205399e-03]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.1.2 预训练的词向量\n",
    "`Embedding`层的查询表是随机初始化的，需要从零开始训练。实际上，我们可以使用预训练的`Word Embedding`模型来得到单词的表示方法，基于预训练模型的词向量相当于迁移了整个语义空间的知识，往往能得到更好的性能。\n",
    "\n",
    "目前应用的比较广泛的预训练模型有`Word2Vec`和`GloVe`等，它们已经在海量语料库训练得到了较好的词向量表示方法。比如`GloVe`模型`GloVe.6B.50d`，词汇量为40万，每个单词使用长度为50的向量表示。\n",
    "\n",
    "那么如何使用这些预训练的词向量模型来帮助提升`NLP`任务的性能？非常简单，对于`Embedding`层，不再采用随机初始化的方式，而是利用我们已经预训练好的模型参数去初始化`Embedding`层的查询表：\n",
    "\n",
    "```python\n",
    "# 从预训练模型中加载词向量表\n",
    "embed_glove = load_embed('glove.6B.50d.txt')\n",
    "# 直接利用预训练的词向量表初始化 Embedding 层\n",
    "net.set_weights([embed_glove])\n",
    "```\n",
    "\n",
    "经过预训练的词向量模型初始化的`Embedding`层可以设置为不参与训练：`net.trainable = False`，那么预训练的词向量就直接应用到此特定任务上；如果希望能够学到区别于预训练词向量模型不同的表示方法，那么可以把`Embedding`层包含进反向传播算法中去，利用梯度下降来微调单词表示方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.2 循环神经网络\n",
    "以文本序列为例：\n",
    "> “I hate this boring movie”\n",
    "\n",
    "通过`Embedding`层，可以将它转换为`shape`为$[b,s,n]$的张量，$b$为句子数量，$s$为句子长度，$n$为词向量长度。上述句子可以表示为`shape`为$[1,5,10]$的张量。\n",
    "\n",
    "我们以情感分类任务为例逐步探索能够处理序列信号的网络模型，如`图11.3`所示。\n",
    "\n",
    "<img src=\"images/11_03.png\" style=\"width:450px;\"/>\n",
    "\n",
    "情感分类任务通过分析给出的文本序列，提炼出文本数据表达的整体语义特征，从而预测输入文本的情感类型：正面评价或者负面评价。\n",
    "\n",
    "### 11.2.1 全连接层可行吗\n",
    "首先我们想到的是，对于每个词向量，分别使用一个全连接层网络：\n",
    "+ $o = \\sigma(W_tx_t+b_t)$\n",
    "\n",
    "提取语义特征，如`图11.4`所示，各个单词的词向量通过$s$个全连接层`分类网络1`提取每个单词的特征，所有单词的特征最后合并，并通过`分类网络2`输出序列的类别概率分布，对于长度为$s$的句子来说，至少需要$s$个全网络层。\n",
    "\n",
    "<img src=\"images/11_04.png\" style=\"width:500px;\"/>\n",
    "\n",
    "这种方案的缺点有：\n",
    "+ 网络参数量是相当可观的，内存占用和计算代价较高，同时由于每个序列的长度$s$并不相同，网络结构是动态变化的\n",
    "+ 每个全连接层子网络$W_i$和$b_i$只能感受当前词向量的输入，并不能感知之前和之后的语境信息，导致句子整体语义的缺失，每个子网络只能根据自己的输入来提取高层特征，有如管中窥豹\n",
    "\n",
    "我们接下来逐一解决这2大缺陷。\n",
    "\n",
    "### 11.2.2 共享权值\n",
    "卷积神经网络之所以在处理局部相关数据时优于全连接网络，是因为它充分利用了权值共享的思想，大大减少了网络的参数量。我们在处理序列信号时能否借鉴权值共享的思想呢？\n",
    "\n",
    "`图11.4`中的方案，$s$个全连接层的网络并没有实现权值同享。我们尝试将这$s$个网络层参数共享，这样其实相当于使用一个全连接网络来提取所有单词的特征信息，如`图11.5`所示。\n",
    "\n",
    "<img src=\"images/11_05.png\" style=\"width:500px;\"/>\n",
    "\n",
    "通过权值共享后，参数量大大减少。但是，这种网络结构也没有考虑序列之间的先后顺序，将词向量打乱次序仍然能获得相同的输出，无法获取有效的全局语义信息。\n",
    "\n",
    "### 11.2.3 全局语义\n",
    "如何赋予网络提取整体语义特征的能力呢？我们想到了内存(Memory)机制。如果网络能够提供一个单独的内存变量，每次提取词向量的特征并刷新内存变量，直至最后一个输入完成，此时的内存变量即存储了所有序列的语义特征，并且由于输入序列之间的先后顺序，使得内存变量内容与序列顺序紧密关联。\n",
    "\n",
    "<img src=\"images/11_06.png\" style=\"width:500px;\"/>\n",
    "\n",
    "我们将上述`Memory`机制实现为一个状态张量 ，如`图11.6`所示，除了原来的$W_{x,h}$参数共享外，这里额外增加了一个$W_{hh}$参数，每个时间戳$t$上状态张量$h$刷新机制为：\n",
    "+ $h_t = \\sigma(W_{xh}x_t + W_{hh}h_{t−1} + b)$\n",
    "\n",
    "其中状态张量$h_0$为初始的内存状态，可以初始化为全0，经过$s$个词向量的输入后得到网络最终的状态张量$h_s$，$h_s$较好地代表了句子的全局语义信息，基于$h_s$通过某个全连接层分类器即可完成情感分类任务。\n",
    "\n",
    "### 11.2.4 循环神经网络\n",
    "通过一步步地探索，我们最终提出了一种如`图11.7`所示的网络模型：\n",
    "\n",
    "<img src=\"images/11_07.png\" style=\"width:400px;\"/>\n",
    "\n",
    "在每个时间戳$t$，网络层接受当前时间戳的输入$x_t$和上一个时间戳的网络状态向量$h_{t-1}$，经过$h_t = f_{\\theta}(h_{t−1}, x_t)$\n",
    "\n",
    "变换后得到当前时间戳的新状态向量$h_t$，并写入内存状态中，其中$f_{\\theta}$代表了网络的运算逻辑，$\\theta$为网络参数集。在每个时间戳上，网络层均有输出产生$o_t$，$o_t = g_{\\phi}(h_t)$，即将网络的状态向量变换后输出。\n",
    "\n",
    "上述网络结构在时间戳上折叠，如`图11.8`所示，网络循环接受序列的每个特征向量$x_t$，并刷新内部状态向量$t$，同时形成输出$o_t$。对于这种网络结构，我们把它叫做`循环网络结构`(Recurrent Neural Network，简称 RNN)。\n",
    "\n",
    "<img src=\"images/11_08.png\" style=\"width:200px;\"/>\n",
    "\n",
    "更特别地，如果使用张量$W_{xh}$、$W_{hh}$和偏置$b$来参数化$f_{\\theta}$网络，并按照$h_t = \\sigma(W_{xh}x_t + W_{hh}h_{t−1} + b)$方式更新内存状态，我们把这种网络叫做基本的循环神经网络。\n",
    "\n",
    "在循环神经网络中，激活函数更多地采用`tanh`函数，并且可以选择不使用偏置$b$来进一步减少参数量。状态向量$h_t$可以直接用作输出，即$o_t=h_t$，也可以对$h_t$做一个简单的线性变换$o_t = W_{ho}h_t$后得到每个时间戳上的网络输出$o_t$。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.3 梯度传播\n",
    "通过循环神经网络的更新表达式可以看出输出对张量$W_{xh}、W_{hh}$和偏置$b$均是可导的，可以利用自动梯度算法来求解网络的梯度。此处我们仅简单地推导一下RNN的梯度传播公式，并观察其特点。\n",
    "\n",
    "考虑梯度$\\displaystyle\\frac{\\partial\\mathcal{L}}{\\partial W_{hh}}$，其中$\\mathcal{L}$为网络的误差，只考虑最后一个时刻$t$的输出$o_t$与真实值之间的差距。由于$W_{hh}$被每个时间戳$i$上权值共享，在计算$\\displaystyle\\frac{\\partial\\mathcal{L}}{\\partial W_{hh}}$时需要将每个中间时间戳$i$上面的梯度求和，利用链式法则展开为\n",
    "+ $\\displaystyle\\frac{\\partial\\mathcal{L}}{\\partial W_{hh}}=\\sum_{i=1}^{t}\\frac{\\partial\\mathcal{L}}{\\partial o_t}\\frac{\\partial o_t}{\\partial h_t}\\frac{\\partial h_t}{\\partial h_i}\\frac{\\partial^+ h_i}{\\partial W_{hh}}$\n",
    "\n",
    "其中$\\displaystyle\\frac{\\partial\\mathcal{L}}{\\partial o_t}$可以基于损失函数直接求得，$\\displaystyle\\frac{\\partial o_t}{\\partial h_t}$在$o_t=h_t$的情况下：\n",
    "+ $\\displaystyle\\frac{\\partial o_t}{\\partial h_t} = 1$\n",
    "\n",
    "而$\\displaystyle\\frac{\\partial^+ h_i}{\\partial W_{hh}}$的梯度将$h_i$展开后也可以求得：\n",
    "+ $\\displaystyle\\frac{\\partial^+ h_i}{\\partial W_{hh}} = \\frac{\\partial\\sigma\\big(W_{xh}x_t+W_{hh}h_{t-1}+b\\big)}{\\partial W_{hh}}$\n",
    "\n",
    "其中$\\displaystyle\\frac{\\partial^+ h_i}{\\partial W_{hh}}$只考虑到一个时间戳的梯度传播，即`直接`偏导数，与$\\displaystyle\\frac{\\partial\\mathcal{L}}{\\partial W_{hh}}$考虑$i=1,\\dots,t$所有的时间戳的偏导数不同。\n",
    "\n",
    "因此，只需要推导出$\\displaystyle\\frac{\\partial h_t}{\\partial h_i}$的表达式即可完成循环神经网络的梯度推导。利用链式法则，我们把$\\displaystyle\\frac{\\partial h_t}{\\partial h_i}$分拆分连续时间戳的梯度表达式：\n",
    "+ $\\displaystyle\\frac{\\partial h_t}{\\partial h_i} = \\frac{\\partial h_t}{\\partial h_{t-1}}\\frac{\\partial h_{t-1}}{\\partial h_{t-2}}\\dots\\frac{\\partial h_{i+1}}{\\partial h_i} = \\prod_{k=1}^{t-1}\\frac{\\partial h_{k+1}}{\\partial h_{k}}$\n",
    "\n",
    "考虑到\n",
    "+ $h_{k+1} = \\sigma\\big(W_{xh}x_{k+1}+W_{hh}h_k+b\\big)$\n",
    "\n",
    "那么\n",
    "+ $\\displaystyle\\frac{\\partial h_{k+1}}{\\partial h_{k}} = W_{hh}^{T}\\mathit{diag}\\bigg(\\sigma'\\big(W_{xh}x_{k+1}+W_{hh}h_k+b\\big)\\bigg) = W_{hh}^{T}\\mathit{diag}\\bigg(\\sigma'\\big(h_{k+1}\\big)\\bigg)$\n",
    "\n",
    "其中$\\mathit{diag}(x)$是把向量$x$的每个元素作为矩阵的对角元素的对角矩阵， 例如：\n",
    "+ $\\mathit{diag} = \\begin{bmatrix}3&0&0\\\\0&2&0\\\\0&0&1\\\\ \\end{bmatrix}$\n",
    "\n",
    "因此\n",
    "+ $\\displaystyle\\frac{\\partial h_t}{\\partial h_i} = \\prod_{j=i}^{t-1}\\mathit{diag}\\bigg(\\sigma'\\big(W_{xh}x_{j+1}+W_{hh}h_j+b\\big)\\bigg)W_{hh}$\n",
    "\n",
    "至此，$\\displaystyle\\frac{\\partial\\mathcal{L}}{\\partial W_{hh}}$的梯度推导完成。\n",
    "\n",
    "由于深度学习框架可以帮助我们自动推导梯度，只需要简单地了解循环神经网络的梯度传播方式即可。我们在推导$\\displaystyle\\frac{\\partial\\mathcal{L}}{\\partial W_{hh}}$的过程中发现，$\\displaystyle\\frac{\\partial h_t}{\\partial h_i}$的梯度包含了$W_{hh}$的连乘运算，我们会在后面介绍，这是导致循环神经网络训练困难的根本原因。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.4 RNN 层使用方法\n",
    "`TensorFlow`通过`layers.SimpleRNNCell`实现基础循环神经网络。`SimpleRNN`与`SimpleRNNCell`的区别在于，带`Cell`的层仅仅是完成了一个时间戳的前向运算，不带`Cell`的层一般是基于`Cell`层实现的，它在内部已经完成了多个时间戳的循环运算，因此使用起来更为方便快捷。\n",
    "\n",
    "### 11.4.1 SimpleRNNCell\n",
    "以某输入特征长度$n=4$，`Cell`状态向量特征长度$h = 3$为例，首先我们新建一个`SimpleRNNCell`，不需要指定序列长度$s$："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: kernel:0, shape: (4, 3), type: <dtype: 'float32'>\n",
      "name: recurrent_kernel:0, shape: (3, 3), type: <dtype: 'float32'>\n",
      "name: bias:0, shape: (3,), type: <dtype: 'float32'>\n"
     ]
    }
   ],
   "source": [
    "# 创建RNN Cell，内存向量长度为 3\n",
    "cell = layers.SimpleRNNCell(3)\n",
    "# 输出特征长度n=4\n",
    "cell.build(input_shape=(None,4)) \n",
    "# 打印W_xh, W_hh, b张量\n",
    "for v in cell.trainable_variables:\n",
    "    print(\"name: {}, shape: {}, type: {}\".format(v.name, v.shape, v.dtype))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`SimpleRNNCell`内部维护了3个张量，`kernel`变量即$W_{xh}$张量，`recurrent_kernel`变量即$W_{hh}$张量，`bias`变量即偏置$b$向量。但是RNN的`Memory`向量并不由`SimpleRNNCell`维护，需要用户自行初始化向量$h_0$并记录每个时间戳上的$t$。\n",
    "\n",
    "通过调用`Cell`实例即可完成前向运算：\n",
    "+ $o_t,[h_t] = \\text{Cell}(x_t, [h_{t-1}])$\n",
    "\n",
    "对于`SimpleRNNCell`来说，$o_t=h_t$，并没有经过额外的线性层转换，是同一个对象；$[h_t]$通过一个`List`包裹起来，这么设置是为了与`LSTM`、`GRU`等RNN变种格式统一。在循环神经网络的初始化阶段，状态向量$h_0$一般初始化为全0向量："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([4, 64]), TensorShape([4, 64]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 初始化状态向量，用列表包裹，统一格式\n",
    "h0 = [tf.zeros([4, 64])]\n",
    "# 生成输入张量，4个80单词的句子\n",
    "x = tf.random.normal([4, 80, 100]) \n",
    "# 所有句子的第1个单词\n",
    "xt = x[:,0,:] \n",
    "# 构建输入特征n=100,序列长度s=80,状态长度=64的Cell\n",
    "cell = layers.SimpleRNNCell(64)\n",
    "# 前向计算\n",
    "out, h1 = cell(xt, h0) \n",
    "out.shape, h1[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到经过一个时间戳的计算后，输出和状态张量的`shape`都为$[b,h]$，打印出这两者的`id`如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(139687642413096, 139687642413096)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id(out), id(h1[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "两者`id`一致，即状态向量直接作为输出向量。对于长度为$s$的训练来说，需要循环通过`Cell`类$s$次才算完成一次网络层的前向运算："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 64])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# h保存每个时间戳上的状态向量列表\n",
    "h = h0\n",
    "\n",
    "# 在序列长度的维度解开输入，得到xt:[b,n]\n",
    "for xt in tf.unstack(x, axis=1):\n",
    "    # 前向计算,out和h均被覆盖\n",
    "    out, h = cell(xt, h) \n",
    "\n",
    "# 最终输出可以聚合每个时间戳上的输出，也可以只取最后时间戳的输出\n",
    "out = out\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后一个时间戳的输出变量`out`将作为网络的最终输出。实际上，也可以将每个时间戳上的输出保存，然后求和或者均值，将其作为网络的最终输出。\n",
    "\n",
    "### 11.4.2 多层SimpleRNNCell网络\n",
    "和卷积神经网络一样，循环神经网络虽然在时间轴上面展开了多次，但只能算一个网络层。通过在深度方向堆叠多个`Cell`类来实现深层卷积神经网络一样的效果，大大的提升网络的表达能力。但是和卷积神经网络动辄几十、上百的深度层数来比，循环神经网络很容易出现`梯度弥散`和`梯度爆炸`现象，深层的循环神经网络训练起来非常困难，目前常见的循环神经网络模型层数一般控制在十层以内。\n",
    "\n",
    "我们这里以两层的循环神经网络为例，介绍利用`Cell`方式构建多层RNN网络："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.random.normal([4,80,100])\n",
    "# 取第一个时间戳的输入x0\n",
    "xt = x[:,0,:] \n",
    "# 构建2个Cell, 内存状态向量长度都为64\n",
    "cell0 = layers.SimpleRNNCell(64)\n",
    "cell1 = layers.SimpleRNNCell(64)\n",
    "# cell0的初始状态向量\n",
    "h0 = [tf.zeros([4,64])] \n",
    "# cell1的初始状态向量\n",
    "h1 = [tf.zeros([4,64])] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在时间轴上面循环计算多次来实现整个网络的前向运算，每个时间戳上的输入`xt`首先通过第一层，得到输出`out0`，再通过第二层，得到输出`out1`："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for xt in tf.unstack(x, axis=1):\n",
    "    # xtw作为输入，输出为out0\n",
    "    out0, h0 = cell0(xt, h0)\n",
    "    # 上一个cell的输出out0作为本cell的输入\n",
    "    out1, h1 = cell1(out0, h1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上述方式先完成一个时间戳上的输入在所有层上的传播，再循环计算完所有时间戳上的输 入。\n",
    "\n",
    "实际上，也可以先完成输入在第一层上所有时间戳的计算，并保存第一层在所有时间戳上的输出列表，再计算第二层、第三层等的传播："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存上一层的所有时间戳上面的输出\n",
    "middle_sequences = []\n",
    "# 计算第一层的所有时间戳上的输出，并保存\n",
    "for xt in tf.unstack(x, axis=1):\n",
    "    out0, h0 = cell0(xt, h0)\n",
    "    middle_sequences.append(out0)\n",
    "# 计算第二层的所有时间戳上的输出\n",
    "# 如果不是末层，需要保存所有时间戳上面的输出\n",
    "for xt in middle_sequences:\n",
    "    out1, h1 = cell1(xt, h1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用这种方式的话，我们需要一个额外的`List`来保存上一层所有时间戳上面的状态信息。这两种方式效果相同，可以根据个人喜好选择编程风格。\n",
    "\n",
    "需要注意的是，循环神经网络的每一层、每一个时间戳上面均有状态输出，那么对于后续任务来说，我们应该收集哪些状态输出最有效呢？一般来说，最末层 `Cell`的状态有可能保存了高层的全局语义特征，因此一般使用最末层的输出作为后续任务网络的输入。更特别地，每层最后一个时间戳上的状态输出包含了整个序列的全局信息，如果只希望选用一个状态变量来完成后续任务，比如情感分类问题，一般选用最末层、最末时间戳的状态输出最为合适。\n",
    "\n",
    "### 11.4.3 SimpleRNN层\n",
    "通过`SimpleRNNCell`层的使用可以非常深入地理解循环神经网络前向运算的每个细节。在实际使用中，为了简便，通常使用`SimpleRNN`高层接口。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 64])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建状态向量长度为64的SimpleRNN层\n",
    "layer = layers.SimpleRNN(64) \n",
    "x = tf.random.normal([4, 80, 100])\n",
    "# 和普通卷积网络一样，一行代码即可获得输出\n",
    "out = layer(x)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`SimpleRNN`仅需一行代码即可完成整个前向运算过程，它默认返回最后一个时间戳上的输出。\n",
    "\n",
    "如果希望返回所有时间戳上的输出列表，可以设置`return_sequences=True`参数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([4, 80, 100]), TensorShape([4, 80, 64]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建RNN层时，设置返回所有时间戳上的输出\n",
    "layer = layers.SimpleRNN(64,return_sequences=True)\n",
    "# 前向计算\n",
    "out = layer(x) \n",
    "# 输出，自动进行了concat操作\n",
    "x.shape, out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "输出张量`shape`为$[4,80,64]$，中间维度的80即为时间戳维度。\n",
    "\n",
    "可以通过堆叠多个`SimpleRNN`实现多层循环神经网络："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 64])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = keras.Sequential([ \n",
    "    # 构建2层RNN网络，除最末层外，都需要返回所有时间戳的输出，用作下一层的输入\n",
    "    layers.SimpleRNN(64, return_sequences=True),\n",
    "    layers.SimpleRNN(64),\n",
    "])\n",
    "\n",
    "# 前向计算\n",
    "out = net(x) \n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.5 RNN情感分类问题实战\n",
    "现在利用基础的RNN网络来解决情感分类问题。网络结构如`图11.9`所示，RNN网络共两层，循环提取序列信号的语义特征，利用第2层RNN层的最后时间戳的状态向量$h_s^{2}$作为句子的全局语义特征表示，送入全连接层构成的分类网络3，得到样本$x$为积极情感的概率$P(x为积极情感|x)\\in[0,1]$。\n",
    "\n",
    "<img src=\"images/11_09.png\" style=\"width:500px;\"/>\n",
    "\n",
    "### 11.5.1 数据集\n",
    "我们使用经典的`IMDB`影评数据集。`IMDB`影评数据集包含了50000条用户评价，评价的标签分为消极和积极，其中`IMDB`评级$\\lt5$的用户评价标注为0，即消极；`IMDB`评价$\\ge7$的用户评价标注为1，即积极。25000条影评用于训练集，25000条用于测试集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000,) 218 (25000,)\n",
      "(25000,) 68 (25000,)\n"
     ]
    }
   ],
   "source": [
    "# 批量大小\n",
    "batchsz = 128 \n",
    "# 词汇表大小N_vocab\n",
    "total_words = 10000 \n",
    "# 句子最大长度s，大于的句子部分将截断，小于的将填充\n",
    "max_review_len = 80 \n",
    "# 词向量特征长度n\n",
    "embedding_len = 100 \n",
    "# 加载IMDB数据集，此处的数据采用数字编码，一个数字代表一个单词\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.imdb.load_data(num_words=total_words)\n",
    "\n",
    "# 打印输入的形状，标签的形状\n",
    "print(x_train.shape, len(x_train[0]), y_train.shape)\n",
    "print(x_test.shape, len(x_test[0]), y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到，`x_train`和`x_test`是长度为25000的一维数组，数组的每个元素是不定长`List`，保存了数字编码的每个句子，例如训练集的第一个句子共有218个单词，测试集的第一个句子共有68个单词，每个句子都包含了句子起始标志ID。\n",
    "\n",
    "那么每个单词是如何编码为数字的呢？我们可以通过查看它的编码表获得编码方案："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fawn 34701\n",
      "tsukino 52006\n",
      "nunnery 52007\n",
      "sonja 16816\n",
      "vani 63951\n",
      "woods 1408\n",
      "spiders 16115\n",
      "hanging 2345\n",
      "woody 2289\n",
      "trawling 52008\n",
      "hold's 52009\n"
     ]
    }
   ],
   "source": [
    "word_index = keras.datasets.imdb.get_word_index()\n",
    "# 打印出编码表的单词和对应的数字\n",
    "i = 0\n",
    "for k,v in word_index.items():\n",
    "    print(k,v)\n",
    "    i += 1\n",
    "    if i >10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于编码表的键为单词，值为ID，这里翻转编码表，并添加标志位的编码ID，代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 前面4个ID是特殊位\n",
    "word_index = {k:(v+3) for k,v in word_index.items()}\n",
    "word_index[\"<PAD>\"] = 0\n",
    "# 填充标志\n",
    "word_index[\"<START>\"] = 1 # 起始标志\n",
    "word_index[\"<UNK>\"] = 2\n",
    "# 未知单词的标志\n",
    "word_index[\"<UNUSED>\"] = 3\n",
    "# 翻转编码表\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于一个数字编码的句子，通过如下函数转换为字符串数据："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<START> big hair big boobs bad music and a giant safety pin these are the words to best describe this terrible movie i love cheesy horror movies and i've seen hundreds but this had got to be on of the worst ever made the plot is paper thin and ridiculous the acting is an abomination the script is completely laughable the best is the end showdown with the cop and how he worked out who the killer is it's just so damn terribly written the clothes are sickening and funny in equal <UNK> the hair is big lots of boobs <UNK> men wear those cut <UNK> shirts that show off their <UNK> sickening that men actually wore them and the music is just <UNK> trash that plays over and over again in almost every scene there is trashy music boobs and <UNK> taking away bodies and the gym still doesn't close for <UNK> all joking aside this is a truly bad film whose only charm is to look back on the disaster that was the 80's and have a good old laugh at how bad everything was back then\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def decode_review(text):\n",
    "    return ' '.join([reverse_word_index.get(i, '?') for i in text])\n",
    "\n",
    "decode_review(x_train[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于长度参差不齐的句子，人为设置一个阈值，对大于此长度的句子，选择截断部分单词，可以选择截去句首单词，也可以截去句末单词；对于小于此长度的句子，可以选择在句首或句尾填充。\n",
    "\n",
    "句子截断功能通过`keras.preprocessing.sequence.pad_sequences()`函数实现："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 截断和填充句子，使得等长，此处长句子保留句子后面的部分，短句子在前面填充\n",
    "x_train = keras.preprocessing.sequence.pad_sequences(x_train, maxlen=max_review_len)\n",
    "x_test = keras.preprocessing.sequence.pad_sequences(x_test, maxlen=max_review_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "截断或填充为相同长度后，通过`Dataset`类包裹成数据集对象，并添加常用的数据集处理流程："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (25000, 80) tf.Tensor(1, shape=(), dtype=int64) tf.Tensor(0, shape=(), dtype=int64)\n",
      "x_test shape: (25000, 80)\n"
     ]
    }
   ],
   "source": [
    "# 构建数据集、打散、批量，并丢掉最后一个不够batchsz的batch\n",
    "db_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "# drop_remainder=True丢弃掉最后一个Batch，因为真实的Batch Size可能小于预设的Batch Size\n",
    "db_train = db_train.shuffle(1000).batch(batchsz, drop_remainder=True)\n",
    "db_test = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "db_test = db_test.batch(batchsz, drop_remainder=True)\n",
    "\n",
    "# 统计数据集属性\n",
    "print('x_train shape:', x_train.shape, tf.reduce_max(y_train), tf.reduce_min(y_train))\n",
    "print('x_test shape:', x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.5.2 网络模型\n",
    "自定义的模型类`MyRNN`，包含一个`Embedding`层、两个`RNN`层、以及分类网络层："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyRNN(keras.Model):\n",
    "    # Cell方式构建多层网络\n",
    "    def __init__(self, units):\n",
    "        super(MyRNN, self).__init__() \n",
    "        # 词向量编码 [b, 80] => [b, 80, 100]\n",
    "        self.embedding = layers.Embedding(total_words, embedding_len,\n",
    "                                          input_length=max_review_len)\n",
    "        # 构建RNN\n",
    "        self.rnn = keras.Sequential([\n",
    "            layers.SimpleRNN(units, dropout=0.5, return_sequences=True),\n",
    "            layers.SimpleRNN(units, dropout=0.5)\n",
    "        ])\n",
    "        # 构建分类网络，用于将CELL的输出特征进行分类，2分类\n",
    "        # [b, 80, 100] => [b, 64] => [b, 1]\n",
    "        self.outlayer = Sequential([\n",
    "        \tlayers.Dense(32),\n",
    "        \tlayers.Dropout(rate=0.5),\n",
    "        \tlayers.ReLU(),\n",
    "        \tlayers.Dense(1)])\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        x = inputs # [b, 80]\n",
    "        # embedding: [b, 80] => [b, 80, 100]\n",
    "        x = self.embedding(x)\n",
    "        # rnn cell compute,[b, 80, 100] => [b, 64]\n",
    "        x = self.rnn(x)\n",
    "        # 末层最后一个输出作为分类网络的输入: [b, 64] => [b, 1]\n",
    "        x = self.outlayer(x,training)\n",
    "        # p(y is pos|x)\n",
    "        prob = tf.sigmoid(x)\n",
    "\n",
    "        return prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.5.3 训练与测试\n",
    "设置优化器为`Adam`优化器，学习率为0.001，误差函数选用二分类的交叉熵损失函数 BinaryCrossentropy，测试指标采用准确率即可："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 195 steps, validate for 195 steps\n",
      "Epoch 1/20\n",
      "195/195 [==============================] - 17s 87ms/step - loss: 0.6994 - accuracy: 0.5058 - val_loss: 0.6923 - val_accuracy: 0.5096\n",
      "Epoch 2/20\n",
      "195/195 [==============================] - 15s 76ms/step - loss: 0.6833 - accuracy: 0.5471 - val_loss: 0.6489 - val_accuracy: 0.6398\n",
      "Epoch 3/20\n",
      "195/195 [==============================] - 15s 76ms/step - loss: 0.5345 - accuracy: 0.7430 - val_loss: 0.4364 - val_accuracy: 0.8020\n",
      "Epoch 4/20\n",
      "195/195 [==============================] - 15s 78ms/step - loss: 0.3805 - accuracy: 0.8451 - val_loss: 0.4265 - val_accuracy: 0.8207\n",
      "Epoch 5/20\n",
      "195/195 [==============================] - 15s 76ms/step - loss: 0.3171 - accuracy: 0.8761 - val_loss: 0.4370 - val_accuracy: 0.8314\n",
      "Epoch 6/20\n",
      "195/195 [==============================] - 15s 75ms/step - loss: 0.2548 - accuracy: 0.9044 - val_loss: 0.4780 - val_accuracy: 0.8225\n",
      "Epoch 7/20\n",
      "195/195 [==============================] - 15s 75ms/step - loss: 0.2016 - accuracy: 0.9284 - val_loss: 0.7100 - val_accuracy: 0.8151\n",
      "Epoch 8/20\n",
      "195/195 [==============================] - 15s 78ms/step - loss: 0.1572 - accuracy: 0.9439 - val_loss: 0.6547 - val_accuracy: 0.8155\n",
      "Epoch 9/20\n",
      "195/195 [==============================] - 15s 78ms/step - loss: 0.1340 - accuracy: 0.9532 - val_loss: 0.7050 - val_accuracy: 0.8163\n",
      "Epoch 10/20\n",
      "195/195 [==============================] - 16s 80ms/step - loss: 0.1017 - accuracy: 0.9666 - val_loss: 0.7635 - val_accuracy: 0.8080\n",
      "Epoch 11/20\n",
      "195/195 [==============================] - 15s 74ms/step - loss: 0.0905 - accuracy: 0.9698 - val_loss: 0.9129 - val_accuracy: 0.8153\n",
      "Epoch 12/20\n",
      "195/195 [==============================] - 14s 73ms/step - loss: 0.0821 - accuracy: 0.9735 - val_loss: 0.9480 - val_accuracy: 0.8184\n",
      "Epoch 13/20\n",
      "195/195 [==============================] - 14s 74ms/step - loss: 0.0662 - accuracy: 0.9779 - val_loss: 0.8989 - val_accuracy: 0.8126\n",
      "Epoch 14/20\n",
      "195/195 [==============================] - 15s 75ms/step - loss: 0.0648 - accuracy: 0.9782 - val_loss: 0.8098 - val_accuracy: 0.8064\n",
      "Epoch 15/20\n",
      "195/195 [==============================] - 14s 74ms/step - loss: 0.0619 - accuracy: 0.9792 - val_loss: 0.9318 - val_accuracy: 0.7955\n",
      "Epoch 16/20\n",
      "195/195 [==============================] - 15s 77ms/step - loss: 0.0516 - accuracy: 0.9829 - val_loss: 1.0093 - val_accuracy: 0.8050\n",
      "Epoch 17/20\n",
      "195/195 [==============================] - 15s 76ms/step - loss: 0.0510 - accuracy: 0.9832 - val_loss: 1.1238 - val_accuracy: 0.8061\n",
      "Epoch 18/20\n",
      "195/195 [==============================] - 14s 74ms/step - loss: 0.0521 - accuracy: 0.9821 - val_loss: 1.0247 - val_accuracy: 0.8121\n",
      "Epoch 19/20\n",
      "195/195 [==============================] - 15s 76ms/step - loss: 0.0517 - accuracy: 0.9834 - val_loss: 1.0661 - val_accuracy: 0.7839\n",
      "Epoch 20/20\n",
      "195/195 [==============================] - 14s 74ms/step - loss: 0.0452 - accuracy: 0.9846 - val_loss: 1.1112 - val_accuracy: 0.7710\n",
      "195/195 [==============================] - 3s 17ms/step - loss: 1.1112 - accuracy: 0.7710\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    units = 64 # RNN状态向量长度\n",
    "    epochs = 20 # 训练epochs\n",
    "    model = MyRNN(units) # 创建模型\n",
    "    # 装配\n",
    "    model.compile(optimizer = optimizers.Adam(0.001), loss = losses.BinaryCrossentropy(), metrics=['accuracy'])\n",
    "    # 训练和验证\n",
    "    model.fit(db_train, epochs=epochs, validation_data=db_test)\n",
    "    # 测试\n",
    "    model.evaluate(db_test)\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.6 梯度弥散和梯度爆炸\n",
    "循环神经网络的训练并不稳定，网络的深度也不能任意的加深。那么，为什么循环神经网络会出现训练困难的问题呢？简单回顾梯度推导中的关键表达式：\n",
    "+ $\\displaystyle\\frac{\\partial h_t}{\\partial h_i} = \\prod_{j=i}^{t-1}\\mathit{diag}\\bigg(\\sigma'\\big(W_{xh}x_{j+1}+W_{hh}h_j+b\\big)\\bigg)W_{hh}$\n",
    "\n",
    "也就是说，从时间戳$i$到时间戳$t$的梯度$\\displaystyle\\frac{\\partial h_t}{\\partial h_i}$包含了$W_{hh}$的连乘运算。当$W_{hh}$的最大特征值(Largest Eignvalue)小于1时，多次连乘运算会使得$\\displaystyle\\frac{\\partial h_t}{\\partial h_i}$的元素值接近于零；当$\\displaystyle\\frac{\\partial h_t}{\\partial h_i}$的值大于1时，多次连乘运算会使得$\\displaystyle\\frac{\\partial h_t}{\\partial h_i}$的元素值爆炸式增长。\n",
    "\n",
    "我们可以从下面的两个例子直观地感受一下梯度弥散和梯度爆炸现象的产生："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([0.       , 1.9999999], dtype=float32)>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 任意创建某矩阵\n",
    "W = tf.ones([2,2])\n",
    "# 计算矩阵的特征值\n",
    "eigenvalues = tf.linalg.eigh(W)[0]\n",
    "eigenvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到，全1矩阵的最大特征值为2。计算$W$矩阵的$W^1 \\sim W^{10}$运算结果，并绘制为次方与矩阵的`L2`范数的曲线图，可以看到，当$W$矩阵的最大特征值大于1时，矩阵多次相乘会使得结果越来越大。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "val = [W]\n",
    "# 矩阵相乘n次方\n",
    "for i in range(10): \n",
    "    val.append([val[-1]@W])\n",
    "    \n",
    "# 计算L2范数\n",
    "norm = list(map(lambda x:tf.norm(x).numpy(),val))\n",
    "\n",
    "# 绘图\n",
    "plt.plot(range(1,12), norm)\n",
    "plt.xlabel('n times')\n",
    "plt.ylabel('L2-norm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当最大特征值小于1时："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0.         0.79999995], shape=(2,), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 任意创建某矩阵\n",
    "W = tf.ones([2,2])*0.4 \n",
    "eigenvalues = tf.linalg.eigh(W)[0]\n",
    "print(eigenvalues)\n",
    "\n",
    "val = [W]\n",
    "for i in range(10):\n",
    "    val.append([val[-1]@W])\n",
    "\n",
    "# 计算L2范数\n",
    "norm = list(map(lambda x:tf.norm(x).numpy(),val))\n",
    "\n",
    "# 绘图\n",
    "plt.plot(range(1,12), norm)\n",
    "plt.xlabel('n times')\n",
    "plt.ylabel('L2-norm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们把梯度值接近于0的现象叫做`梯度弥散`(Gradient Vanishing)，把梯度值远大于1的现象叫做`梯度爆炸`(Gradient Exploding)。\n",
    "\n",
    "考虑梯度下降算法：\n",
    "+ $\\theta' = \\theta - \\mu\\nabla_{\\theta}\\mathcal{L}$\n",
    "\n",
    "+ 当出现梯度弥散时，$\\nabla_{\\theta}\\mathcal{L} \\approx 0$，此时$\\theta'\\approx\\theta$，神经网络的参数长时间得不到更新，具体表现为$\\mathcal{L}$几乎保持不变\n",
    "+ 当出现梯度爆炸时，$\\nabla_{\\theta}\\mathcal{L} \\gg 1$，此时梯度的更新步长$\\theta'\\approx\\theta$非常大，使得更新后的$\\theta'$与$\\theta$差距很大，网络$\\mathcal{L}$出现突变现象，甚至可能出现来回震荡、不收敛的现象\n",
    "\n",
    "那么怎么解决这两个问题呢？\n",
    "\n",
    "### 11.6.1 梯度裁剪\n",
    "`梯度爆炸`可以通过`梯度裁剪`(Gradient Clipping)的方式在一定程度上的解决。梯度裁剪与张量限幅非常类似，也是通过将梯度张量的数值或者范数限制在某个较小的区间内，从而将远大于1的梯度值减少，避免出现梯度爆炸。\n",
    "\n",
    "在深度学习中，有3种常用的梯度裁剪方式：\n",
    "\n",
    "##### 方法1:限幅\n",
    "对张量的数值进行限幅，使得张量$W$的所有元素$w_{ij} \\in [\\mathrm{min},\\mathrm{max}]$。`TensorFlow`通过`tf.clip_by_value()`函数来实现:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       " array([[0.6676514 , 0.6177614 ],\n",
       "        [0.41793048, 0.33756483]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       " array([[0.6       , 0.6       ],\n",
       "        [0.41793048, 0.4       ]], dtype=float32)>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=tf.random.uniform([2,2])\n",
    "a, tf.clip_by_value(a,0.4,0.6) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 方法2:限制范数\n",
    "将$W$的$L2$范数约束在$[0, \\mathrm{max}]$之间，如果$L2$范数大于$\\mathrm{max}$值，则按照\n",
    "+ $W'=\\displaystyle\\frac{W}{\\lVert W \\rVert_{2}}\\cdot\\mathrm{max}$\n",
    "\n",
    "方式将$\\lVert W' \\rVert_{2}$约束$\\mathrm{max}$内。可以通过`tf.clip_by_norm`函数实现："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=5.5082097>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.0>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=tf.random.uniform([2,2]) * 5\n",
    "# 按范数方式裁剪\n",
    "b = tf.clip_by_norm(a, 5)\n",
    "# 裁剪前和裁剪后的张量范数\n",
    "tf.norm(a), tf.norm(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 方法3:全局范数裁剪\n",
    "神经网络的更新方向是由所有参数的梯度张量$W$共同表示的，前两种方式只考虑单个梯度张量的限幅，会出现网络更新方向发生变动的情况。如果能够考虑所有参数的梯度$W$的范数，实现等比例的缩放，那么就能既很好地限制网络的梯度值，同时不改变网络的更新方向。这就是`全局范数裁剪`。\n",
    "\n",
    "令$W^{(i)}$表示网络参数的第$i$个梯度张量，首先通过\n",
    "+ $\\mathrm{\\text{global_norm}} = \\displaystyle\\sqrt{\\sum_{i}{{\\lVert W^{(i)}\\rVert}}_2^2}$\n",
    "\n",
    "计算网络的总范数$\\mathrm{\\text{global_norm}}$。对第$i$个参数$W^{(i)}$，通过\n",
    "+ $W^{(i)} = \\displaystyle\\frac{W^{(i)}\\cdot\\mathrm{\\text{max_norm}}}{\\max{(\\mathrm{\\text{global_norm}}, \\mathrm{\\text{max_norm}})}}$\n",
    "\n",
    "进行裁剪，其中$\\mathrm{\\text{max_norm}}$是用户指定的全局最大范数值。\n",
    "\n",
    "`TensorFlow`通过`tf.clip_by_global_norm`函数快捷地缩放整体网络梯度$W$的范数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(4.616837, shape=(), dtype=float32) tf.Tensor(2.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 创建梯度张量1\n",
    "w1=tf.random.normal([3,3]) \n",
    "# 创建梯度张量2\n",
    "w2=tf.random.normal([3,3])\n",
    "# 计算`global norm`\n",
    "global_norm=tf.math.sqrt(tf.norm(w1)**2+tf.norm(w2)**2)\n",
    "# 根据`global norm`和`max norm=2`裁剪\n",
    "(ww1,ww2),global_norm=tf.clip_by_global_norm([w1,w2],2)\n",
    "# 计算裁剪后的张量组的`global norm`\n",
    "global_norm2 = tf.math.sqrt(tf.norm(ww1)**2+tf.norm(ww2)**2)\n",
    "# 打印裁剪前的全局范数和裁剪后的全局范数\n",
    "print(global_norm, global_norm2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到，通过裁剪后，网络参数的梯度组的总范数缩减到`max_norm = 2`。需要注意的是，`tf.clip_by_global_norm`返回裁剪后的张量`List`和`global_norm`这两个对象，其中`global_norm`表示裁剪前的梯度总范数和。\n",
    "\n",
    "通过梯度裁剪，可以较大程度的抑制梯度爆炸现象。如`图11.12`所示，图中曲面表示的$𝐽(w,b)$函数在不同网络参数$w$和$b$下的误差值$J$，其中有一块区域$𝐽(w,b)$函数的梯度变化较大，一旦网络参数进入此区域，很容易出现梯度爆炸的现象。`图11.12`右演示了添加梯度裁剪后的优化轨迹，由于对梯度进行了有效限制，使得每次更新的步长得到有效控制，从而防止网络突然恶化。\n",
    "\n",
    "<img src=\"images/11_12.png\" style=\"width:300px;\"/>\n",
    "\n",
    "在网络训练时，梯度裁剪一般在计算出梯度后，梯度更新之前进行：\n",
    "\n",
    "```python\n",
    "with tf.GradientTape() as tape:\n",
    "  logits = model(x) # 前向传播\n",
    "  loss = criteon(y, logits) # 误差计算\n",
    "# 计算梯度值\n",
    "grads = tape.gradient(loss, model.trainable_variables)\n",
    "# 全局梯度裁剪\n",
    "grads, _ = tf.clip_by_global_norm(grads, 25) \n",
    "# 利用裁剪后的梯度张量更新参数\n",
    "optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "```\n",
    "\n",
    "### 11.6.2 梯度弥散\n",
    "对于`梯度弥散`现象，可以通过增大学习率、减少网络深度、添加`Skip Connection`等一系列的措施抑制。\n",
    "\n",
    "对于深层次的神经网络，梯度由最末层逐渐向首层传播，梯度弥散一般更有可能出现在网络的开始数层。在深度残差网络出现之前，几十上百层的深层网络训练起来非常困难，前面数层的网络梯度极容易出现梯度离散现象，从而使得网络参数长时间得不到更新。深度残差网络较好地克服了梯度弥散现象，从而让神经网络层数达到成百上千。一般来说，减少网络深度可以减轻梯度弥散现象，但是网络层数减少后，网络表达能力也会偏弱，需要用户自行平衡。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
