{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# 加载TF模块\n",
    "from tensorflow.keras import layers,Sequential,losses,optimizers,datasets\n",
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. 卷积神经网络\n",
    "\n",
    "## 10.1 全连接网络的问题\n",
    "首先我们来分析全连接网络存在的问题。考虑一个简单的4层全连接层网络，如`图10.1`所示。\n",
    "\n",
    "<img src=\"images/10_01.png\" style=\"width:600px;\"/>\n",
    "\n",
    "通过`TensorFlow`快速地搭建此网络模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                multiple                  200960    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  65792     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              multiple                  65792     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              multiple                  2570      \n",
      "=================================================================\n",
      "Total params: 335,114\n",
      "Trainable params: 335,114\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 创建4层全连接网络\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dense(10),\n",
    "])\n",
    "\n",
    "# build模型，并打印模型信息\n",
    "model.build(input_shape=(4, 784))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`summary()`函数打印出模型每一层的参数量统计结果。\n",
    "\n",
    "网络的参数量是怎么计算的呢？对于每一条连接线的权值标量，视作一个参数，因此对输入节点数为$n$，输出节点数为$m$的全连接层来说，$W$张量包含的参数量共有$n \\cdot m$个，$b$向量包含的参数量有$m$个，则全连接层的总参数量为$n\\cdot m+m$。上面的四层网络总参数量约34万个。如果将单个权值保存为`float`类型的变量，至少需要占用4个字节内存(`Python`语言中`float`占用内存更多)，那么34万个网络参数至少需要约1.34MB内存。网络的训练过程中还需要缓存计算图模型、梯度信息、输入和中间计算结果等，其中梯度相关运算占用资源非常多。\n",
    "\n",
    "那么训练这样一个网络到底需要多少内存呢？我们可以在现代GPU 备上简单模拟一下资源消耗情况。在`TensorFlow`中，如果不设置显存占用方式，那么默认会占用全部显存。这里将`TensorFlow`的显存使用方式设置为按需分配：\n",
    "\n",
    "```python\n",
    "# 获取所有 GPU 设备列表\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # 设置 GPU 显存占用为按需分配，增长式\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        # 异常处理\n",
    "        print(e)\n",
    "```\n",
    "\n",
    "设置`TensorFlow`按需申请显存资源，这样`TensorFlow`占用的显存大小即为运算需要的数量。在`Batch Size`设置为32的情况下，我们观察到显存占用了约708MB，内存占用约870MB。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.1.1 局部相关性\n",
    "接下来我们探索如何避免全连接网络的参数量过大的缺陷。为了便于讨论，我们以图片类型数据为输入的场景为例。对于2D的图片数据，在进入全连接层之前，需要将矩阵数据打平成1D向量，然后每个像素点与每个输出节点两两相连，如`图10.2`所示。\n",
    "\n",
    "<img src=\"images/10_02.png\" style=\"width:500px;\"/>\n",
    "\n",
    "网络层的每个输出节点与所有的输入节点相连接，用于提取所有输入节点的特征信息，这种稠密的连接方式是全连接层参数量大、计算代价高的根本原因。全连接层也称为`稠密连接层`(Dense Layer)，输出与输入的关系为：\n",
    "+ $o_j = \\sigma\\bigg(\\displaystyle\\sum_{i \\in nodes(I)}w_{ij}x_i+b_j\\bigg)$\n",
    "\n",
    "其中$nodes(I)$表示$I$层的节点集合。\n",
    "\n",
    "那么，输出节点是否有必要和全部的输入节点相连接呢？我们可以分析输入节点对输出节点的重要性分布，仅考虑较重要的一部分输入节点， 而抛弃重要性较低的部分节点，这样输出节点只需要与部分输入节点相连接，表达为：\n",
    "+ $o_j = \\sigma\\bigg(\\displaystyle\\sum_{i \\in top(I,j,k)}w_{ij}x_i+b_j\\bigg)$\n",
    "\n",
    "其中$top(I,j,k)$表示$I$层中对于$J$层中的$j$号节点重要性最高的前$k$个节点集合。通过这种方式，可以把全连接层的$\\lVert I\\rVert\\cdot\\lVert J\\rVert$个权值连接减少到$k\\cdot\\lVert J\\rVert$个，其中$\\lVert I\\rVert$、$\\lVert J\\rVert$分布表示$I,J$层的节点数量。\n",
    "\n",
    "现在问题就转变为探索$I$层输入节点对于$j$号输出节点的重要性分布。找出每个中间节点的重要性分布是件非常困难的事情，我们可以针对于具体问题，利用先验知识把这个问题进一步简化。\n",
    "\n",
    "在现实生活中，存在着大量以位置或距离作为重要性分布衡量标准的数据，比如股票的走势预测应该更加关注近段时间的数据趋势(时间相关)、图片每个像素点和周边像素点的关联度更大(位置相关)。\n",
    "\n",
    "以2D图片数据为例，如果简单地认为与当前像素欧式距离(Euclidean Distance)小于和等于$\\displaystyle\\frac{k}{\\sqrt{2}}$的像素点重要性较高，反之则重要性较低，那么我们就很轻松地简化了每个像素点的重要性分布问题。如`图10.3`所示\n",
    "\n",
    "<img src=\"images/10_03.png\" style=\"width:300px;\"/>\n",
    "\n",
    "这个高宽为$k$的窗口称为`感受野`(Receptive Field)，它表征了每个像素对于中心像素的重要性分布情况，网格内的像素才会被考虑。\n",
    "\n",
    "这种基于距离的重要性分布假设特性称为`局部相关性`。在这种重要性分布假设下，全连接层的连接模式变成了如`图10.4`：\n",
    "\n",
    "<img src=\"images/10_04.png\" style=\"width:300px;\"/>\n",
    "\n",
    "利用局部相关性的思想，我们把感受野窗口的高、宽记为$k$(实际上感受野的高、宽可以不相等)，当前位置的节点与大小为$k$的窗口内的所有像素相连接，网络层的输入输出关系表达如下：\n",
    "+ $o_j = \\sigma\\bigg(\\displaystyle\\sum_{\\text{dist}(i,j) \\le \\frac{k}{\\sqrt{2}}}w_{ij}x_i+b_j\\bigg)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.1.2 权值共享\n",
    "每个输出节点仅与感受野区域内$k\\times k$个输入节点相连接，输出层节点数为$\\lVert J\\rVert$，则当前层的参数量为$k \\times k \\times \\lVert J\\rVert$，相对于全连接层的$\\lVert I\\rVert\\times\\lVert J\\rVert$，考虑到$k$(如1、3、5)，网络模型参数量减少了很多。\n",
    "\n",
    "能否再将参数量进一步减少，比如只需要$k\\times k$个参数即可完成当前层的计算？答案是肯定的，通过`权值共享`的思想，对于每个输出节点$o_j$，均使用相同的权值矩阵$W$，那么无论输出节点的数量$\\lVert J\\rVert$是多少，网络层的参数量总是$k\\times k$。如`图10.5`所示，在计算左上角 位置的输出像素时，使用权值矩阵：\n",
    "+ $W = \\begin{bmatrix}w_{11}&w_{12}&w_{13}\\\\w_{21}&w_{22}&w_{23}\\\\w_{31}&w_{32}&w_{33}\\\\ \\end{bmatrix}$\n",
    "\n",
    "与对应感受野内部的像素相乘累加，作为左上角像素的输出值；在计算右下方感受野区域时，使用相同的权值参数$W$相乘累加，得到右下角像素的输出值，此时网络层的参数量只有$3 \\times 3 = 9$个，且与输入、输出节点数无关。\n",
    "\n",
    "<img src=\"images/10_05.png\" style=\"width:300px;\"/>\n",
    "\n",
    "通过运用`局部相关性`和`权值共享`的思想，我们把网络的参数量减少到$k \\times k$(准确地说，是在单输入通道、单卷积核的条件下)。这种共享权值的`局部连接层`网络其实就是卷积神经网络。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.2 卷积神经网络\n",
    "卷积神经网络通过充分利用局部相关性和权值共享的思想，大大地减少了网络的参数量，从而提高训练效率，更容易实现超大规模的深层网络。\n",
    "\n",
    "本节介绍卷积神经网络层的具体计算流程。以2D图片数据为例，卷积层接受高、宽分别为$h、w$，通道数为$c_{in}$的输入特征图$X$，在$c_{out}$个高、宽都为$k$，通道数为$c_{in}$的 卷积核作用下，生成高、宽分别为$h'、w'$，通道数为$c_{out}$的特征图输出。需要注意的是，卷积核的高宽可以不等。\n",
    "\n",
    "我们首先从单通道输入、单卷积核的情况开始讨论，然后推广至多通道输入、单卷积核，最后讨论最常用，也是最复杂的多通道输入、多个卷积核的卷积层实现。\n",
    "\n",
    "### 10.2.1 单通道输入和单卷积核\n",
    "首先讨论单通道输入$c_{in} = 1$，如灰度图片只有灰度值一个通道，单个卷积核$c_{out} = 1$的情况。以输入$X$为$5 \\times 5$的矩阵，卷积核为$3 \\times 3$的矩阵为例，如`图10.12`所示。\n",
    "\n",
    "<img src=\"images/10_12.png\" style=\"width:500px;\"/>\n",
    "\n",
    "首先移动至输入$X$最左上方(上方的绿色方框)，选中输入$X$上$3 \\times 3$的感受野元素，与卷积核(图片中间$3 \\times 3$方框)对应元素相乘：\n",
    "+ $\\begin{bmatrix}1&-1&0\\\\-1&-2&2\\\\1&2&-2\\\\ \\end{bmatrix} \\odot \\begin{bmatrix}-1&1&2\\\\1&-1&3\\\\0&-1&-2\\\\ \\end{bmatrix} = \\begin{bmatrix}-1&-1&0\\\\-1&2&6\\\\0&-2&4\\\\ \\end{bmatrix}$\n",
    "\n",
    "$\\odot$表示哈达马积(Hadamard Product)，即矩阵的对应元素相乘，它与矩阵相乘符号@是矩阵的二种最为常见的运算形式。运算后得到$3\\times 3$的矩阵，这9个数值全部相加：$−1−1+0−1+2+6+0−2+4=7$，得到标量7，写入输出矩阵第一行、第一列的位置。\n",
    "\n",
    "完成第一个感受野区域的特征提取后，感受野窗口向右移动一个步长单位(Strides，默认为1)，选中`图10.13`中绿色方框标示的感受野元素，按照同样的计算方法得到输出10，写入第一行、第二列位置。\n",
    "\n",
    "<img src=\"images/10_13.png\" style=\"width:500px;\"/>\n",
    "\n",
    "感受野窗口再次向右移动一个步长单位计算输出，如`图10.14`所示。\n",
    "\n",
    "<img src=\"images/10_14.png\" style=\"width:500px;\"/>\n",
    "\n",
    "此时感受野已经移动至输入$X$的有效像素的最右边，此时，感受野窗口向下移动一个步长单位并回到当前行的行首位置，继续选中新的感受野元素区域，如`图10.15`所示。\n",
    "\n",
    "<img src=\"images/10_15.png\" style=\"width:500px;\"/>\n",
    "\n",
    "按照上述方法，每次感受野向右移动1个步长单位，若超出输入边界，则向下移动1个步长单位，并回到行首，直到感受野移动至最右边、最下方位置，如下`图10.16`所示。\n",
    "\n",
    "<img src=\"images/10_16.png\" style=\"width:500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.2.2 多通道输入和单卷积核\n",
    "多通道输入的卷积层更为常见，比如彩色的图片包含了`R/G/B`三个通道，每个通道上面的像素值表示`R/G/B`色彩的强度。下面我们以3通道输入、单个卷积核为例，将单通道输入的卷积运算方法推广到多通道的情况。\n",
    "\n",
    "如`图10.17`中所示，每行的最左边$5\\times5$的矩阵表示输入$X$的`1~3`通道，第2列的$3\\times3$矩阵分别表示卷积核的`1~3`通道，第3列的矩阵表示当前通道上运算结果的中间矩阵，最右边一个矩阵表示卷积层运算的最终输出。\n",
    "\n",
    "<img src=\"images/10_17.png\" style=\"width:500px;\"/>\n",
    "\n",
    "在多通道输入的情况下，卷积核的通道数需要和输入$X$的通道数量相匹配，卷积核的第$i$个通道和$X$的第$i$个通道运算，得到第$i$个中间矩阵，此时可以视为单通道输入与单卷积核的情况，所有通道的中间矩阵对应元素再次相加，作为最终输出。\n",
    "\n",
    "具体的计算流程如下：在初始状态，如`图10.17`所示，每个通道上面的感受野窗口同步落在对应通道上面的最左边、最上方位置，每个通道上感受野区域元素与卷积核对应通道上面的矩阵相乘累加，分别得到三个通道上面的输出`7、-11、-1`的中间变量，这些中间变量相加得到输出-5，写入对应位置。\n",
    "\n",
    "随后，感受野窗口同步在$X$的每个通道上向右移动1个步长单位，如`图10.18`所示，每个通道上面的感受野与卷积核对应通道上面的矩阵相乘累加，得到中间变量`10、20、20`，全部相加得到输出50，写入第一行、第二列元素位置。\n",
    "\n",
    "<img src=\"images/10_18.png\" style=\"width:500px;\"/>\n",
    "\n",
    "以此方式同步移动感受野窗口，直至最右边、最下方位置，此时全部完成输入和卷积核的卷积运算，得到$3\\times3$的输出矩阵，如`图10.19`所示。\n",
    "\n",
    "<img src=\"images/10_19.png\" style=\"width:500px;\"/>\n",
    "\n",
    "整个计算如`图10.20`所示，输入的每个通道处的感受野均与卷积核的对应通道相乘累加，得到与通道数量相等的中间变量，这些中间变量全部相加即得到当前位置的输出值。输入通道的通道数量决定了卷积核的通道数。一个卷积核只能得到一个输出矩阵，无论输入$X$的通道数量。\n",
    "\n",
    "<img src=\"images/10_20.png\" style=\"width:300px;\"/>\n",
    "\n",
    "一般来说，一个卷积核只能完成某种逻辑的特征提取，当需要同时提取多种逻辑特征时，可以通过增加多个卷积核来得到多种特征，提高神经网络的表达能力，这就是多通道输入、多卷积核的情况。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.2.3 多通道输入、多卷积核\n",
    "多通道输入、多卷积核是卷积神经网络中最为常见的形式。\n",
    "\n",
    "当出现多卷积核时，第$i$($i \\in n$，$n$为卷积核个数)个卷积核与输入$X$运算得到第$i$个输出矩阵(也称为输出张量$O$的通道$i$)，最后全部的输出矩阵在通道维度上进行拼接(Stack操作，创建输出通道数的新维度)，产生输出张量$O$，$O$包含了$n$个通道数。\n",
    "\n",
    "以3通道输入、2个卷积核的卷积层为例。第一个卷积核与输入$X$运算得到输出$O$的第一个通道，第二个卷积核与输入$X$运算得到输出$O$的第二个通道，如`图10.21`所示，输出的两个通道拼接在一起形成了最终输出$O$。每个卷积核的大小$k$、步长$s$、填充设定等都是统一设置，这样才能保证输出的每个通道大小一致，从而满足拼接的条件。\n",
    "\n",
    "<img src=\"images/10_21.png\" style=\"width:350px;\"/>\n",
    "\n",
    "### 10.2.4 步长\n",
    "在卷积运算中，如何控制感受野布置的密度呢？\n",
    "+ 对于信息密度较大的输入，如物体数量很多的图片，为了尽可能的少漏掉有用信息，在网络设计的时候希望能够较密集地布置感受野窗口\n",
    "+ 对于信息密度较小的输入，比如全是海洋的图片，可以适量的减少感受野窗口的数量\n",
    "\n",
    "感受野密度的控制手段一般是通过移动步长(Strides)实现的。`图10.22`中感受野沿$x$方向的步长为：\n",
    "\n",
    "<img src=\"images/10_22.png\" style=\"width:500px;\"/>\n",
    "\n",
    "当感受野移动至输入$X$右边的边界时，感受野向下移动一个步长$s = 2$，并回到行首：\n",
    "\n",
    "<img src=\"images/10_23.png\" style=\"width:500px;\"/>\n",
    "\n",
    "循环往复移动，直至达到最下方、最右边边缘位置，如`图10.24`所示，最终卷积层输出的高宽只有$2\\times2$，输出高宽由$3\\times3$降低为$2\\times2$，感受野的数量减少为4个。\n",
    "\n",
    "<img src=\"images/10_24.png\" style=\"width:500px;\"/>\n",
    "\n",
    "可以看到，通过设定步长$s$，可以有效地控制信息密度的提取：\n",
    "+ 当步长设计的较小时，感受野以较小幅度移动窗口，有利于提取到更多的特征信息，输出张量的尺寸也更大\n",
    "+ 当步长设计的较大时，感受野以较大幅度移动窗口，有利于减少计算代价，过滤冗余信息，输出张量的尺寸也更小\n",
    "\n",
    "### 10.2.5 填充\n",
    "经过卷积运算后的输出$O$的高宽一般会小于输入$X$的高宽。在网络模型设计时，有时希望输出$O$的高宽能够与输入$X$的高宽相同，从而方便网络参数的设计、残差连接等。一般的做法是通过在原输入$X$的高和宽维度上面进行填充(Padding)若干无效元素操作，得到增大的输入$X'$。通过精心设计填充单元的数量，在$X'$上面进行卷积运算得到输出$O$的高宽可以和原输入$X$相等，甚至更大。\n",
    "\n",
    "`图10.25`中通过填充得到新的输入`𝑿'`：\n",
    "\n",
    "<img src=\"images/10_25.png\" style=\"width:500px;\"/>\n",
    "\n",
    "填充后的输入通过$3\\times3$的卷积核得到$5\\times5$的输出：\n",
    "\n",
    "<img src=\"images/10_28.png\" style=\"width:500px;\"/>\n",
    "\n",
    "\n",
    "## 10.3 卷积层实现\n",
    "在`TensorFlow`中，既可以通过自定义权值的底层实现方式搭建神经网络，也可以直接调用现成的卷积层类的高层方式快速搭建复杂网络。\n",
    "\n",
    "### 10.3.1 自定义权值\n",
    "在`TensorFlow`中，通过`tf.nn.conv2d`函数可以方便地实现2D卷积运算。`tf.nn.conv2d`基于输入$X:[b,h,w,c_{in}]$和卷积核$W:[k,k,c_{in},c_{out}]$进行卷积运算，得到输出$O:[b,h',w',c_{out}]$，其中$c_{in}$表示输入通道数，$c_{out}$表示卷积核的数量，也是输出特征图的通道数。\n",
    "\n",
    "例如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 3, 3, 4])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 模拟输入，3通道，高宽为5\n",
    "x = tf.random.normal([2,5,5,3]) \n",
    "# 需要根据[k,k,cin,cout]格式创建W张量\n",
    "w = tf.random.normal([3,3,3,4])\n",
    "# 步长为1, padding为0,\n",
    "out = tf.nn.conv2d(x,w,strides=1,padding=[[0,0],[0,0],[0,0],[0,0]])\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "设置一下`padding`，`padding`参数的设置格式为：`padding=[[0,0],[上,下],[左,右],[0,0]]`："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 5, 5, 4])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 模拟输入，3通道，高宽为5\n",
    "x = tf.random.normal([2,5,5,3]) \n",
    "# 需要根据[k,k,cin,cout]格式创建W张量\n",
    "w = tf.random.normal([3,3,3,4])\n",
    "out = tf.nn.conv2d(x,w,strides=1,padding=[[0,0],[1,1],[1,1],[0,0]])\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "特别地，通过设置参数`padding='SAME'、strides=1`可以直接得到输入、输出同大小的卷积层，`padding`的具体数量由`TensorFlow`自动计算并完成填充操作："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 5, 5, 4])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 模拟输入，3通道，高宽为5\n",
    "x = tf.random.normal([2,5,5,3]) \n",
    "# 需要根据[k,k,cin,cout]格式创建W张量\n",
    "w = tf.random.normal([3,3,3,4])\n",
    "out = tf.nn.conv2d(x,w,strides=1,padding='SAME')\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当$s\\gt1$时，设置`padding='SAME'`将使得输出高、宽将成$\\displaystyle\\frac{1}{s}$倍地减少："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 2, 2, 4])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 模拟输入，3通道，高宽为5\n",
    "x = tf.random.normal([2,5,5,3]) \n",
    "# 需要根据[k,k,cin,cout]格式创建W张量\n",
    "w = tf.random.normal([3,3,3,4])\n",
    "# 高宽先padding成可以整除3的最小整数6，然后6按3倍减少，得到2x2\n",
    "out = tf.nn.conv2d(x,w,strides=3,padding='SAME')\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "卷积神经网络层也可以设置网络带偏置向量。`tf.nn.conv2d`函数是没有实现偏置向量计算的，添加偏置需要手动累加偏置张量："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据[cout]格式创建偏置向量\n",
    "b = tf.zeros([4])\n",
    "# 在卷积输出上叠加偏置向量，它会自动broadcasting为[b,h',w',cout]\n",
    "out = out + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.3.2 卷积层类\n",
    "通过卷积层类`layers.Conv2D`可以不需要手动定义卷积核$W$和偏置$b$张量，直接调用类实例即可完成卷积层的前向计算。\n",
    "\n",
    "> 在`TensorFlow`中，首字母大写的对象一般表示类，全部小写的一般表示函数，如`layers.Conv2D`表示卷积层类，`nn.conv2d`表示卷积运算函数\n",
    "\n",
    "在新建卷积层类时，需要指定卷积核数量参数`filters`，卷积核大小`kernel_size`，步长`strides`，填充`padding`等："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = layers.Conv2D(4,kernel_size=3,strides=1,padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果卷积核高宽不等，步长行列方向不等，参数需要使用`tuple`类型指定："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = layers.Conv2D(4,kernel_size=(3,4),strides=(2,1),padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建完成后，通过调用实例(的`__call__`方法)即可完成前向计算："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 5, 5, 4])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = layers.Conv2D(4,kernel_size=3,strides=1,padding='SAME')\n",
    "out = layer(x) \n",
    "out.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在类`Conv2D`中，保存了卷积核张量$W$和偏置$b$，可以通过类成员`trainable_variables`访问："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d_2/kernel:0 (3, 3, 3, 4) <dtype: 'float32'>\n",
      "conv2d_2/bias:0 (4,) <dtype: 'float32'>\n"
     ]
    }
   ],
   "source": [
    "for v in layer.trainable_variables:\n",
    "    print(v.name, v.shape, v.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "也可以直接调用类实例`layer.kernel`、`layer.bias`访问$W$和$b$张量："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('conv2d_2/kernel:0', TensorShape([3, 3, 3, 4]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer.kernel.name, layer.kernel.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.4 LeNet-5 实战\n",
    "1990年代，`Yann LeCun`等人提出了用于手写数字和机器打印字符图片识别的神经网络，被命名为`LeNet-5`，网络结构如`图10.30`：\n",
    "\n",
    "<img src=\"images/10_30.png\" style=\"width:600px;\"/>\n",
    "\n",
    "它接受$32\\times32$大小的数字、字符图片，经过第一个卷积层得到$28\\times28$形状的张量，经过一个向下采样层，张量尺寸缩小到$[b,14,14,6]$，经过第二个卷积层，得到形状$[b,10,10,16]$的张量，同样经过下采样层，张量尺寸缩小到$[b,5,5,16]$，在进入全连接层之前，先将张量打成$[b,400]$的张量，送入输出节点数分别为120、84的2个全连接层，得到$[b,84]$的张量，最后通过`Gaussian connections`层。\n",
    "\n",
    "我们在`LeNet-5`的基础上进行了少许调整，使得它更容易在现代深度学习框架上实现。首先我们将输入$X$形状调整为$28\\times28$，然后将2个下采样层实现为`最大池化层`，最后利用`全连接层`替换掉`Gaussian connections层`。下文统一称修改的网络也为`LeNet-5`网络：\n",
    "\n",
    "<img src=\"images/10_31.png\" style=\"width:500px;\"/>\n",
    "\n",
    "我们基于`MNIST`手写数字图片数据集训练`LeNet-5`网络："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            multiple                  60        \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) multiple                  0         \n",
      "_________________________________________________________________\n",
      "re_lu (ReLU)                 multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            multiple                  880       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 multiple                  0         \n",
      "_________________________________________________________________\n",
      "re_lu_1 (ReLU)               multiple                  0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              multiple                  48120     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              multiple                  10164     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              multiple                  850       \n",
      "=================================================================\n",
      "Total params: 60,074\n",
      "Trainable params: 60,074\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "network = Sequential([\n",
    "    layers.Conv2D(6,kernel_size=3,strides=1), # 第一个卷积层, 6个3x3卷积核\n",
    "    layers.MaxPooling2D(pool_size=2,strides=2), # 高宽各减半的池化层\n",
    "    layers.ReLU(), # 激活函数\n",
    "    layers.Conv2D(16,kernel_size=3,strides=1), # 第二个卷积层, 16个3x3卷积核\n",
    "    layers.MaxPooling2D(pool_size=2,strides=2), # 高宽各减半的池化层\n",
    "    layers.ReLU(), # 激活函数\n",
    "    layers.Flatten(), # 打平层，方便全连接层处理\n",
    "    layers.Dense(120, activation='relu'), # 全连接层，120个节点\n",
    "    layers.Dense(84, activation='relu'), # 全连接层，84个节点\n",
    "    layers.Dense(10) # 全连接层，10个节点\n",
    "])\n",
    "\n",
    "# build一次网络模型，给输入X的形状，其中4为随意给的 batchsz\n",
    "network.build(input_shape=(4, 28, 28, 1))\n",
    "network.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "卷积层的参数量非常少，主要的参数量集中在全连接层，而`10.1节`的全连接网络参数量达到了34万个，因此通过卷积神经网络可以显著降低网络参数量，同时增加网络深度。\n",
    "\n",
    "在训练阶段，首先将输入$X$增加一个维度，即调整`shape`为$[b,28,28,1]$，送入模型进行前向计算，得到输出张量`output`的`shape`为$[b,10]$。我们新建`交叉熵损失函数`类来定义损失函数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建损失函数的类，在实际计算时直接调用类实例即可\n",
    "# 通过设定`from_logits=True`将`softmax`激活函数实现在损失函数中，\n",
    "# 不需要手动添加损失函数，提升数值计算稳定性\n",
    "criteon = losses.CategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 0 , loss:  0.04207484424114227\n",
      "# 1000 , loss:  0.15341603755950928\n",
      "# 2000 , loss:  0.042185381054878235\n",
      "# 3000 , loss:  0.03214021399617195\n",
      "# 4000 , loss:  0.07692582905292511\n",
      "# 5000 , loss:  0.021433787420392036\n",
      "# 6000 , loss:  0.026960991322994232\n",
      "# 7000 , loss:  0.0038292957469820976\n",
      "# 8000 , loss:  0.024503866210579872\n",
      "# 9000 , loss:  0.06588927656412125\n",
      "# 10000 , loss:  0.043183520436286926\n",
      "# 11000 , loss:  0.016418201848864555\n",
      "# 12000 , loss:  0.0035218519624322653\n",
      "# 13000 , loss:  0.021439535543322563\n",
      "# 14000 , loss:  0.09355004131793976\n",
      "# 15000 , loss:  0.011912934482097626\n",
      "# 16000 , loss:  0.046345874667167664\n",
      "# 17000 , loss:  0.026961183175444603\n",
      "# 18000 , loss:  0.027369201183319092\n"
     ]
    }
   ],
   "source": [
    "(xs, ys), (xt, yt) = mnist.load_data()\n",
    "xs = tf.convert_to_tensor(xs, dtype=tf.float32) / 255.\n",
    "db = tf.data.Dataset.from_tensor_slices((xs, ys))\n",
    "db = db.batch(32).repeat(10)\n",
    "\n",
    "xt = tf.convert_to_tensor(xt, dtype=tf.float32) / 255.\n",
    "dbtest = tf.data.Dataset.from_tensor_slices((xt, yt))\n",
    "dbtest = dbtest.batch(32)\n",
    "\n",
    "optimizer = optimizers.SGD(lr=0.01)\n",
    "# acc_meter = metrics.Accuracy()\n",
    "\n",
    "for step, (x,y) in enumerate(db):\n",
    "    # 构建梯度记录环境\n",
    "    with tf.GradientTape() as tape: \n",
    "        # 插入通道维度，=>[b,28,28,1]\n",
    "        x = tf.expand_dims(x,axis=3)\n",
    "        # 前向计算，获得10类别的预测分布，[b, 784] => [b, 10]\n",
    "        out = network(x)\n",
    "        # 真实标签one-hot编码，[b] => [b, 10]\n",
    "        y_onehot = tf.one_hot(y, depth=10)\n",
    "        # 计算交叉熵损失函数，标量\n",
    "        loss = criteon(y_onehot, out)\n",
    "    # 自动计算梯度\n",
    "    grads = tape.gradient(loss, network.trainable_variables)\n",
    "    # 自动更新参数\n",
    "    optimizer.apply_gradients(zip(grads, network.trainable_variables))\n",
    "    # 打印状态\n",
    "    if step % 1000 == 0:\n",
    "        print(\"#\", step, ', loss: ', float(loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试阶段不需要记录梯度信息，因此不需要`tf.GradientTape() as tape`环境。前向计算得到的输出经过`softmax`函数后，代表了网络预测当前图片属于类别$i$的概率。通过`argmax`函数选取概率最大的元素所在的索引，作为当前图片的预测类别："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc: 0.9837\n"
     ]
    }
   ],
   "source": [
    "correct, total = 0,0\n",
    "for x,y in dbtest: # 遍历所有训练集样本\n",
    "    # 插入通道维度，=>[b,28,28,1]\n",
    "    x = tf.expand_dims(x,axis=3)\n",
    "    # 前向计算，获得10类别的预测分布，[b, 784] => [b, 10]\n",
    "    out = network(x)\n",
    "    # 真实的流程时先经过softmax，再argmax\n",
    "    # 但是由于softmax不改变元素的大小相对关系，故省去\n",
    "    pred = tf.argmax(out, axis=-1)  \n",
    "    y = tf.cast(y, tf.int64)\n",
    "    # 统计预测正确数量\n",
    "    correct += float(tf.reduce_sum(tf.cast(tf.equal(pred, y),tf.float32)))\n",
    "    # 统计预测样本总数\n",
    "    total += x.shape[0]\n",
    "# 计算准确率\n",
    "print('test acc:', correct/total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在数据集上面循环训练30个`Epoch`后，测试准确度达到了`97.7%`(*add by alex*我的测试结果更好)。对于非常简单的手写数字图片识别任务，古老的`LeNet-5`网络已经可以取得很好的效果，但是稍复杂一点的任务，比如彩色动物图片识别，`LeNet-5`性能就会急剧下降。\n",
    "\n",
    "\n",
    "## 10.5 表示学习\n",
    "研究人员发现网络层数越深，模型的表达能力越强，也就越有可能取得更好的性能。那么层层堆叠的卷积网络到底学到了什么特征，使得层数越深，网络的表达能力越强呢？\n",
    "\n",
    "2014年，`Matthew Zeiler`等人尝试利用可视化的方法去理解卷积神经网络到底学到了什么。通过将每层的特征图利用`反卷积`网络(Deconvolutional Network)映射回输入图片，即可查看学到的特征分布，如`图10.32`所示。可以观察到，第二层的特征对应到边、角、色彩等底层图像提取；第三层开始捕获到纹理这些中层特征；第四、五层呈现了物体的部分特征，如小狗的脸部、鸟类的脚部等高层特征。通过这些可视化的手段，我们可以一定程度上感受卷积神经网络的特征学习过程。\n",
    "\n",
    "<img src=\"images/10_32.png\" style=\"width:500px;\"/>\n",
    "\n",
    "图片数据的识别过程一般认为也是`表示学习`(Representation Learning)的过程，从接受到的原始像素特征开始，逐渐提取边缘、角点等底层特征，再到纹理等中层特征，再到头部、物体部件等高层特征，最后的网络层基于这些学习到的抽象特征表示(Representation)做分类逻辑的学习。学习到的特征越高层、越准确，就越有利于分类器的分类，从而获得较好的性能。\n",
    "\n",
    "从表示学习的角度来理解，卷积神经网络通过层层堆叠来逐层提取特征，网络训练的过程可以看成特征的学习过程，基于学习到的高层抽象特征可以方便地进行分类任务。\n",
    "\n",
    "应用表示学习的思想，训练好的卷积神经网络往往能够学习到较好的特征，这种特征的提取方法一般是通用的。比如在猫、狗任务上学习到头、脚、身躯等特征的表示，在其它动物上也能够一定程度上使用。基于这种思想，可以将在任务A上训练好的深层神经网络的前面数个特征提取层迁移到任务B上，只需要训练任务B的分类逻辑，即可取得非常好的效果，这种方式是迁移学习的一种，从神经网络角度也称为`网络微调`(Fine-tuning)。\n",
    "\n",
    "## 10.6 梯度传播\n",
    "对卷积神经网络的使用有了初步的了解后，现在我们来解决一个关键问题，卷积层通过移动感受野的方式实现离散卷积操作，那么它的梯度传播是怎么进行的呢？\n",
    "\n",
    "考虑一简单的情形，输入为$3\\times3$的单通道矩阵，与一个$2\\times2$的卷积核，进行卷积运算，输出结果打平后直接与虚构的标注计算误差，如`图10.33`所示。我们来讨论这种情况下的梯度更新方式。\n",
    "\n",
    "<img src=\"images/10_33.png\" style=\"width:500px;\"/>\n",
    "\n",
    "首先推导出输出张量$O$的表达形式：\n",
    "$$\\begin{matrix}\n",
    "o_{00} = x_{00}w_{00} + x_{01}w_{01} + x_{10}w_{10} + x_{11}w_{11} + b \\\\\n",
    "o_{01} = x_{01}w_{00} + x_{02}w_{01} + x_{11}w_{10} + x_{12}w_{11} + b \\\\\n",
    "o_{10} = x_{10}w_{00} + x_{11}w_{01} + x_{20}w_{10} + x_{21}w_{11} + b \\\\\n",
    "o_{11} = x_{11}w_{00} + x_{12}w_{01} + x_{21}w_{10} + x_{22}w_{11} + b \\\\\n",
    "\\end{matrix}$$\n",
    "\n",
    "以$w_{00}$的梯度计算为例，通过链式法则分解：\n",
    "+ $\\displaystyle\\frac{\\partial\\mathcal{L}}{\\partial w_{00}} = \\sum_{i\\in(00,01,10,11)}\\frac{\\partial\\mathcal{L}}{\\partial o_j}\\frac{\\partial o_j}{\\partial w_{00}}$\n",
    "\n",
    "其中，$\\displaystyle\\frac{\\partial\\mathcal{L}}{\\partial o_i}$可直接由误差函数推导出来，我们直接来考虑$\\displaystyle\\frac{\\partial o_j}{\\partial w_i}$，例如：\n",
    "+ $\\displaystyle\\frac{\\partial o_{00}}{\\partial w_{00}} = \\frac{\\partial(x_{00}w_{00} + x_{01}w_{01} + x_{10}w_{10} + x_{11}w_{11} + b)}{w_{00}} = x_{00}$\n",
    "\n",
    "同样的方法，可以推导出：\n",
    "+ $\\displaystyle\\frac{\\partial o_{01}}{\\partial w_{00}} = \\frac{\\partial(x_{01}w_{00} + x_{02}w_{01} + x_{11}w_{10} + x_{12}w_{11} + b)}{w_{00}} = x_{01}$\n",
    "+ $\\displaystyle\\frac{\\partial o_{01}}{\\partial w_{00}} = \\frac{\\partial(x_{10}w_{00} + x_{11}w_{01} + x_{20}w_{10} + x_{21}w_{11} + b)}{w_{00}} = x_{10}$\n",
    "+ $\\displaystyle\\frac{\\partial o_{01}}{\\partial w_{00}} = \\frac{\\partial(x_{11}w_{00} + x_{12}w_{01} + x_{21}w_{10} + x_{22}w_{11} + b)}{w_{00}} = x_{11}$\n",
    "\n",
    "可以观察到，通过循环移动感受野的方式并没有改变网络层可导性，同时梯度的推导也并不复杂，只是当网络层数增大以后，人工梯度推导将变得十分的繁琐。深度学习框架可以自动完成所有参数的梯度计算与更新，我们只需要设计好网络结构即可。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.7 池化层\n",
    "在卷积层中，可以通过调节步长参数$s$实现特征图的高宽成倍缩小，从而降低了网络的参数量。实际上，除了通过设置步长，还有一种专门的网络层可以实现尺寸缩减功能，即`池化层`(Pooling Layer)。\n",
    "\n",
    "池化层同样基于局部相关性的思想，通过从局部相关的一组元素中进行采样或信息聚合，从而得到新的元素值：\n",
    "+ **最大池化层**(Max Pooling)从局部相关元素集中选取最大的一个元素值\n",
    "+ **平均池化层**(Average Pooling)从局部相关元素集中计算平均值并返回\n",
    "\n",
    "以$5\\times5$输入$X$的最大池化层为例，考虑池化感受野窗口大小$k=2$，步长$s=1$的情况，如`图10.34`所示：\n",
    "\n",
    "<img src=\"images/10_34.png\" style=\"width:450px;\"/>\n",
    "\n",
    "循环往复，直至最下方、最右边，获得最大池化层的输出：\n",
    "\n",
    "<img src=\"images/10_35.png\" style=\"width:450px;\"/>\n",
    "\n",
    "由于池化层没有需要学习的参数，计算简单，并且可以有效减低特征图的尺寸，非常适合图片这种类型的数据。通过精心设计池化层感受野的高宽$k$和步长$s$参数，可以实现各种降维运算。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.8 BatchNorm层\n",
    "卷积神经网络的出现，网络参数量大大减低，使得几十层的深层网络成为可能。然而，网络的加深使得网络训练变得非常不稳定，甚至出现网络长时间不更新甚至不收敛的现象，同时网络对超参数比较敏感，超参数的微量扰动也会导致网络的训练轨迹完全改变。\n",
    "\n",
    "2015年，`Google`研究人员`Sergey Ioffe`等提出了一种`参数标准化`(Normalize)的手段，并基于参数标准化设计了`Batch Nomalization`(简写为`BatchNorm`，或`BN`)层。`BN层`的提出，使得网络的超参数的设定更加自由，比如更大的学习率、更随意的网络初始化等，同时网络的收敛速度更快，性能也更好。`BN层`提出后便广泛地应用在各种深度网络模型上，`卷积层`、`BN层`、`ReLU层`、`池化层`一度成为网络模型的标配单元块，通过堆叠`Conv-BN-ReLU-Pooling`方式往往可以获得不错的模型性能。\n",
    "\n",
    "为什么需要对网络中的数据进行标准化操作？这个问题很难从理论层面解释透彻，即使是`BN层`的作者给出的解释也未必让所有人信服。与其纠结其缘由，不如通过具体问题来感受数据标准化后的好处。\n",
    "\n",
    "考虑`Sigmoid`激活函数和它的梯度分布，如`图10.39`所示：\n",
    "\n",
    "<img src=\"images/10_39.png\" style=\"width:300px;\"/>\n",
    "\n",
    "`Sigmoid`函数在$x \\in [−2,2]$区间的导数值在$[0.1, 0.25]$区间分布；当$x \\gt 2$或$x \\lt −2$时，`Sigmoid`函数的导数逼近于0，从而容易出现`梯度弥散`现象。为了避免梯度弥散现象，将函数输入$x$标准化映射到0附近的一段较小区间将变得非常重要，可以从`图10.39` 看到。这是使用标准化手段受益的一个例子。\n",
    "\n",
    "再看一个例子。考虑 2 个输入节点的线性模型，如`图10.40(a)`所示：\n",
    "\n",
    "<img src=\"images/10_40.png\" style=\"width:500px;\"/>\n",
    "\n",
    "+ $\\mathcal{L} = a = x_1w_1+x_2w_2+b$\n",
    "\n",
    "讨论如下2种输入分布下的优化问题：\n",
    "+ 输入$x_1 \\in [1, 10]，x_2 \\in [1, 10]$\n",
    "+ 输入$x_1 \\in [1, 10]，x_2 \\in [100, 1000]$ \n",
    "\n",
    "由于模型相对简单，可以绘制出2种$x_1, x_2$下，函数的损失等高线图，`图10.40(b)`是$x_1 \\in [1, 10]，x_2 \\in [100, 1000]$时的某条优化轨迹线示意，`图10.40(c)`是$x_1 \\in [1, 10]，x_2 \\in [1, 10]$时的某条优化轨迹线示意，图中的圆环中心即为全局极值点。\n",
    "\n",
    "考虑到\n",
    "$$\\begin{matrix}\n",
    "\\displaystyle\\frac{\\partial\\mathcal{L}}{\\partial w_1} = x_1\\\\\n",
    "\\displaystyle\\frac{\\partial\\mathcal{L}}{\\partial w_2} = x_2\\\\\n",
    "\\end{matrix}$$\n",
    "\n",
    "+ 当$x_1, x_2$输入分布相近时，$\\frac{\\partial\\mathcal{L}}{\\partial w_1}, \\frac{\\partial\\mathcal{L}}{\\partial w_2}$偏导数值相当，函数的优化轨迹如`图10.40(c)`所示\n",
    "+ 当$x_1, x_2$输入分布差距较大时，某条可能的优化轨迹如`图10.40(b)`所示\n",
    "\n",
    "对比2条优化轨迹线可以观察到，$x_1, x_2$分布相近时损失函数收敛更加快速，优化轨迹更理想。\n",
    "\n",
    "通过上述例子我们能够经验性归纳出：网络层输入$x$分布相近，并且分布在较小范围内时(如0附近)，更有利于函数的优化。我们通过数据标准化实现此目的，即将数据$x$映射到$\\hat{x}$:\n",
    "+ $\\hat{x} = \\displaystyle\\frac{x-\\mu_r}{\\sqrt{\\sigma_{r}^2+\\epsilon}}$\n",
    "\n",
    "其中$\\mu_r、\\sigma_{r}^2$来自统计的所有数据的均值和方差，$\\epsilon$是为防止出现除0错误而设置的较小数字，如$1e−8$。\n",
    "\n",
    "在基于`Batch`的训练阶段，`Batch`内部的均值$\\mu_B$和$\\sigma_{B}^2$定义如下：\n",
    "$$\\begin{matrix}\n",
    "\\displaystyle\\mu_B = \\frac{1}{m}\\sum_{i=1}^{m}x_i\\\\\n",
    "\\displaystyle\\sigma_{B}^2 = \\frac{1}{m}\\sum_{i=1}^{m}(x_i-\\mu_B)^2\\\n",
    "\\end{matrix}$$\n",
    "\n",
    "其中，$m$为`Batch`中的样本数。\n",
    "\n",
    "因此，在训练阶段，通过\n",
    "+ $\\hat{x}_{\\mathrm{train}} = \\displaystyle\\frac{x_{\\mathrm{train}}-\\mu_{B}}{\\sqrt{\\sigma_{B}^2+\\epsilon}}$\n",
    "\n",
    "标准化输入，并记录每个`Batch`的统计数据$\\mu_B$和$\\sigma_{B}^2$，用于统计真实的全局$\\mu_r$和$\\sigma_{r}^2$。\n",
    "\n",
    "在测试阶段，根据记录的每个`Batch`的$\\mu_B$和$\\sigma_{B}^2$估计出所有训练数据的$\\mu_r$和$\\sigma_{r}^2$，按着\n",
    "+ $\\hat{x}_{\\mathrm{test}} = \\displaystyle\\frac{x_{\\mathrm{test}}-\\mu_{r}}{\\sqrt{\\sigma_{r}^2+\\epsilon}}$\n",
    "\n",
    "将每层的输入标准化。\n",
    "\n",
    "上述的标准化运算并没有引入额外的待优化变量，$\\mu_r、\\sigma_{r}^2$和$\\mu_B、\\sigma_{B}^2$均由统计得到，不需要参与梯度更新。实际上，为了提高`BN层`的表达能力，`BN层`作者引入了`scale and shift`技巧，将$\\hat{x}$变量再次映射变换：\n",
    "+ $\\widetilde{x} = \\hat{x}\\cdot\\lambda+\\beta$\n",
    "\n",
    "其中$\\lambda$实现对标准化后的$\\hat{x}$再次进行缩放，$\\beta$实现对标准化的$\\hat{x}$进行平移，不同的是，$\\lambda、\\beta$均由反向传播算法自动优化，实现网络层`按需`缩放平移数据的分布的目的。\n",
    "\n",
    "下面我们来学习在`TensorFlow`中实现的`BN层`的方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.8.1 前向传播\n",
    "我们分训练阶段和测试阶段来讨论前向传播过程。\n",
    "\n",
    "##### 训练阶段\n",
    "首先计算当前`Batch`的$\\mu_B、\\sigma_{B}^2$，根据\n",
    "+ $\\widetilde{x}_{\\mathrm{train}} = \\displaystyle\\frac{x_{\\mathrm{train}}-\\mu_{B}}{\\sqrt{\\sigma_{B}^2+\\epsilon}}\\cdot\\lambda+\\beta$\n",
    "\n",
    "计算`BN层`的输出。\n",
    "\n",
    "同时按照\n",
    "+ $\\mu_r \\gets \\mathrm{momentum}\\cdot\\mu_r + (1−\\mathrm{momentum})\\cdot\\mu_{B}$\n",
    "+ $\\sigma_{r}^2 \\gets \\mathrm{momentum}\\cdot\\sigma_{r}^2 + (1−\\mathrm{momentum})\\cdot\\sigma_{B}^2$\n",
    "\n",
    "迭代更新全局训练数据的统计值$\\mu_r$和$\\sigma_{r}^2$，其中$\\mathrm{momentum}$是超参数，用于平衡$\\mu_r$和$\\sigma_{r}^2$的更新幅度：\n",
    "+ 当$\\mathrm{momentum}=0$时，$\\mu_r$和$\\sigma_{r}^2$直接被设置为最新一个`Batch`的$\\mu_B$和$\\sigma_{B}^2$\n",
    "+ 当$\\mathrm{momentum}=1$时，$\\mu_r$和$\\sigma_{r}^2$保持不变，忽略最新一个`Batch`的$\\mu_B$和$\\sigma_{B}^2$\n",
    "\n",
    "在`TensorFlow`中，$\\mathrm{momentum}$默认设置为0.99。\n",
    "\n",
    "##### 测试阶段\n",
    "`BN层`根据\n",
    "+ $\\widetilde{x}_{\\mathrm{test}} = \\displaystyle\\frac{x_{\\mathrm{test}}-\\mu_{B}}{\\sqrt{\\sigma_{B}^2+\\epsilon}}\\cdot\\lambda+\\beta$\n",
    "\n",
    "计算输出$\\widetilde{x}_{\\mathrm{test}}$，其中$\\mu_r、\\sigma_{r}^2、\\lambda、\\beta$均来自训练阶段统计或优化的结果，在测试阶段直接使用，并不会更新这些参数。\n",
    "\n",
    "### 10.8.2 反向更新\n",
    "在训练模式下的反向更新阶段，反向传播算法根据损失$\\mathcal{L}$求解梯度$\\frac{\\partial\\mathcal{L}}{\\partial\\lambda}$和$\\frac{\\partial\\mathcal{L}}{\\partial\\beta}$，并按着梯度更新法则自动优化$\\lambda、\\beta$参数。\n",
    "\n",
    "需要注意的是，对于2D特征图输入$X:[b,h,w,c]$，`BN层`并不是计算每个点的$\\mu_B、\\sigma_{B}^2$，而是在通道轴$c$上面统计每个通道上面所有数据的$\\mu_B、\\sigma_{B}^2$，因此$\\mu_B、\\sigma_{B}^2$是每个通道上所有其它维度的均值和方差。以`shape`为$[100,32,32,3]$的输入为例，在通道轴$c$上面的均值计算如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([102400, 3]),\n",
       " <tf.Tensor: shape=(3,), dtype=float32, numpy=array([ 0.00345077,  0.0024313 , -0.00177814], dtype=float32)>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 构造输入\n",
    "x=tf.random.normal([100,32,32,3])\n",
    "# 将其他维度合并，仅保留通道维度\n",
    "x=tf.reshape(x,[-1,3])\n",
    "# 计算其他维度的均值\n",
    "ub=tf.reduce_mean(x,axis=0)\n",
    "x.shape, ub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据有$c$个通道数，因此有$c$个均值产生。\n",
    "\n",
    "除了在$c$轴上面统计数据$\\mu_B、\\sigma_{B}^2$的方式，我们也很容易将其推广至其它维度计算均值的方式，如`图10.41`所示：\n",
    "\n",
    "<img src=\"images/10_41.png\" style=\"width:500px;\"/>\n",
    "\n",
    "+ **Layer Norm**：统计每个样本的所有特征的均值和方差\n",
    "+ **Instance Norm**：统计每个样本的每个通道上特征的均值和方差\n",
    "+ **Group Norm**：将$c$通道分成若干组，统计每个样本的通道组内的特征均值和方差\n",
    "\n",
    "上面提到的`Normalization`方法均由独立的几篇论文提出，并在某些应用上验证了其相当或者优于`BatchNorm`算法的效果。由此可见，深度学习算法研究并非难于上青天，只要多思考、多锻炼算法工程能力，人人都有机会发表创新性成果。\n",
    "\n",
    "### 10.8.3 BN层实现\n",
    "`TensorFlow`中通过`layers.BatchNormalization()`类可以非常方便地实现`BN层`：\n",
    "\n",
    "```python\n",
    "# 创建BN层\n",
    "# BN层的训练阶段和测试阶段的行为不同，需要通过设置training标志位来区分训练模式还是测试模式\n",
    "layer=layers.BatchNormalization()\n",
    "```\n",
    "\n",
    "以`LeNet-5`的网络模型为例，在卷积层后添加`BN层`：\n",
    "\n",
    "```python\n",
    "network = Sequential([\n",
    "    layers.Conv2D(6,kernel_size=3,strides=1),\n",
    "    # 插入BN层\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=2,strides=2),\n",
    "    layers.ReLU(),\n",
    "    layers.Conv2D(16,kernel_size=3,strides=1),\n",
    "    # 插入BN层\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=2,strides=2),\n",
    "    layers.ReLU(),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(120, activation='relu'),\n",
    "    # 此处也可以插入BN层\n",
    "    layers.Dense(84, activation='relu'),\n",
    "    # 此处也可以插入BN层\n",
    "    layers.Dense(10)\n",
    "])\n",
    "```\n",
    "\n",
    "在训练阶段，需要设置网络的参数`training=True`以区分`BN层`是训练还是测试模型：\n",
    "\n",
    "```python\n",
    "with tf.GradientTape() as tape:\n",
    "    # 插入通道维度\n",
    "    x = tf.expand_dims(x,axis=3)\n",
    "    # 前向计算，设置计算模式，[b, 784] => [b, 10]\n",
    "    out = network(x, training=True)\n",
    "```\n",
    "\n",
    "在测试阶段，需要设置`training=False`，避免`BN层`采用错误的行为：\n",
    "\n",
    "```python\n",
    "for x,y in db_test: # 遍历测试集\n",
    "    # 插入通道维度\n",
    "    x = tf.expand_dims(x,axis=3)\n",
    "    # 前向计算，测试模式\n",
    "    out = network(x, training=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.9 经典卷积网络\n",
    "\n",
    "### 10.9.1 AlexNet\n",
    "2012年，`ILSVRC12`挑战赛`ImageNet`数据集分类任务的冠军`Alex Krizhevsky`提出了8层的深度神经网络模型`AlexNet`，它接收输入为$22\\times22$大小的彩色图片数据，经过五个卷积层和三个全连接层后得到样本属于1000个类别的概率分布。为了降低特征图的维度，`AlexNet`在第1、2、5个卷积层后添加了`MaxPooling`层，如`图10.43`所示：\n",
    "\n",
    "<img src=\"images/10_43.png\" style=\"width:600px;\"/>\n",
    "\n",
    "网络的参数量达到了6000万个。为了能够在当时的显卡设备`NVIDIA GTX 580`(3GB显存)上训练模型，`Alex Krizhevsky`将卷积层、前2个全连接层等拆开在两块显卡上面分别训练，最后一层合并到一张显卡上面，进行反向传播更新。`AlexNet`在`ImageNet`取得了`15.3%`的Top5错误率，比第二名在错误率上降低了`10.9%`。\n",
    "\n",
    "`AlexNet`的创新之处在于：\n",
    "+ 层数达到了较深的8层\n",
    "+ 采用了`ReLU`激活函数，过去的神经网络大多采用`Sigmoid`激活函数，计算相对复杂，容易出现梯度弥散现象\n",
    "+ 引入`Dropout`层，提高了模型的泛化能力，防止过拟合\n",
    "\n",
    "### 10.9.2 VGG系列\n",
    "2014年，`ILSVRC14`挑战赛`ImageNet`分类任务的亚军牛津大学`VGG`实验室提出了`VGG11、 VGG13、VGG16、VGG19`等一系列的网络模型。\n",
    "\n",
    "以`VGG16`为例，它接受$22\\times22$大小的彩色图片数据，经过2个`Conv-Conv-Pooling`单元，和3个`Conv-Conv-Conv-Pooling`单元的堆叠，最后通过3层全连接层输出当前图片分别属于1000类别的概率分布，如`图10.44`所示。`VGG16`在`ImageNet`取得了`7.4%`的Top5错误率，比`AlexNet`在错误率上降低了`7.9%`。\n",
    "\n",
    "<img src=\"images/10_44.png\" style=\"width:600px;\"/>\n",
    "\n",
    "`VGG`系列网络的创新之处在于：\n",
    "+ 层数提升至19层\n",
    "+ 全部采用更小的$3\\times3$卷积核，相对于`AlexNet`中的$7\\times7$卷积核，参数量更少，计算代价更低\n",
    "+ 采用更小的池化层$2\\times2$窗口和步长$s = 2$，而`AlexNet`中是步长$s=2$、$3\\times3$的池化窗口\n",
    "\n",
    "### 10.9.3 GoogLeNet\n",
    "$3\\times3$的卷积核参数量更少，计算代价更低，同时在性能表现上甚至更优越，因此业界开始探索卷积核最小的情况：$1\\times1$卷积核。如`图10.46`所示，输入为3通道的$5\\times5$图片，与单个$1\\times1$的卷积核进行卷积运算，每个通道的数据与对应通道的卷积核运算，得到3个通道的中间矩阵，对应位置相加得到最终的输出张量。\n",
    "\n",
    "<img src=\"images/10_46.png\" style=\"width:400px;\"/>\n",
    "\n",
    "对于输入`shape`为$[b,h,w,c_{in}]$，$1\\times1$卷积层的输出为$[b,h,w,c_{out}]$，其中$c_{in}$为输入数据的通道数，$c_{out}$为输出数据的通道数，也是$1\\times1$卷积核的数量。$1\\times1$卷积核的一个特别之处在于，它可以不改变特征图的宽高，而只对通道数$c$进行变换。\n",
    "\n",
    "2014年，`ILSVRC`挑战赛的冠军`Google`提出了大量采用$3\\times3$和$1\\times1$卷积核的网络模型：`GoogLeNet`，网络层数达到了22层。虽然`GoogLeNet`的层数远大于`AlexNet`，但是它的参数量却只有`AlexNet`的$\\frac{1}{12}$，同时性能也远好于`AlexNet`。在`ImageNet`数据集分类任务上取得了`6.7%`的Top5错误率，比`VGG16`在错误率上降低了`0.7%`。\n",
    "\n",
    "`GoogLeNet`网络采用模块化设计的思想，通过大量堆叠`Inception`模块，形成了复杂的网络结构，如`图10.47`所示：\n",
    "\n",
    "<img src=\"images/10_47.png\" style=\"width:300px;\"/>\n",
    "\n",
    "`Inception`模块的输入为$X$，通过4个子网络得到4个网络 输出，在通道轴上面进行拼接合并，形成`Inception`模块的输出。这4个子网络是：\n",
    "+ $1\\times1$卷积层\n",
    "+ $1\\times1$卷积层，再通过一个$3\\times3$卷积层\n",
    "+ $1\\times1$卷积层，再通过一个$5\\times5$卷积层\n",
    "+ $3\\times3$最大池化层，再通过$1\\times1$卷积层\n",
    "\n",
    "`GoogLeNet`的网络结构如`图10.48`所示，其中红色框中的网络结构即为`图10.47`的网络结构。\n",
    "\n",
    "<img src=\"images/10_48.png\" style=\"width:800px;\"/>\n",
    "\n",
    "\n",
    "## 10.10 CIFAR10与VGG13实战\n",
    "`CIFAR10`数据集包含了飞机、汽车、鸟、猫等共10大类物体的彩色图片，每个种类收集了6000张$32\\times32$大小图片，共6万张图片。其中5万张作为训练数据集，1万张作为测试数据集，如`图10.49`所示：\n",
    "\n",
    "<img src=\"images/10_49.png\" style=\"width:500px;\"/>\n",
    "\n",
    "下载数据集："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3) (50000,) (10000, 32, 32, 3) (10000,)\n",
      "sample: (128, 32, 32, 3) (128,) tf.Tensor(-1.0, shape=(), dtype=float32) tf.Tensor(1.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "def preprocess(x, y):\n",
    "    # [0~1]\n",
    "    x = 2*tf.cast(x, dtype=tf.float32) / 255.-1\n",
    "    y = tf.cast(y, dtype=tf.int32)\n",
    "    return x,y\n",
    "\n",
    "(x,y), (x_test,y_test) = datasets.cifar10.load_data()\n",
    "# 删除y的一个维度，[b,1] => [b]\n",
    "y = tf.squeeze(y, axis=1)\n",
    "y_test = tf.squeeze(y_test, axis=1)\n",
    "\n",
    "print(x.shape, y.shape, x_test.shape, y_test.shape)\n",
    "\n",
    "# 构建训练集对象，随机打乱，预处理，批量化\n",
    "train_db = tf.data.Dataset.from_tensor_slices((x,y))\n",
    "train_db = train_db.shuffle(1000).map(preprocess).batch(128)\n",
    "# 构建测试集对象，预处理，批量化\n",
    "test_db = tf.data.Dataset.from_tensor_slices((x_test,y_test))\n",
    "test_db = test_db.map(preprocess).batch(64)\n",
    "# 从训练集中采样一个Batch，并观察\n",
    "sample = next(iter(train_db))\n",
    "print('sample:', sample[0].shape, sample[1].shape, tf.reduce_min(sample[0]), tf.reduce_max(sample[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`CIFAR10`图片识别任务并不简单，图片内容需要大量细节才能呈现，而保存的图片分辨率仅有$32\\times32$，使得部分主体信息较为模糊，甚至人眼都很难分辨。浅层的神经网络表达能力有限，很难训练优化到较好的性能，本节将基于`VGG13`网络，并根据我们的数据集特点修改部分网络结构，完成`CIFAR10`图片识别。修改如下：\n",
    "+ 将网络输入调整为$32\\times32$。原网络输入为$224\\times224$，导致全连接层输入特征维度过大，网络参数量过大\n",
    "+ 3个全连接层的维度调整为$[256,64,10]$，满足10分类任务的设定\n",
    "\n",
    "`图10.50`是调整后的`VGG13`网络模型：\n",
    "\n",
    "<img src=\"images/10_50.png\" style=\"width:600px;\"/>\n",
    "\n",
    "我们将网络实现为2个子网络：`卷积子网络`和`全连接子网络`。卷积子网络由5个子模块构成，每个子模块包含了`Conv-Conv-MaxPooling`单元结构，代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layers = [ # 先创建包含多网络层的列表\n",
    "    # unit 1: 64个3x3卷积核, 输入输出同大小\n",
    "    layers.Conv2D(64, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\n",
    "    layers.Conv2D(64, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\n",
    "    layers.MaxPool2D(pool_size=[2, 2], strides=2, padding='same'),\n",
    "    # unit 2: 输出通道提升至128，高宽大小减半\n",
    "    layers.Conv2D(128, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\n",
    "    layers.Conv2D(128, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\n",
    "    layers.MaxPool2D(pool_size=[2, 2], strides=2, padding='same'),\n",
    "    # unit 3: 输出通道提升至256，高宽大小减半\n",
    "    layers.Conv2D(256, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\n",
    "    layers.Conv2D(256, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\n",
    "    layers.MaxPool2D(pool_size=[2, 2], strides=2, padding='same'),\n",
    "    # unit 4: 输出通道提升至512，高宽大小减半\n",
    "    layers.Conv2D(512, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\n",
    "    layers.Conv2D(512, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\n",
    "    layers.MaxPool2D(pool_size=[2, 2], strides=2, padding='same'),\n",
    "    # unit 5: 输出通道提升至512，高宽大小减半\n",
    "    layers.Conv2D(512, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\n",
    "    layers.Conv2D(512, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\n",
    "    layers.MaxPool2D(pool_size=[2, 2], strides=2, padding='same')\n",
    "]\n",
    "\n",
    "# 利用前面创建的层列表构建网络容器\n",
    "conv_net = Sequential(conv_layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "全连接子网络包含了3个全连接层，每层添加`ReLU`非线性激活函数，最后一层除外："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            multiple                  1792      \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            multiple                  36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            multiple                  73856     \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           multiple                  147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           multiple                  295168    \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           multiple                  590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           multiple                  1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           multiple                  2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           multiple                  2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           multiple                  2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 multiple                  0         \n",
      "=================================================================\n",
      "Total params: 9,404,992\n",
      "Trainable params: 9,404,992\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 创建3层全连接层子网络\n",
    "fc_net = Sequential([\n",
    "    layers.Dense(256, activation=tf.nn.relu),\n",
    "    layers.Dense(128, activation=tf.nn.relu),\n",
    "    layers.Dense(10, activation=None),\n",
    "])\n",
    "\n",
    "# 子网络创建完成后，通过如下代码查看网络的参数量\n",
    "conv_net.build(input_shape=[None, 32, 32, 3])\n",
    "fc_net.build(input_shape=[None, 512])\n",
    "conv_net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_16 (Dense)             multiple                  131328    \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             multiple                  32896     \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             multiple                  1290      \n",
      "=================================================================\n",
      "Total params: 165,514\n",
      "Trainable params: 165,514\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "fc_net.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "网络总参数量约为950万个，相比于原始版本的`VGG13`参数量减少了很多。\n",
    "\n",
    "由于我们将网络实现为2个子网络，在进行梯度更新时，需要合并2个子网络的待优化参数列表："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [1, 2] + [3, 4] => [1, 2, 3, 4]\n",
    "variables = conv_net.trainable_variables + fc_net.trainable_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "开始训练模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optimizers.Adam(lr=1e-4)\n",
    "\n",
    "for epoch in range(50):\n",
    "    for step, (x,y) in enumerate(train_db):\n",
    "        with tf.GradientTape() as tape:\n",
    "            # [b, 32, 32, 3] => [b, 1, 1, 512]\n",
    "            out = conv_net(x)\n",
    "            # flatten, => [b, 512]\n",
    "            out = tf.reshape(out, [-1, 512])\n",
    "            # [b, 512] => [b, 10]\n",
    "            logits = fc_net(out)\n",
    "            # [b] => [b, 10]\n",
    "            y_onehot = tf.one_hot(y, depth=10)\n",
    "            # compute loss\n",
    "            loss = tf.losses.categorical_crossentropy(y_onehot, logits, from_logits=True)\n",
    "            loss = tf.reduce_mean(loss)\n",
    "        grads = tape.gradient(loss, variables)\n",
    "        optimizer.apply_gradients(zip(grads, variables))\n",
    "\n",
    "        if step %100 == 0:\n",
    "            print(epoch, step, 'loss:', float(loss))\n",
    "\n",
    "    total_num = 0\n",
    "    total_correct = 0\n",
    "    for x,y in test_db:\n",
    "        out = conv_net(x)\n",
    "        out = tf.reshape(out, [-1, 512])\n",
    "        logits = fc_net(out)\n",
    "        prob = tf.nn.softmax(logits, axis=1)\n",
    "        pred = tf.argmax(prob, axis=1)\n",
    "        pred = tf.cast(pred, dtype=tf.int32)\n",
    "        correct = tf.cast(tf.equal(pred, y), dtype=tf.int32)\n",
    "        correct = tf.reduce_sum(correct)\n",
    "        total_num += x.shape[0]\n",
    "        total_correct += int(correct)\n",
    "    acc = total_correct / total_num\n",
    "    print(epoch, 'acc:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.11 卷积层变种\n",
    "卷积神经网络的研究产生了各种各样优秀的网络模型，还提出了各种卷积层的变种，本节将重点介绍数种典型的卷积层变种。\n",
    "\n",
    "### 10.11.1 空洞卷积\n",
    "普通的卷积层为了减少网络的参数量，卷积核的设计通常选择较小的$1\\times1$和$3\\times3$感受野大小。小卷积核使得网络提取特征时的感受野区域有限，但是增大感受野的区域又会增加网络的参数量和计算代价，因此需要权衡设计。\n",
    "\n",
    "`空洞卷积`(Dilated/Atrous Convolution)的提出较好地解决这个问题，空洞卷积在普通卷积的感受野上增加一个`Dilation Rate`参数，用于控制感受野区域的采样步长，如`图10.51`所示：\n",
    "\n",
    "<img src=\"images/10_51.png\" style=\"width:500px;\"/>\n",
    "\n",
    "+ 当采样步长`Dilation Rate`为1时，每个感受野采样点之间的距离为1，此时的空洞卷积退化为普通的卷积\n",
    "+ 当`Dilation Rate`为2时，感受野每2个单元采样一个点，如`图10.51`中间的绿色方框中绿色格子所示，每个采样格子之间的距离为2\n",
    "+ 当`Dilation Rate`为3，采样步长为3\n",
    "\n",
    "尽管`Dilation Rate`的增大会使得感受野区域增大，但是实际参与运算的点数仍然保持不变。\n",
    "\n",
    "以输入为单通道的$7\\times7$张量，单个$3\\times3$卷积核为例，如`图10.52` 所示：\n",
    "\n",
    "<img src=\"images/10_52.png\" style=\"width:400px;\"/>\n",
    "\n",
    "在初始位置，感受野共采集9个数据点，这9个数据点与卷积核相乘运算，写入输出张量的对应位置。\n",
    "\n",
    "卷积核窗口按着步长为$s=1$向右移动一个单位，同样进行隔点采样，共采样9个数据点，与卷积核完成相乘累加运算，写入输出张量对应位置，直至卷积核移动至最下方、最右边位置。\n",
    "\n",
    "<img src=\"images/10_53.png\" style=\"width:400px;\"/>\n",
    "\n",
    "空洞卷积在不增加网络参数的条件下，提供了更大的感受野窗口。但是在使用空洞卷积设置网络模型时，需要精心设计`Dilation Rate`参数来避免出现网格效应，同时较大的`Dilation Rate`参数并不利于小物体的检测、语义分割等任务。\n",
    "\n",
    "`TensorFlow`通过设置`layers.Conv2D()`类的`dilation_rate`参数来选择使用普通卷积还是空洞卷积："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 3, 3, 1])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 模拟输入\n",
    "x = tf.random.normal([1,7,7,1]) \n",
    "# 空洞卷积，1个3x3的卷积核\n",
    "layer = layers.Conv2D(1,kernel_size=3,strides=1,dilation_rate=2)\n",
    "out = layer(x)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.11.2 转置卷积\n",
    "`转置卷积`(Transposed Convolution，部分资料也称之为反卷积/Deconvolution，实际上反卷积在数学上定义为卷积的逆过程，但转置卷积并不能恢复出原卷积的输入，因此称为反卷积并不妥当)通过在输入之间填充大量的`padding`来实现输出高宽大于输入高宽的效果，从而实现向上采样的目的，如`图10.54`所示。\n",
    "\n",
    "<img src=\"images/10_54.png\" style=\"width:450px;\"/>\n",
    "\n",
    "我们先介绍转置卷积的计算过程，再介绍转置卷积与普通卷积的联系。为了简化讨论，我们此处只讨论输入$h=w$，即输入高宽相等的情况。\n",
    "\n",
    "##### o+2p-k为s倍数\n",
    "考虑输入为$2\\times2$的单通道特征图，转置卷积核为$3\\times3$大小，步长$s=2$，填充$p=0$。首先在输入数据点之间均匀插入$s-1$个空白数据点，得到$3\\times3$的矩阵，如`图10.55`第2个矩阵所示，根据填充量在$3\\times3$矩阵周围填充相应$k-p-1=3−0=2$行/列，此时输入张量的高宽为$7\\times7$，如`图10.55`中第3个矩阵所示。\n",
    "\n",
    "<img src=\"images/10_55.png\" style=\"width:500px;\"/>\n",
    "\n",
    "在$7\\times7$的输入张量上，进行$3\\times3$卷积核，步长$s'=1$，填充$p=0$的普通卷积运算(注意，此阶段的普通卷积的步长$s'$始终为1，与转置卷积的步长$s$不同)，根据普通卷积的输出计算公式，得到输出大小为：\n",
    "+ $\\displaystyle o=\\big[\\frac{i+2*p-k}{s'}\\big]+1=\\big[\\frac{7+2*0-3}{1}\\big]+1=5$\n",
    "\n",
    "$5\\times5$大小的输出。我们直接按照此计算流程给出最终转置卷积输出与输入关系。在$o+2p-k$为$s$倍数时，满足关系\n",
    "+ $o = (i − 1)s + k − 2p$\n",
    "\n",
    "转置卷积并不是普通卷积的逆过程，但是二者之间有一定的联系，同时转置卷积也是基于普通卷积实现的。在相同的设定下，输入$x$经过普通卷积运算后得到$o=\\text{Conv}(x)$，我们将$o$送入转置卷积运算后，得到$x'=\\text{ConvTranspose}(o)$，其中$x'\\ne x$，但是$x'$与$x$形状相同。\n",
    "\n",
    "我们可以用输入为$5\\times5$，步长$s=2$，填充$p=0$，$3\\times3$卷积核的普通卷积运算进行验证演示，如`图10.56`所示：\n",
    "\n",
    "<img src=\"images/10_56.png\" style=\"width:400px;\"/>\n",
    "\n",
    "可以看到，将转置卷积的输出$x$在同设定条件下送入普通卷积，可以得到$2\\times2$的输出，此大小恰好就是转置卷积的输入大小，同时我们也观察到，输出的$2\\times2$矩阵并不是转置卷积输入的$2\\times2$矩阵。转置卷积与普通卷积并不是互为逆过程，不能恢复出对方的输入内容，仅能恢复出等大小的张量。因此称之为反卷积并不贴切。\n",
    "\n",
    "基于`TensorFlow`实现上述例子的转置卷积运算，代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 2, 2, 1])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建X矩阵，高宽为5x5\n",
    "x = tf.range(25)+1\n",
    "# Reshape为合法维度的张量\n",
    "x = tf.reshape(x,[1,5,5,1])\n",
    "x = tf.cast(x, tf.float32)\n",
    "# 创建固定内容的卷积核矩阵\n",
    "w = tf.constant([[-1,2,-3.],[4,-5,6],[-7,8,-9]])\n",
    "# 调整为合法维度的张量\n",
    "w = tf.expand_dims(w,axis=2)\n",
    "w = tf.expand_dims(w,axis=3)\n",
    "# 进行普通卷积运算\n",
    "out = tf.nn.conv2d(x,w,strides=2,padding='VALID')\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在我们将普通卷积的输出作为转置卷积的输入，验证转置卷积的输出是否为$5\\times5$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 5, 5, 1])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx = tf.nn.conv2d_transpose(out, w, strides=2, padding='VALID', output_shape=[1,5,5,1])\n",
    "xx.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到，转置卷积能够恢复出同大小的普通卷积的输入，但转置卷积的输出并不等同于普通卷积的输入。\n",
    "\n",
    "##### o+2p-k不为s倍数\n",
    "让我们更加深入地分析卷积运算中输入与输出大小关系的一个细节。考虑卷积运算的输出表达式：\n",
    "+ $\\displaystyle o=\\big[\\frac{i+2*p-k}{s}\\big]+1$\n",
    "\n",
    "当步长$s\\gt1$时，$\\big[\\frac{i+2*p-k}{s}\\big]$向下取整运算使得出现多种不同输入尺寸$i$对应到相同的输出尺寸$o$上。举个例子，考虑输入大小为$6\\times6$，卷积核大小为$3\\times3$，步长为1的卷积运算，代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 2, 2, 1])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.random.normal([1,6,6,1])\n",
    "# 6x6的输入经过普通卷积\n",
    "out = tf.nn.conv2d(x,w,strides=2,padding='VALID')\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此种情况也能获得$2\\times$大小的卷积输出，与`图10.56`中可以获得相同大小的输出。因此，不同输入大小的卷积运算可能获得相同大小的输出。考虑到卷积与转置卷积输入输出大小关系互换，从转置卷积的角度来说，输入尺寸$i$经过转置卷积运算后，可能获得不同的输出$o$大小。因此通过在`图10.55`中填充$a$行、$a$列来实现不同大小的输出$o$，从而恢复普通卷积不同大小的输入的情况，其中$a$关系为：\n",
    "+ $a = (o+2p-k)%s$\n",
    "\n",
    "此时转置卷积的输出变为：\n",
    "+ $o = (i−1)s+k−2p+a$\n",
    "\n",
    "`TensorFlow`不需要手动指定$a$参数，只需要指定输出尺寸即可，`TensorFlow`会自动推导需要填充的行列数$a$，前提是输出尺寸合法。例如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 6, 6, 1])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx = tf.nn.conv2d_transpose(out, w, strides=2, padding='VALID', output_shape=[1,6,6,1])\n",
    "xx.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 矩阵角度\n",
    "转置卷积的转置是指卷积核矩阵$W$产生的稀疏矩阵$W'$在计算过程中需要先转置${W'}^T$，再进行矩阵相乘运算。这也是它被称为转置卷积的名字由来。\n",
    "\n",
    "考虑普通`Conv2d`运算：$X$和$W$，需要根据`strides`将卷积核在行、列方向循环移动串行计算每个窗口处的“相乘累加”值，计算效率极低。为了加速运算，在数学上可以将卷积核$W$根据`strides`重排成稀疏矩阵$W'$，再通过$W'@X'$一次完成运算(实际上，$W'$矩阵过于稀疏，导致很多无用的0乘运算，很多深度学习框架也不是通过这种方式实现的)。\n",
    "\n",
    "以$4\\times4$的输入$X$为例，卷积核高宽为$3\\times3$，步长为1，无`padding`。首先将$X$打平成$X'$，如`图10.57`所示。\n",
    "\n",
    "<img src=\"images/10_57.png\" style=\"width:450px;\"/>\n",
    "\n",
    "然后将卷积核$W$转换成稀疏矩阵$W'$，如`图10.58`所示。\n",
    "\n",
    "<img src=\"images/10_58.png\" style=\"width:450px;\"/>\n",
    "\n",
    "此时通过一次矩阵相乘即可实现普通卷积运算：\n",
    "+ $O'=W'@X'$\n",
    "\n",
    "如果给定$O$，希望能够生成与$X$同形状大小的张量，怎么实现呢？将$W'$转置后与`图10.57`方法重排后的$O'$完成矩阵相乘即可：\n",
    "+ $O'={W'}^T@X'$\n",
    "\n",
    "得到的$X'$通过`Reshape`操作变为与原来的输入$X$尺寸一致，但是内容不同。例如$O'$的`shape`为$[4,1]$，${W'}^T$的`shape`为$[16,4]$，矩阵相乘得到$X'$的`shape`为$[4,4]$，`Reshape`后即可产生$[4,4]$形状的张量。由于转置卷积在矩阵运算时，需要将$W'$转置后才能与转置卷积的输入$O'$矩阵相乘，故称为转置卷积。\n",
    "\n",
    "转置卷积具有“放大特征图”的功能，在生成对抗网络、语义分割等中得到了广泛应用，如`DCGAN`中的生成器通过堆叠转置卷积层实现逐层“放大”特征图，最后获得十分逼真的生成图片。\n",
    "\n",
    "<img src=\"images/10_59.png\" style=\"width:600px;\"/>\n",
    "\n",
    "##### 转置卷积实现\n",
    "`TensorFlow`通过`nn.conv2d_transpose`实现转置卷积运算。我们先通过`nn.conv2d`完成普通卷积运算。注意转置卷积的卷积核的定义格式为$[k,k,c_{out},c_{in}]$。例如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2, 2, 1), dtype=float32, numpy=\n",
       "array([[[[-56.],\n",
       "         [-61.]],\n",
       "\n",
       "        [[-76.],\n",
       "         [-81.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建4x4大小的输入\n",
    "x = tf.range(16)+1\n",
    "x = tf.reshape(x,[1,4,4,1])\n",
    "x = tf.cast(x, tf.float32)\n",
    "# 创建3x3卷积核\n",
    "w = tf.constant([[-1,2,-3.],[4,-5,6],[-7,8,-9]])\n",
    "w = tf.expand_dims(w,axis=2)\n",
    "w = tf.expand_dims(w,axis=3)\n",
    "# 普通卷积运算\n",
    "out = tf.nn.conv2d(x,w,strides=1,padding='VALID')\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在保持`strides=1，padding='VALID'`，卷积核不变的情况下，我们通过卷积核$w$与输出$\\text{out}$的转置卷积运算尝试恢复与输入$x$相同大小的高宽张量："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 4), dtype=float32, numpy=\n",
       "array([[  56.,  -51.,   46.,  183.],\n",
       "       [-148.,  -35.,   35., -123.],\n",
       "       [  88.,   35.,  -35.,   63.],\n",
       "       [ 532.,  -41.,   36.,  729.]], dtype=float32)>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx = tf.nn.conv2d_transpose(out, w, strides=1, padding='VALID', output_shape=[1,4,4,1])\n",
    "tf.squeeze(xx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到，转置卷积生成了$4\\times4$的特征图，但特征图的数据与输入$x$并不相同。\n",
    "\n",
    "在使用`tf.nn.conv2d_transpose`进行转置卷积运算时，需要手动设置输出的高宽。`tf.nn.conv2d_transpose`并不支持自定义`padding`设置，只能设置为`VALID`或者`SAME`：\n",
    "+ 当设置`padding='VALID'`时，输出大小表达为：$o = (i−1)s+k$\n",
    "+ 当设置`padding='SAME'`时，输出大小表达为：$o = i\\cdot s$\n",
    "\n",
    "转置卷积也可以和其他层一样，通过`layers.Conv2DTranspose`类创建一个转置卷积层，然后调用实例即可完成前向计算："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 4, 4, 1), dtype=float32, numpy=\n",
       "array([[[[ -3.0053358],\n",
       "         [  6.567172 ],\n",
       "         [ -6.5922136],\n",
       "         [-18.85739  ]],\n",
       "\n",
       "        [[  4.4244685],\n",
       "         [-12.43082  ],\n",
       "         [-51.6935   ],\n",
       "         [-34.833168 ]],\n",
       "\n",
       "        [[  6.637212 ],\n",
       "         [-64.02243  ],\n",
       "         [-87.75142  ],\n",
       "         [-12.143947 ]],\n",
       "\n",
       "        [[ -6.653749 ],\n",
       "         [-46.875683 ],\n",
       "         [-41.330204 ],\n",
       "         [  1.1418453]]]], dtype=float32)>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建转置卷积类\n",
    "layer = layers.Conv2DTranspose(1,kernel_size=3,strides=1,padding='VALID')\n",
    "# 通过转置卷积层\n",
    "xx2 = layer(out) \n",
    "xx2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.11.3 分离卷积\n",
    "本节以`深度可分离卷积`(Depth-wise Separable Convolution)为例。普通卷积在对多通道输入进行运算时，卷积核的每个通道与输入的每个通道分别进行卷积运算，得到多通道的特征图，再对应元素相加产生单个卷积核的最终输出，如`图10.60`所示。\n",
    "\n",
    "<img src=\"images/10_60.png\" style=\"width:500px;\"/>\n",
    "\n",
    "分离卷积的计算流程则不同，卷积核的每个通道与输入的每个通道进行卷积运算，得到多个通道的中间特征，如`图10.61`所示。\n",
    "\n",
    "<img src=\"images/10_61.png\" style=\"width:500px;\"/>\n",
    "\n",
    "这个多通道的中间特征张量接下来进行多个$1\\times1$卷积核的普通卷积运算，得到多个高宽不变的输出，这些输出在通道轴上面进行拼接，从而产生最终的分离卷积层的输出。可以看到，分离卷积层包含了两步卷积运算，第一步卷积运算是单个卷积核，第二个卷积运算包含了多个卷积核。\n",
    "\n",
    "那么采用分离卷积有什么优势呢？一个很明显的优势在于，同样的输入和输出，采用`Separable Convolution`的参数量约是普通卷积的$\\frac{1}{3}$。考虑上图中的普通卷积和分离卷积的例子。普通卷积的参数量是$3\\times3\\times3\\times4=108$，分离卷积的第一部分参数量是$3\\times3\\times3\\times1=27$，第二部分参数量是$1\\times1\\times3\\times4=12$，分离卷积的总参数量只有39，但是却能实现普通卷积同样的输入输出尺寸变换。分离卷积在`Xception`和`MobileNets`等对计算代价敏感的领域中得到了大量应用。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.12 深度残差网络\n",
    "研究人员发现网络的层数越深，越有可能获得更好的泛化能力。但是当模型加深以后，网络变得越来越难训练，这主要是由于梯度弥散和梯度爆炸现象造成的。在较深层数的神经网络中，梯度信息由网络的末层逐层传向网络的首层时，传递的过程中会出现梯度接近于0或梯度值非常大的现象。网络层数越深，这种现象可能会越严重。\n",
    "\n",
    "那么怎么解决深层神经网络的梯度弥散和梯度爆炸现象呢？一个很自然的想法是，既然浅层神经网络不容易出现这些梯度现象，那么可以尝试给深层神经网络添加一种回退到浅层神经网络的机制。当深层神经网络可以轻松地回退到浅层神经网络时，深层神经网络可以获得与浅层神经网络相当的模型性能，而不至于更糟糕。\n",
    "\n",
    "通过在输入和输出之间添加一条直接连接的`Skip Connection`可以让神经网络具有回退的能力。以`VGG13`深度神经网络为例，假设观察到`VGG13`模型出现梯度弥散现象，而10层的网络模型并没有观测到梯度弥散现象，那么可以考虑在最后的两个卷积层添加`Skip Connection`，如`图10.62`所示。\n",
    "\n",
    "<img src=\"images/10_62.png\" style=\"width:600px;\"/>\n",
    "\n",
    "通过这种方式，网络模型可以自动选择是否经由这两个卷积层完成特征变换，还是直接跳过这两个卷积层而选择`Skip Connection`，亦或结合两个卷积层和`Skip Connection`的输出。\n",
    "\n",
    "2015年，`何凯明`等人发表了基于`Skip Connection`的`深度残差网络`(Residual Neural Network，简称`ResNet`)，并提出了18层、34层、50层、101层、152层的`ResNet-18`、`ResNet-34`、`ResNet-50`、`ResNet-101`和`ResNet-152`等模型，甚至成功训练出层数达到1202层的极深层神经网络。`ResNet`在`ILSVRC2015`挑战赛`ImageNet`数据集上的分类、检测等任务上面均获得了最好性能，`ResNet`论文至今已经获得超25000的引用量，可见`ResNet`在人工智能行业的影响力。\n",
    "\n",
    "### 10.12.1 ResNet原理\n",
    "`ResNet`通过在卷积层的输入和输出之间添加`Skip Connection`实现层数回退机制，如`图10.63`所示：\n",
    "\n",
    "<img src=\"images/10_63.png\" style=\"width:300px;\"/>\n",
    "\n",
    "输入$x$通过两个卷积层，得到特征变换后的输出$\\mathcal{F}(x)$，与输入$x$进行对应元素的相加运算，得到最终输出$\\mathcal{H}(x)$：\n",
    "+ $\\mathcal{H}(x) = \\mathcal{F}(x) + x$\n",
    "\n",
    "$\\mathcal{H}(x)$叫作`残差模块`(Residual Block，简称`ResBlock`)。由于被`Skip Connection`包围的卷积神经网络需要学习映射$\\mathcal{F}(x) = \\mathcal{H}(x)-x$，故称为`残差网络`。\n",
    "\n",
    "为了能够满足输入$x$与卷积层的输出$\\mathcal{F}(x)$能够相加运算，需要输入$x$的`shape`与$\\mathcal{F}(x)$的`shape`完全一致。当出现`shape`不一致时，一般通过在`Skip Connection`上添加额外的卷积运算环节将输入$x$变换到与$\\mathcal{F}(x)$相同的`shape`，如`图10.63`中$\\text{identity}(x)$函数所示。\n",
    "\n",
    "`图10.64`对比了34层的深度残差网络、34层的普通深度网络以及19层的`VGG`网络结构。可以看到，深度残差网络通过堆叠残差模块，达到了较深的网络层数，从而获得了训练稳定、性能优越的深层网络模型。\n",
    "\n",
    "<img src=\"images/10_64.png\" style=\"width:600px;\"/>\n",
    "\n",
    "### 10.12.2 ResBlock实现\n",
    "深度残差网络并没有增加新的网络层类型，只是通过在输入和输出之间添加一条`Skip Connection`，因此并没有针对`ResNet`的底层实现。在`TensorFlow`中通过调用普通卷积层即可实现残差模块：\n",
    "\n",
    "```python\n",
    "class BasicBlock(layers.Layer):\n",
    "    # 残差模块\n",
    "    def __init__(self, filter_num, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        # 第一个卷积单元\n",
    "        self.conv1 = layers.Conv2D(filter_num, (3, 3), strides=stride, padding='same')\n",
    "        self.bn1 = layers.BatchNormalization()\n",
    "        self.relu = layers.Activation('relu')\n",
    "        # 第二个卷积单元\n",
    "        self.conv2 = layers.Conv2D(filter_num, (3, 3), strides=1, padding='same')\n",
    "        self.bn2 = layers.BatchNormalization()\n",
    "        # Skip Connection的shape匹配\n",
    "        if stride != 1:# 通过1x1卷积完成shape匹配\n",
    "            self.downsample = Sequential()\n",
    "            self.downsample.add(layers.Conv2D(filter_num, (1, 1), strides=stride))\n",
    "        else:# shape匹配，直接短接\n",
    "            self.downsample = lambda x:x\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        # [b, h, w, c]，通过第一个卷积单元\n",
    "        out = self.conv1(inputs)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        # 通过第二个卷积单元\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        # 通过identity模块\n",
    "        identity = self.downsample(inputs)\n",
    "        # 2条路径输出直接相加\n",
    "        output = layers.add([out, identity])\n",
    "        output = tf.nn.relu(output) # 激活函数\n",
    "        return output\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.13 DenseNet\n",
    "`Skip Connection`的思想在`ResNet`上面获得了巨大的成功，研究人员开始尝试不同的`Skip Connection`方案，其中比较流行的就是`DenseNet`。`DenseNet`将前面所有层的特征图信息通过`Skip Connection`与当前层输出进行聚合，与`ResNet`的对应位置相加方式不同，`DenseNet`采用在通道轴$c$维度进行拼接操作，聚合特征信息。\n",
    "\n",
    "如`图10.65`所示：\n",
    "\n",
    "<img src=\"images/10_65.jpg\" style=\"width:500px;\"/>\n",
    "\n",
    "输入$X_0$通过$H_1$卷积层得到输出$X_1$，$X_1$与$X_0$在通道轴上进行拼接，得到聚合后的特征张量，送入$H_2$卷积层，得到输出$X_2$；同样的方法，$X_2$与前面所有层的特征信息$X_1$与$X_0$进行聚合，再送入下一层。如此循环，直至最后的输出。这样一种基于`Skip Connection`稠密连接的模块叫做`Dense Block`。\n",
    "\n",
    "`DenseNet`通过堆叠多个`Dense Block`构成复杂的深层神经网络，如`图10.66`所示。\n",
    "\n",
    "<img src=\"images/10_66.jpg\" style=\"width:800px;\"/>\n",
    "\n",
    "`图10.67`比较了不同版本的`DenseNet`的性能、`DenseNet`与`ResNet`的性能比较，以及`DenseNet`与`ResNet`训练曲线。\n",
    "\n",
    "<img src=\"images/10_67.png\" style=\"width:600px;\"/>\n",
    "\n",
    "## 10.14 CIFAR10与ResNet18实战\n",
    "标准的`ResNet18`接受输入为$22\\times22$大小的图片数据，我们将`ResNet18`进行适量调整，使得它输入大小为$32\\times32$，输出维度为10。调整后的`ResNet18`网络结构如`图10.68`所示。\n",
    "\n",
    "<img src=\"images/10_68.png\" style=\"width:600px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(layers.Layer):\n",
    "    # 残差模块\n",
    "    def __init__(self, filter_num, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        # 第一个卷积单元\n",
    "        self.conv1 = layers.Conv2D(filter_num, (3, 3), strides=stride, padding='same')\n",
    "        self.bn1 = layers.BatchNormalization()\n",
    "        self.relu = layers.Activation('relu')\n",
    "        # 第二个卷积单元\n",
    "        self.conv2 = layers.Conv2D(filter_num, (3, 3), strides=1, padding='same')\n",
    "        self.bn2 = layers.BatchNormalization()\n",
    "        # Skip Connection的shape匹配\n",
    "        if stride != 1:# 通过1x1卷积完成shape匹配\n",
    "            self.downsample = Sequential()\n",
    "            self.downsample.add(layers.Conv2D(filter_num, (1, 1), strides=stride))\n",
    "        else:# shape匹配，直接短接\n",
    "            self.downsample = lambda x:x\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        # [b, h, w, c]，通过第一个卷积单元\n",
    "        out = self.conv1(inputs)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        # 通过第二个卷积单元\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        # 通过identity模块\n",
    "        identity = self.downsample(inputs)\n",
    "        # 2条路径输出直接相加\n",
    "        output = layers.add([out, identity])\n",
    "        output = tf.nn.relu(output) # 激活函数\n",
    "        return output\n",
    "\n",
    "class ResNet(keras.Model):\n",
    "    # 通用的ResNet实现类\n",
    "    def __init__(self, layer_dims, num_classes=10): # [2, 2, 2, 2]\n",
    "        super(ResNet, self).__init__()\n",
    "        # 根网络，预处理\n",
    "        self.stem = Sequential([\n",
    "            layers.Conv2D(64, (3, 3), strides=(1, 1)),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Activation('relu'),\n",
    "            layers.MaxPool2D(pool_size=(2, 2), strides=(1, 1), padding='same')])\n",
    "        # 堆叠4个Block，每个block包含了多个BasicBlock,设置步长不一样\n",
    "        self.layer1 = self.build_resblock(64,  layer_dims[0])\n",
    "        self.layer2 = self.build_resblock(128, layer_dims[1], stride=2)\n",
    "        self.layer3 = self.build_resblock(256, layer_dims[2], stride=2)\n",
    "        self.layer4 = self.build_resblock(512, layer_dims[3], stride=2)\n",
    "        # 通过Pooling层将高宽降低为1x1\n",
    "        self.avgpool = layers.GlobalAveragePooling2D()\n",
    "        # 最后连接一个全连接层分类\n",
    "        self.fc = layers.Dense(num_classes)\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        # 通过根网络\n",
    "        x = self.stem(inputs)\n",
    "        # 一次通过4个模块\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        # 通过池化层\n",
    "        x = self.avgpool(x)\n",
    "        # 通过全连接层\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "    def build_resblock(self, filter_num, blocks, stride=1):\n",
    "        # 辅助函数，堆叠filter_num个BasicBlock\n",
    "        res_blocks = Sequential()\n",
    "        # 只有第一个BasicBlock的步长可能不为1，实现下采样\n",
    "        res_blocks.add(BasicBlock(filter_num, stride))\n",
    "        #其他BasicBlock步长都为1\n",
    "        for _ in range(1, blocks):\n",
    "            res_blocks.add(BasicBlock(filter_num, stride=1))\n",
    "        return res_blocks\n",
    "\n",
    "def resnet18():\n",
    "    # 通过调整模块内部BasicBlock的数量和配置实现不同的ResNet\n",
    "    return ResNet([2, 2, 2, 2])\n",
    "\n",
    "def resnet34():\n",
    "     # 通过调整模块内部BasicBlock的数量和配置实现不同的ResNet\n",
    "    return ResNet([3, 4, 6, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
