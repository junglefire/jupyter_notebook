{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Introduction to Artificial Neural Networks with Keras\n",
    "Birds inspired us to fly, burdock plants inspired Velcro, and nature has inspired countless more inventions. It seems only logical, then, to look at the brain’s architecture for inspiration on how to build an intelligent machine. This is the logic that sparked artificial neural networks (`ANN`): an `ANN` is a Machine Learning model inspired by the networks of biological neurons found in our brains. However, although planes were inspired by birds, they don’t have to flap their wings. Similarly, `ANN` have gradually become quite different from their biological cousins. Some researchers even argue that we should drop the biological analogy altogether (e.g., by saying `units` rather than `neurons`), lest we restrict our creativity to biologically plausible systems.\n",
    "\n",
    "`ANN` are at the very core of Deep Learning. They are versatile, powerful, and scalable, making them ideal to tackle large and highly complex Machine Learning tasks such as classifying billions of images (e.g., Google Images), powering speech recognition services (e.g., Apple’s Siri), recommending the best videos to watch to hundreds of millions of users every day (e.g., YouTube), or learning to beat the world champion at the game of Go (DeepMind’s AlphaGo).\n",
    "\n",
    "The first part of this chapter introduces artificial neural networks, starting with a quick tour of the very first `ANN` architectures and leading up to Multilayer Perceptrons (`MLP`), which are heavily used today (other architectures will be explored in the next chapters). In the second part, we will look at how to implement neural networks using the popular `Keras` API. This is a beautifully designed and simple high-level API for building, training, evaluating, and running neural networks. But don’t be fooled by its simplicity: it is expressive and flexible enough to let you build a wide variety of neural network architectures. In fact, it will probably be sufficient for most of your use cases. And should you ever need extra flexibility, you can always write custom `Keras` components using its lower-level API, as we will see in `Chapter 12`.\n",
    "\n",
    "But first, let’s go back in time to see how artificial neural networks came to be!\n",
    "\n",
    "## 10.1 From Biological to Artificial Neurons\n",
    "Surprisingly, `ANN` have been around for quite a while: they were first introduced back in 1943 by the neurophysiologist Warren McCulloch and the mathematician Walter Pitts. In their landmark paper `A Logical Calculus of Ideas Immanent in Nervous Activity`, McCulloch and Pitts presented a simplified computational model of how biological neurons might work together in animal brains to perform complex computations using propositional logic. This was the first artificial neural network architecture. Since then many other architectures have been invented, as we will see.\n",
    "\n",
    "The early successes of `ANN` led to the widespread belief that we would soon be conversing with truly intelligent machines. When it became clear in the 1960s that this promise would go unfulfilled (at least for quite a while), funding flew elsewhere, and `ANN` entered a long winter. In the early 1980s, new architectures were invented and better training techniques were developed, sparking a revival of interest in connectionism (the study of neural networks). But progress was slow, and by the 1990s other powerful Machine Learning techniques were invented, such as `Support Vector Machines` (see `Chapter 5`). These techniques seemed to offer better results and stronger theoretical foundations than `ANN`, so once again the study of neural networks was put on hold.\n",
    "\n",
    "We are now witnessing yet another wave of interest in `ANN`. Will this wave die out like the previous ones did? Well, here are a few good reasons to believe that this time is different and that the renewed interest in `ANN` will have a much more profound impact on our lives:\n",
    "+ There is now a huge quantity of data available to train neural networks, and `ANN` frequently outperform other ML techniques on very large and complex problems.\n",
    "+ The tremendous increase in computing power since the 1990s now makes it possible to train large neural networks in a reasonable amount of time. This is in part due to Moore’s law (the number of components in integrated circuits has doubled about every 2 years over the last 50 years), but also thanks to the gaming industry, which has stimulated the production of powerful GPU cards by the millions. Moreover, cloud platforms have made this power accessible to everyone.\n",
    "+ The training algorithms have been improved. To be fair they are only slightly different from the ones used in the 1990s, but these relatively small tweaks have had a huge positive impact.\n",
    "+ Some theoretical limitations of `ANN` have turned out to be benign in practice. For example, many people thought that `ANN` training algorithms were doomed because they were likely to get stuck in local optima, but it turns out that this is rather rare in practice (and when it is the case, they are usually fairly close to the global optimum).\n",
    "+ `ANN` seem to have entered a virtuous circle of funding and progress. Amazing products based on `ANN` regularly make the headline news, which pulls more and more attention and funding toward them, resulting in more and more progress and even more amazing products.\n",
    "\n",
    "### 10.1.1 Biological Neurons\n",
    "Before we discuss artificial neurons, let’s take a quick look at a biological neuron (represented in `Figure 10-1`). It is an unusual-looking cell mostly found in animal brains. It’s composed of a cell body containing the nucleus and most of the cell’s complex components, many branching extensions called dendrites, plus one very long extension called the axon. The axon’s length may be just a few times longer than the cell body, or up to tens of thousands of times longer. Near its extremity the axon splits off into many branches called telodendria, and at the tip of these branches are minuscule structures called synaptic terminals (or simply synapses), which are connected to the dendrites or cell bodies of other neurons. 3 Biological neurons produce short electrical impulses called action potentials (APs, or just signals) which travel along the axons and make the synapses release chemical signals called neurotransmitters. When a neuron receives a sufficient amount of these neurotransmitters within a few milliseconds, it fires its own electrical impulses (actually, it depends on the neurotransmitters, as some of them inhibit the neuron from firing).\n",
    "\n",
    "<img src=\"images/10_01.png\" style=\"width:500px;\"/>\n",
    "\n",
    "Thus, individual biological neurons seem to behave in a rather simple way, but they are organized in a vast network of billions, with each neuron typically connected to thousands of other neurons. Highly complex computations can be performed by a network of fairly simple neurons, much like a complex anthill can emerge from the combined efforts of simple ants. The architecture of biological neural networks (`BNN`) is still the subject of active research, but some parts of the brain have been mapped, and it seems that neurons are often organized in consecutive layers, especially in the cerebral cortex (i.e., the outer layer of your brain), as shown in `Figure 10-2`.\n",
    "\n",
    "<img src=\"images/10_02.png\" style=\"width:500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.1.2 Logical Computations with Neurons\n",
    "McCulloch and Pitts proposed a very simple model of the biological neuron, which later became known as an artificial neuron: it has one or more binary (on/off) inputs and one binary output. The artificial neuron activates its output when more than a certain number of its inputs are active. In their paper, they showed that even with such a simplified model it is possible to build a network of artificial neurons that computes any logical proposition you want. To see how such a network works, let’s build a few ANNs that perform various logical computations (see `Figure 10-3`), assuming that a neuron is activated when at least two of its inputs are active.\n",
    "\n",
    "<img src=\"images/10_03.png\" style=\"width:500px;\"/>\n",
    "\n",
    "Let’s see what these networks do:\n",
    "+ The first network on the left is the identity function: if neuron A is activated, then neuron C gets activated as well (since it receives two input signals from neuron A); but if neuron A is off, then neuron C is off as well.\n",
    "+ The second network performs a logical `AND`: neuron C is activated only when both neurons A and B are activated (a single input signal is not enough to activate neuron C).\n",
    "+ The third network performs a logical `OR`: neuron C gets activated if either neuron A or neuron B is activated (or both).\n",
    "+ Finally, if we suppose that an input connection can inhibit the neuron’s activity (which is the case with biological neurons), then the fourth network computes a slightly more complex logical proposition: neuron C is activated only if neuron A is active and neuron B is off. If neuron A is active all the time, then you get a logical `NOT`: neuron C is active when neuron B is off, and vice versa.\n",
    "\n",
    "You can imagine how these networks can be combined to compute complex logical expressions (see the exercises at the end of the chapter for an example).\n",
    "\n",
    "### 10.1.3 The Perceptron\n",
    "The Perceptron is one of the simplest `ANN` architectures, invented in 1957 by Frank Rosenblatt. It is based on a slightly different artificial neuron (see `Figure 10-4`) called a `threshold logic unit` (`TLU`), or sometimes a `linear threshold unit` (`LTU`). The inputs and output are numbers (instead of binary on/off values), and each input connection is associated with a weight. The `TLU` computes a weighted sum of its inputs ($z = w_1x_1 + w_2x_2+ \\dots + w_nx_n= \\textbf{x}^{\\top}\\textbf{w}$), then applies a step function to that sum and outputs the result: $h_w(\\textbf{x}) = step(z)$, where $z = \\textbf{x}^{\\top}\\textbf{w}$.\n",
    "\n",
    "<img src=\"images/10_04.png\" style=\"width:500px;\"/>\n",
    "\n",
    "The most common step function used in Perceptrons is the `Heaviside step function` (see `Equation 10-1`). Sometimes the `sign` function is used instead.\n",
    "\n",
    "<img src=\"images/e_10_01.png\" style=\"width:500px;\"/>\n",
    "\n",
    "A single `TLU` can be used for simple linear binary classification. It computes a linear combination of the inputs, and if the result exceeds a threshold, it outputs the positive class. Otherwise it outputs the negative class (just like a `Logistic Regression` or `linear SVM classifier`). You could, for example, use a single `TLU` to classify iris flowers based on petal length and width (also adding an extra bias feature $x_0 = 1$, just like we did in previous chapters). Training a `TLU` in this case means finding the right values for $w_0, w_1, \\text{and} w_2$ (the training algorithm is discussed shortly).\n",
    "\n",
    "A Perceptron is simply composed of a single layer of `TLU`s, 7 with each `TLU` connected to all the inputs. When all the neurons in a layer are connected to every neuron in the previous layer (i.e., its input neurons), the layer is called a `fully connected layer`, or a `dense layer`. The inputs of the Perceptron are fed to special passthrough neurons called input neurons: they output whatever input they are fed. All the input neurons form the input layer. Moreover, an extra bias feature is generally added ($x_0 = 1$): it is typically represented using a special type of neuron called a bias neuron, which outputs 1 all the time. A Perceptron with two inputs and three outputs is represented in `Figure 10-5`. This Perceptron can classify instances simultaneously into three different binary classes, which makes it a multioutput classifier.\n",
    "\n",
    "<img src=\"images/10_05.png\" style=\"width:500px;\"/>\n",
    "\n",
    "Thanks to the magic of linear algebra, `Equation 10-2` makes it possible to efficiently compute the outputs of a layer of artificial neurons for several instances at once.\n",
    "\n",
    "**Equation 10-2. Computing the outputs of a fully connected layer**\n",
    "\n",
    "$h_{W,b}(\\textbf{X}) = \\phi(\\textbf{XW} + b)$\n",
    "\n",
    "In this equation:\n",
    "+ As always, $\\textbf{X}$ represents the matrix of input features. It has one row per instance and one column per feature.\n",
    "+ The weight matrix $\\textbf{W}$ contains all the connection weights except for the ones from the bias neuron. It has one row per input neuron and one column per artificial neuron in the layer.\n",
    "+ The bias vector $\\textbf{b}$ contains all the connection weights between the bias neuron and the artificial neurons. It has one bias term per artificial neuron.\n",
    "+ The function $\\phi$ is called the `activation function`: when the artificial neurons are `TLU`s, it is a `step function` (but we will discuss other `activation functions` shortly).\n",
    "\n",
    "So, how is a Perceptron trained? The Perceptron training algorithm proposed by Rosenblatt was largely inspired by Hebb’s rule. In his 1949 book The Organization of Behavior (Wiley), Donald Hebb suggested that when a biological neuron triggers another neuron often, the connection between these two neurons grows stronger. Siegrid Löwel later summarized Hebb’s idea in the catchy phrase, “Cells that fire together, wire together”; that is, the connection weight between two neurons tends to increase when they fire simultaneously. This rule later became known as Hebb’s rule (or Hebbian learning). Perceptrons are trained using a variant of this rule that takes into account the error made by the network when it makes a prediction; the Perceptron learning rule reinforces connections that help reduce the error. More specifically, the Perceptron is fed one training instance at a time, and for each instance it makes its predictions. For every output neuron that produced a wrong prediction, it reinforces the connection weights from the inputs that would have contributed to the correct prediction. The rule is shown in `Equation 10-3`.\n",
    "\n",
    "**Equation 10-3. Perceptron learning rule (weight update)**\n",
    "\n",
    "$w_{i,j}^{(\\text{next step})} = w_{i,j} + \\eta(y_j − \\hat{y}_j) x_i$\n",
    "\n",
    "In this equation:\n",
    "+ $w_{i,j}$ is the connection weight between the $i^{th}$ input neuron and the $j^{th}$ output neuron.\n",
    "+ $x_i$ is the $i^{th}$ input value of the current training instance.\n",
    "+ $\\hat{y}_j$ is the output of the $j^{th}$ output neuron for the current training instance.\n",
    "+ $y_j$ is the target output of the $j^{th}$ output neuron for the current training instance.\n",
    "+ $\\eta$ is the learning rate.\n",
    "\n",
    "The decision boundary of each output neuron is linear, so Perceptrons are incapable of learning complex patterns (just like `Logistic Regression classifiers`). However, if the training instances are linearly separable, Rosenblatt demonstrated that this algorithm would converge to a solution. This is called the `Perceptron convergence theorem`.\n",
    "\n",
    "`Scikit-Learn` provides a Perceptron class that implements a single-TLU network. It can be used pretty much as you would expect—for example, on the iris dataset (introduced in Chapter 4):\n",
    "\n",
    "```python \n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.datasets import load_iris \n",
    "import numpy as np\n",
    "\n",
    "iris = load_iris() \n",
    "X = iris.data[:, (2, 3)] # petal length, petal width \n",
    "y = (iris.target == 0).astype(np.int) # Iris setosa?\n",
    "\n",
    "per_clf = Perceptron() \n",
    "per_clf.fit(X, y)\n",
    "\n",
    "y_pred = per_clf.predict([[2, 0.5]])\n",
    "```\n",
    "\n",
    "You may have noticed that the Perceptron learning algorithm strongly resembles `Stochastic Gradient Descent`. In fact, `Scikit-Learn`’s Perceptron class is equivalent to using an `SGDClassifier` with the following hyperparameters: `loss=\"perceptron\", learning_rate=\"constant\", eta0=1` (the learning rate), and `penalty=None` (no regularization).\n",
    "\n",
    "Note that contrary to `Logistic Regression classifiers`, Perceptrons do not output a class probability; rather, they make predictions based on a hard threshold. This is one reason to prefer `Logistic Regression` over Perceptrons.\n",
    "\n",
    "In their 1969 monograph Perceptrons, Marvin Minsky and Seymour Papert highlighted a number of serious weaknesses of Perceptrons—in particular, the fact that they are incapable of solving some trivial problems (e.g., the `Exclusive OR` (`XOR`) classification problem; see the left side of `Figure 10-6`). This is true of any other linear classification model (such as `Logistic Regression classifiers`), but researchers had expected much more from Perceptrons, and some were so disappointed that they dropped neural networks altogether in favor of higher-level problems such as logic, problem solving, and search.\n",
    "\n",
    "It turns out that some of the limitations of Perceptrons can be eliminated by stacking multiple Perceptrons. The resulting `ANN` is called a `Multilayer Perceptron` (`MLP`). An `MLP` can solve the `XOR` problem, as you can verify by computing the output of the `MLP` represented on the right side of `Figure 10-6`: with inputs `(0, 0)` or `(1, 1)`, the network outputs 0, and with inputs `(0, 1)` or `(1, 0)` it outputs 1. All connections have a weight equal to 1, except the four connections where the weight is shown. Try verifying that this network indeed solves the `XOR` problem!\n",
    "\n",
    "<img src=\"images/10_06.png\" style=\"width:500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.1.4 The Multilayer Perceptron and Backpropagation\n",
    "An `MLP` is composed of one (passthrough) input layer, one or more layers of `TLU`s, called `hidden layers`, and one final layer of `TLU`s called the `output layer` (see `Figure 10-7`). The layers close to the input layer are usually called the `lower layers`, and the ones close to the outputs are usually called the `upper layers`. Every layer except the output layer includes a bias neuron and is fully connected to the next layer.\n",
    "\n",
    "<img src=\"images/10_07.png\" style=\"width:500px;\"/>\n",
    "\n",
    "> The signal flows only in one direction (from the inputs to the outputs), so this architecture is an example of a `feedforward neural network` (`FNN`).\n",
    "\n",
    "When an `ANN` contains a deep stack of hidden layers, it is called a `deep neural network` (`DNN`). The field of Deep Learning studies `DNN`s, and more generally models containing deep stacks of computations. Even so, many people talk about Deep Learning whenever neural networks are involved (even shallow ones).\n",
    "\n",
    "For many years researchers struggled to find a way to train `MLP`s, without success. But in 1986, David Rumelhart, Geoffrey Hinton, and Ronald Williams published a groundbreaking paper that introduced the backpropagation training algorithm, which is still used today. In short, it is `Gradient Descent` (introduced in `Chapter 4`) using an efficient technique for computing the gradients automatically: in just two passes through the network (one forward, one backward), the backpropagation algorithm is able to compute the gradient of the network’s error with regard to every single model parameter. In other words, it can find out how each connection weight and each bias term should be tweaked in order to reduce the error. Once it has these gradients, it just performs a regular `Gradient Descent` step, and the whole process is repeated until the network converges to the solution.\n",
    "\n",
    "> Automatically computing gradients is called `automatic differentiation`, or `autodiff`. There are various autodiff techniques, with different pros and cons. The one used by backpropagation is called reverse-mode autodiff. It is fast and precise, and is well suited when the function to differentiate has many variables (e.g., connection weights) and few outputs (e.g., one loss). If you want to learn more about autodiff, check out `Appendix D`.\n",
    "\n",
    "Let’s run through this algorithm in a bit more detail:\n",
    "+ It handles one mini-batch at a time (for example, containing 32 instances each), and it goes through the full training set multiple times. Each pass is called an epoch.\n",
    "+ Each mini-batch is passed to the network’s input layer, which sends it to the first hidden layer. The algorithm then computes the output of all the neurons in this layer (for every instance in the mini-batch). The result is passed on to the next layer, its output is computed and passed to the next layer, and so on until we get the output of the last layer, the output layer. This is the forward pass: it is exactly like making predictions, except all intermediate results are preserved since they are needed for the backward pass.\n",
    "+ Next, the algorithm measures the network’s output error (i.e., it uses a loss function that compares the desired output and the actual output of the network, and returns some measure of the error).\n",
    "+ Then it computes how much each output connection contributed to the error. This is done analytically by applying the chain rule (perhaps the most fundamental rule in calculus), which makes this step fast and precise.\n",
    "+ The algorithm then measures how much of these error contributions came from each connection in the layer below, again using the chain rule, working backward until the algorithm reaches the input layer. As explained earlier, this reverse pass efficiently measures the error gradient across all the connection weights in the network by propagating the error gradient backward through the network (hence the name of the algorithm).\n",
    "+ Finally, the algorithm performs a `Gradient Descent` step to tweak all the connection weights in the network, using the error gradients it just computed.\n",
    "\n",
    "This algorithm is so important that it’s worth summarizing it again: for each training instance, the backpropagation algorithm first makes a prediction (`forward pass`) and measures the error, then goes through each layer in reverse to measure the error contribution from each connection (`reverse pass`), and finally tweaks the connection weights to reduce the error (`Gradient Descent step`).\n",
    "\n",
    "> It is important to initialize all the hidden layers’ connection weights randomly, or else training will fail. For example, if you initialize all weights and biases to zero, then all neurons in a given layer will be perfectly identical, and thus backpropagation will affect them in exactly the same way, so they will remain identical. In other words, despite having hundreds of neurons per layer, your model will act as if it had only one neuron per layer: it won’t be too smart. If instead you randomly initialize the weights, you break the symmetry and allow backpropagation to train a diverse team of neurons.\n",
    "\n",
    "In order for this algorithm to work properly, its authors made a key change to the `MLP`’s architecture: they replaced the step function with the logistic (`sigmoid`) function, $\\sigma(z) = \\displaystyle\\frac{1}{(1 + e^{–z})}$. This was essential because the step function contains only flat segments, so there is no gradient to work with (`Gradient Descent` cannot move on a flat surface), while the logistic function has a well-defined nonzero derivative everywhere, allowing `Gradient Descent` to make some progress at every step. In fact, the backpropagation algorithm works well with many other activation functions, not just the logistic function. Here are two other popular choices:\n",
    "+ **The hyperbolic tangent function: $tanh(z) = 2\\sigma(2z) – 1$**\n",
    "\n",
    "    Just like the logistic function, this activation function is S-shaped, continuous, and differentiable, but its output value ranges from –1 to 1 (instead of 0 to 1 in the case of the logistic function). That range tends to make each layer’s output more or less centered around 0 at the beginning of training, which often helps speed up convergence.\n",
    "    \n",
    "+ **The Rectified Linear Unit function: ReLU(z) = max(0, z)**\n",
    "    \n",
    "    The ReLU function is continuous but unfortunately not differentiable at $z = 0$ (the slope changes abruptly, which can make Gradient Descent bounce around), and its derivative is 0 for $z < 0$. In practice, however, it works very well and has the advantage of being fast to compute, so it has become the default. Most importantly, the fact that it does not have a maximum output value helps reduce some issues during `Gradient Descent` (we will come back to this in `Chapter 11`).\n",
    "\n",
    "These popular activation functions and their derivatives are represented in `Figure 10-8`. But wait! Why do we need activation functions in the first place? Well, if you chain several linear transformations, all you get is a linear transformation. For example, if $f(x) = 2x + 3$ and $g(x) = 5x – 1$, then chaining these two linear functions gives you another linear function: $f(g(x)) = 2(5x – 1) + 3 = 10x + 1$. So if you don’t have some nonlinearity between layers, then even a deep stack of layers is equivalent to a single layer, and you can’t solve very complex problems with that. Conversely, a large enough `DNN` with nonlinear activations can theoretically approximate any continuous function.\n",
    "\n",
    "<img src=\"images/10_08.png\" style=\"width:500px;\"/>\n",
    "\n",
    "OK! You know where neural nets came from, what their architecture is, and how to compute their outputs. You’ve also learned about the backpropagation algorithm. But what exactly can you do with them?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.1.5 Regression MLPs\n",
    "First, `MLP`s can be used for regression tasks. If you want to predict a single value (e.g., the price of a house, given many of its features), then you just need a single output neuron: its output is the predicted value. For multivariate regression (i.e., to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
