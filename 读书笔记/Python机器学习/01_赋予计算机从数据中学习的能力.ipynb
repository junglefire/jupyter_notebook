{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01. 赋予计算机从数据中学习的能力\n",
    "\n",
    "## 1.1 构建把数据转换为知识的智能机器\n",
    "机 器学习在二十世纪下半叶演变为人工智能（AI）的一个分支，它涉及从数据 中通过自我学习获得算法以进行预测。机器学习并不需要先在大量的数据中进行人工分析，然后提取规则并建立模型，而是提供了一种更有效的方法来捕获数据中的知识，逐步提高预测模型的性能，以完成数据驱动的决策。\n",
    "\n",
    "## 1.2 三种不同类型的机器学习\n",
    "<img src=\"images/01_01.png\" style=\"width:350px;\"/>\n",
    "\n",
    "### 1.2.1 用有监督学习预测未来\n",
    "有监督学习的主要目标是从有标签的训练数据中学习模型，以便对未知或未来的数据做出预测。“监督”一词指的是已经知道样本所需要的输出信号或标签。\n",
    "\n",
    "<img src=\"images/01_02.png\" style=\"width:450px;\"/>\n",
    "\n",
    "##### 预测标签的分类\n",
    "分类是有监督学习的一个分支，其目的是根据过去的观测结果来预测新样本的分类标签。这些分类标签是离散的无序值。邮件垃圾检测就是典型的`二元分类任务`，机器学习算法学习规则以区分垃圾和非垃圾邮件。\n",
    "\n",
    "但是，数据集的分类并非都是二元的。有监督学习算法经过学习得到的预测模型可以将训练集中出现过的标签分配给尚未标记的新样本。`多元分类任务`的典型例子是识别手写字符。首先，收集包含字母表中所有字母的多个手写示例形成训练集。然后，当用户通过输入设备提供一个新的手写字符时，预测模型能够准确地将其识别为字母表中的正确字母。然而，如果0～9之间的数字不是训练集的一部分，那么机器学习系统将无法正确地识别。\n",
    "\n",
    "##### 预测连续结果的回归\n",
    "分类任务是为样本分配无序的分类标签。第二类有监督学习是对连续结果的预测，也称为`回归分析`。`回归分析`包括一些预测（解释）变量和一个连续的响应变量（结果或目标），试图寻找那些能够预测结果的变量之间的关系。\n",
    "\n",
    "> 1886年，弗朗西斯·高尔顿在其论文《回归平均的遗传身高》中首次提到回归一词。高尔顿描述了一种生物学现象，即种群身高的变化不会随时间的推移而增加。他观察到父母的身高不会遗传给自己的孩子，相反，孩子的身高会回归种群的均值。\n",
    "\n",
    "### 1.2.2 用强化学习解决交互问题\n",
    "强化学习的目标是开发`系统`或`代理`，通过它们与`环境`的交互来提高其预测性能。当前环境状态的信息通常包含所谓的`奖励信号`，可以把强化学习看作是与有监督学习相关的领域。然而强化学习的反馈并非标定过的正确标签或数值，而是奖励函数对行动的度量。`代理`可以与`环境`交互完成强化学习，通过探索性的试错或深思熟虑的规划来最大化这种奖励。\n",
    "\n",
    "强化学习的常见例子是国际象棋。代理根据棋盘的状态或环境来决定一系列的行动，奖励为比赛结果的输赢：\n",
    "\n",
    "<img src=\"images/01_03.png\" style=\"width:250px;\"/>\n",
    "\n",
    "### 1.2.3 用无监督学习发现隐藏结构\n",
    "无监督学习处理的是无标签或结构未知的数据。使用无监督学习技术，可以在没有已知结果变量或奖励函数的指导下，探索数据结构以提取有意义的信息。\n",
    "\n",
    "#### 1.2.3.1 寻找聚类的子集\n",
    "`聚类`是探索性的数据分析技术，可以在事先不了解组员的情况下，将信息分成有意义的组群。为在分析过程中出现的每个群定义一组对象，它们之间都具有一定程度的相似性，但与其他群中对象的差异性更大类。`聚类`是构造信息和从数据中导出有意义关系的一种有用的技术。例如，它允许营销人员根据自己的兴趣发现客户群，以便制订不同的市场营销计划。\n",
    "\n",
    "#### 1.2.3.2 通过降维压缩数据\n",
    "无监督降维是特征预处理中数据去噪的一种常用方法，它也降低了某些算法对预测性能的要求，并在保留大部分相关信息的同时将数据压缩到较小维数的子空间上。\n",
    "\n",
    "降维有时有利于数据的可视化。例如，为了通过二维或三维散点图或直方图实现数据的可视化，可以把高维特征数据集投影到一、二或三维特征空间。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 基本术语与符号\n",
    "下表是描述鸢尾属植物数据集的摘要，这是机器学习领域的典型案例。该数据集包含了对Setosa、Versicolor和Virginica三种不同鸢尾属植物150多朵鸢尾花的测量结果。数据集中每行代表一朵花的`样本数据`，每种花的数据以厘米为单位按列存储，称为`特征数据集`：\n",
    "\n",
    "<img src=\"images/01_04.png\" style=\"width:500px;\"/>\n",
    "\n",
    "为了简单且高效的表示数据集，通常使用线性代数的矩阵和向量符号来表示数据。按照约定将每个`样本`表示为`特征矩阵`$X$的一行，每个`特征`表示为一列。\n",
    "\n",
    "鸢尾属数据集包含150个样本的4种特征，可以用$150×4$矩阵（$X\\in R^{150×4}$）表示：\n",
    "\n",
    "$\\displaystyle \\left[ \\begin{matrix}\n",
    "   x_1^{(1)} & x_2^{(1)} & x_3^{(1)} & x_4^{(1)}  \\\\\n",
    "   x_1^{(2)} & x_2^{(2)} & x_3^{(2)} & x_4^{(2)}  \\\\\n",
    "   \\vdots   & \\vdots & \\vdots  & \\vdots  \\\\\n",
    "   x_1^{(150)} & x_2^{(150)} & x_3^{(150)} & x_4^{(150)}  \n",
    "   \\end{matrix}\\right]$\n",
    "\n",
    "上标$i$指第$i$个训练样本，下标$j$表示训练数据集的维度。\n",
    "\n",
    "用小写和黑斜体字符表示向量（$x\\in R^{nx1}$），用大写和黑斜体字符表示矩阵（X\\in R^{nxm}），分别采用斜体字符$x^{(n)}$或者$x_m^{(n)}$表示向量或者矩阵中的某个元素。\n",
    "\n",
    "例如，$x_1^{(150)}$表示第150个鸢尾花样本的第1个维度，即萼片长度。因此该矩阵中每行代表一朵花的数据，可以写成4维行向量：\n",
    "\n",
    "$\\displaystyle x_{(i)} = [x_1^{(i)}\\quad x_2^{(i)}\\quad x_3^{(i)}\\quad x_4^{(i)}]$\n",
    "\n",
    "每个特征维度是一个150个元素的列向量：\n",
    "\n",
    "$\\displaystyle\\begin{equation} x_j = \\left[\\begin{matrix}\n",
    "    x_j^{(1)} \\\\ x_j^{(2)} \\\\ \\vdots \\\\ x_j^{(150)} \n",
    "\\end{matrix} \\right]\\end{equation}$\n",
    "\n",
    "类似，可以把目标变量（分类标签）存储为150个元素的列向量：\n",
    "\n",
    "$\\displaystyle\\begin{equation} y = \\left[\\begin{matrix}\n",
    "    y^{(1)} \\\\ y^{(2)} \\\\ \\vdots \\\\ y^{(150)} \n",
    "\\end{matrix} \\right]\\end{equation} , \\quad (y \\in \\{Setosa\\quad Versicolor\\quad Virginica\\})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 构建机器学习系统的路线图\n",
    "下图展示了在预测建模中使用机器学习的典型工作流程：\n",
    "\n",
    "<img src=\"images/01_05.png\" style=\"width:500px;\"/>\n",
    "\n",
    "### 1.4.1 预处理——整理数据\n",
    "原始数据很少以能满足学习算法最佳性能所需要的理想形式出现。因此，数据的`预处理`是任何机器学习应用中最关键的步骤之一。例如，很多机器学习算法要求所选择特征的测量结果具有相同的单位，以获得最佳性能，通常通过把特征数据变换为$[0，1]$的取值范围或者均值和单位方差为0的`标准正态分布`来实现。\n",
    "\n",
    "某些选定的特征可能是高度相关的，因此在某种程度上是多余的。在这种情况下，`降维`对于将特征压缩到低维子空间非常有价值。降低特征空间维数的优点是减少存储空间，提高算法运行的速度。在某些情况下，如果数据集包含大量不相关的特征或噪声，即数据集具有较低的信噪比，那么降维也可以提高模型预测的性能。\n",
    "\n",
    "为了确定机器学习算法不仅能在训练集上表现良好，对新数据也有很好的适应性，我们将数据集随机分成`训练集`和`测试集`。用`训练集`来训练和优化机器学习模型，同时把`测试集`保留到最后用以评估最终的模型。\n",
    "\n",
    "### 1.4.2 训练和选择预测模型\n",
    "从戴维·沃尔珀特著名的“天下没有免费的午餐定理”，可以得出的重要结论是学习不是“免费”的。例如，每个分类算法都有其固有的偏差，如果不对任务做任何假设，没有哪个分类模型更优越。在实践中，至少要比较几种不同的算法，以便训练和选择性能最好的模型。但在比较不同模型之前，首先必须确定性能度量的指标。\n",
    "\n",
    "### 1.4.3 评估模型和预测新样本数据\n",
    "\n",
    "在选择了适合训练集的模型之后，可以用测试集来评估它在新数据上的 性能，以评估泛化误差。如果对模型的性能感到满意，那么就可以用它来预 测未来的新数据。需要注意的是前面提到的诸如特征尺度和降维这样的性能 测量参数，仅是从训练集获得的，而相同的参数会被进一步转换成测试集， 以及任何新的数据样本。否则，对测试数据的性能评估可能会过于乐观。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
