{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# 忽略warnings\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore') \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 导入util模块的各种方法\n",
    "# from keras.utils.np_utils import to_categorical\n",
    "# 导入数据集\n",
    "from keras.datasets import imdb\n",
    "# 导入模型、优化器、损失函数等等\n",
    "from keras import regularizers\n",
    "from keras import optimizers\n",
    "from keras import metrics\n",
    "from keras import models\n",
    "from keras import losses\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04. 机器学习基础\n",
    "学完第3章的三个实例，你应该已经知道如何用神经网络解决分类问题和回归问题，而且也看到了机器学习的核心难题：**过拟合**。本章会将你对这些问题的直觉固化为解决深度学习问题的可靠的概念框架。我们将把所有这些概念——**模型评估**、**数据预处理**、**特征工程**、**解决过拟合**——整合为详细的七步工作流程，用来解决任何机器学习任务。\n",
    "\n",
    "## 4.1 机器学习的四个分支\n",
    "机器学习算法大致可分为四大类，我们将在接下来的四小节中依次介绍。\n",
    "\n",
    "### 4.1.1 监督学习\n",
    "监督学习是目前最常见的机器学习类型。给定一组样本（通常由人工标注），它可以学会将输入数据映射到已知目标［也叫`标注`（annotation）］。本书前面的四个例子都属于监督学习。一般来说，近年来广受关注的深度学习应用几乎都属于监督学习，比如光学字符识别、语音识别、图像分类和语言翻译。\n",
    "\n",
    "虽然监督学习主要包括`分类`和`回归`，但还有更多的奇特变体，主要包括如下几种：\n",
    "+ 序列生成（sequence generation）。给定一张图像，预测描述图像的文字。序列生成有时可以被重新表示为一系列分类问题，比如反复预测序列中的单词或标记\n",
    "+ 语法树预测（syntax tree prediction）。给定一个句子，预测其分解生成的语法树\n",
    "+ 目标检测（object detection）。给定一张图像，在图中特定目标的周围画一个边界框。这个问题也可以表示为分类问题（给定多个候选边界框，对每个框内的目标进行分类）或分类与回归联合问题（用向量回归来预测边界框的坐标）\n",
    "+ 图像分割（image segmentation）。给定一张图像，在特定物体上画一个像素级的掩模（mask）。\n",
    "\n",
    "### 4.1.2 无监督学习\n",
    "无监督学习是指在没有目标的情况下寻找输入数据的有趣变换，其目的在于数据可视化、数据压缩、数据去噪或更好地理解数据中的相关性。无监督学习是数据分析的必备技能，在解决监督学习问题之前，为了更好地了解数据集，它通常是一个必要步骤。`降维`（dimensionality reduction）和`聚类`（clustering）都是众所周知的无监督学习方法。\n",
    "\n",
    "### 4.1.3 自监督学习\n",
    "自监督学习是监督学习的一个特例，它与众不同，值得单独归为一类。自监督学习是没有人工标注的标签的监督学习，你可以将它看作没有人类参与的监督学习。标签仍然存在（因为总要有什么东西来监督学习过程），但它们是从输入数据中生成的，通常是使用启发式算法生成的。\n",
    "\n",
    "举个例子，`自编码器`（autoencoder）是有名的自监督学习的例子，其生成的目标就是未经修改的输入。同样，给定视频中过去的帧来预测下一帧，或者给定文本中前面的词来预测下一个词，都是自监督学习的例子［这两个例子也属于`时序监督学习`（temporally supervised learning），即用未来的输入数据作为监督］。\n",
    "\n",
    "> **注意**\n",
    "> \n",
    "> 监督学习、自监督学习和无监督学习之间的区别有时很模糊，这三个类别更像是没有明确界限的连续体。自监督学习可以被重新解释为监督学习或无监督学习，这取决于你关注的是学习机制还是应用场景。\n",
    "> \n",
    "> 本书的重点在于监督学习，因为它是当前深度学习的主要形式，行业应用非常广泛。后续章节也会简要介绍自监督学习。\n",
    "\n",
    "### 4.1.4 强化学习\n",
    "强化学习一直以来被人们所忽视，但最近随着Google的DeepMind公司将其成功应用于学习下围棋并达到最高水平，机器学习的这一分支开始受到大量关注。\n",
    "\n",
    "在强化学习中，`智能体`（agent）接收有关其环境的信息，并学会选择使某种奖励最大化的行动。例如，神经网络会“观察”视频游戏的屏幕并输出游戏操作，目的是尽可能得高分，这种神经网络可以通过强化学习来训练。\n",
    "\n",
    "目前，强化学习主要集中在研究领域，除游戏外还没有取得实践上的重大成功。但是，我们期待强化学习未来能够实现越来越多的实际应用：自动驾驶汽车、机器人、资源管理、教育等。强化学习的时代已经到来，或即将到来。\n",
    "\n",
    "##### 分类和回归术语表\n",
    "分类和回归都包含很多专业术语，这些术语在机器学习领域都有确切的定义，你应该了解这些定义：\n",
    "+ **样本**（sample）或**输入**（input）：进入模型的数据点\n",
    "+ **预测**（prediction）或**输出**（output）：从模型出来的结果\n",
    "+ **目标**（target）：真实值。对于外部数据源，理想情况下，模型应该能够预测出目标\n",
    "+ **预测误差**（prediction error）或**损失值**（loss value）：模型预测与目标之间的距离\n",
    "+ **类别**（class）：分类问题中供选择的一组标签。例如，对猫狗图像进行分类时，“狗”和“猫”就是两个类别\n",
    "+ **标签**（label）：分类问题中类别标注的具体例子。比如，如果1234号图像被标注为包含类别“狗”，那么“狗”就是 1234 号图像的标签。\n",
    "+ **真值**（ground-truth）或**标注**（annotation）：数据集的所有目标，通常由人工收集\n",
    "+ **二分类**（binary classification）：一种分类任务，每个输入样本都应被划分到两个互斥的类别中\n",
    "+ **多分类**（multiclass classification）：一种分类任务，每个输入样本都应被划分到两个以上的类别中，比如手写数字分类\n",
    "+ **多标签分类**（multilabel classification）：一种分类任务，每个输入样本都可以分配多个标签。举个例子，如果一幅图像里可能既有猫又有狗，那么应该同时标注“猫”标签和“狗”标签。每幅图像的标签个数通常是可变的\n",
    "+ **标量回归**（scalar regression）：目标是连续标量值的任务。预测房价就是一个很好的例子，不同的目标价格形成一个连续的空间\n",
    "+ **向量回归**（vector regression）：目标是一组连续值（比如一个连续向量）的任务。如果对多个值（比如图像边界框的坐标）进行回归，那就是向量回归\n",
    "+ **小批量**（mini-batch）或**批量**（batch）：模型同时处理的一小部分样本（样本数通常为8~128）。样本数通常取2的幂，这样便于GPU上的内存分配。训练时，小批量用来为模型权重计算一次梯度下降更新"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 评估机器学习模型\n",
    "机器学习的目的是得到可以`泛化`（generalize）的模型，即在前所未见的数据上表现很好的模型，而过拟合则是核心难点。你只能控制可以观察的事情，所以能够可靠地衡量模型的泛化能力非常重要。后面几节将介绍降低过拟合以及将泛化能力最大化的方法。本节重点介绍如何衡量泛化能力，即如何评估机器学习模型。\n",
    "\n",
    "### 4.2.1 训练集、验证集和测试集\n",
    "\n",
    "评估模型的重点是将数据划分为三个集合：训练集、验证集和测试集。在训练数据上训练模型，在验证数据上评估模型。一旦找到了最佳参数，就在测试数据上最后测试一次。\n",
    "\n",
    "你可能会问，为什么不是两个集合：一个训练集和一个测试集？在训练集上训练模型，然后在测试集上评估模型。这样简单得多！\n",
    "\n",
    "原因在于开发模型时总是需要调节模型配置，比如选择层数或每层大小［这叫作模型的`超参数`（hyperparameter），以便与`模型参数`（即权重）区分开］。这个调节过程需要使用模型在验证数据上的性能作为反馈信号。这个调节过程本质上就是一种学习：在某个参数空间中寻找良好的模型配置。因此，如果基于模型在验证集上的性能来调节模型配置，会很快导致模型在验证集上过拟合，即使你并没有在验证集上直接训练模型也会如此。\n",
    "\n",
    "最后，你得到的模型在验证集上的性能非常好（人为造成的），因为这正是你优化的目的。你关心的是模型在全新数据上的性能，因此你需要使用一个完全不同的、前所未见的数据集来评估模型，它就是测试集。\n",
    "\n",
    "将数据划分为训练集、验证集和测试集可能看起来很简单，但如果可用数据很少，还有几种高级方法可以派上用场。我们先来介绍三种经典的评估方法：\n",
    "+ 简单的留出验证\n",
    "+ K折验证\n",
    "+ 带有打乱数据的重复 K 折验证\n",
    "\n",
    "##### 简单的留出验证\n",
    "留出一定比例的数据作为测试集。在剩余的数据上训练模型，然后在测试集上评估模型。\n",
    "\n",
    "下面代码给出了其简单实现：\n",
    "```python\n",
    "num_validation_samples = 10000\n",
    "# 通常需要打乱数据\n",
    "np.random.shuffle(data) \n",
    "# 定义验证集\n",
    "validation_data = data[:num_validation_samples]\n",
    "data = data[num_validation_samples:]\n",
    "# 定义训练集\n",
    "training_data = data[:] \n",
    "# 在训练数据上训练模型，并在验证数据上评估模型\n",
    "model = get_model() \n",
    "model.train(training_data)                          \n",
    "validation_score = model.evaluate(validation_data)  \n",
    "# 现在你可以调节模型、重新训练、评估，然后再次调节……\n",
    "# 一旦调节好超参数，通常就在所有非测试数据上从头开始训练最终模型\n",
    "model = get_model()\n",
    "model.train(np.concatenate([training_data, validation_data]))   \n",
    "test_score = model.evaluate(test_data)    \n",
    "```\n",
    "\n",
    "这是最简单的评估方法，但有一个缺点：如果可用的数据很少，那么可能验证集和测试集包含的样本就太少，从而无法在统计学上代表数据。这个问题很容易发现：如果在划分数据前进行不同的随机打乱，最终得到的模型性能差别很大，那么就存在这个问题。接下来会介绍K折验证与重复的K折验证，它们是解决这一问题的两种方法。\n",
    "\n",
    "##### K折验证\n",
    "K折验证将数据划分为大小相同的`K`个分区。对于每个分区`i`，在剩余的`K-1`个分区上训练模型，然后在分区`i`上评估模型。最终分数等于`K`个分数的平均值。与留出验证一样，这种方法也需要独立的验证集进行模型校正。\n",
    "\n",
    "K折交叉验证的简单实现：\n",
    "```python\n",
    "k = 4\n",
    "num_validation_samples = len(data) // k\n",
    "np.random.shuffle(data)\n",
    "validation_scores = []\n",
    "for fold in range(k):\n",
    "    # 选择验证数据分区\n",
    "    validation_data = data[num_validation_samples * fold:num_validation_samples * (fold + 1)]           \n",
    "    # 使用剩余数据作为训练数据。注意，+ 运算符是列表合并，不是求和\n",
    "    training_data = data[:num_validation_samples * fold] + data[num_validation_samples * (fold + 1):]\n",
    "    # 创建一个全新的模型实例（未训练）\n",
    "    model = get_model()\n",
    "    model.train(training_data)\n",
    "    validation_score = model.evaluate(validation_data)\n",
    "    validation_scores.append(validation_score)\n",
    "\n",
    "# 最终验证分数：K 折验证分数的平均值\n",
    "validation_score = np.average(validation_scores) \n",
    "# 在所有非测试数据上训练最终模型　\n",
    "model = get_model() \n",
    "model.train(data)                        \n",
    "test_score = model.evaluate(test_data)   \n",
    "```\n",
    "\n",
    "##### 带有打乱数据的重复K折验证\n",
    "如果可用的数据相对较少，而你又需要尽可能精确地评估模型，那么可以选择`带有打乱数据的重复K折验证`（iterated K-fold validation with shuffling）。具体做法是多次使用K折验证，在每次将数据划分为`K`个分区之前都先将数据打乱。最终分数是每次K折验证分数的平均值。注意，这种方法一共要训练和评估$P \\times K$个模型（P是重复次数），计算代价很大。\n",
    "\n",
    "### 4.2.2 评估模型的注意事项\n",
    "选择模型评估方法时，需要注意以下几点：\n",
    "+ **数据代表性**（data representativeness）：你希望训练集和测试集都能够代表当前数据。例如，你想要对数字图像进行分类，而图像样本是按类别排序的，如果你将前`80%`作为训练集，剩余`20%`作为测试集，那么会导致训练集中只包含类别`0~7`，而测试集中只包含类别`8~9`。这个错误看起来很可笑，却很常见。因此，在将数据划分为训练集和测试集之前，通常应该随机打乱数据\n",
    "+ **时间箭头**（the arrow of time）：如果想要根据过去预测未来（比如明天的天气、股票走势等），那么在划分数据前你不应该随机打乱数据，因为这么做会造成时间泄露，你的模型将在未来数据上得到有效训练。在这种情况下，你应该始终确保测试集中所有数据的时间都晚于训练集数据\n",
    "+ **数据冗余**（redundancy in your data）：如果数据中的某些数据点出现了两次（这在现实中的数据里十分常见），那么打乱数据并划分成训练集和验证集会导致训练集和验证集之间的数据冗余。从效果上来看，你是在部分训练数据上评估模型，这是极其糟糕的！一定要确保训练集和验证集之间没有交集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 数据预处理、特征工程和特征学习\n",
    "许多数据预处理方法和特征工程技术都是和特定领域相关的（比如只和文本数据或图像数据相关），我们将在后续章节的实例中介绍这些内容。现在我们要介绍所有数据领域通用的基本方法。\n",
    "\n",
    "### 4.3.1　神经网络的数据预处理\n",
    "数据预处理的目的是使原始数据更适于用神经网络处理，包括向量化、标准化、处理缺失值和特征提取。\n",
    "\n",
    "##### 1.向量化\n",
    "神经网络的所有输入和目标都必须是浮点数张量（在特定情况下可以是整数张量）。无论处理什么数据（声音、图像还是文本），都必须首先将其转换为张量，这一步叫作`数据向量化`（data vectorization）。例如，在前面两个文本分类的例子中，开始时文本都表示为整数列表（代表单词序列），然后我们用`one-hot`编码将其转换为`float32`格式的张量。在手写数字分类和预测房价的例子中，数据已经是向量形式，所以可以跳过这一步\n",
    "\n",
    "##### 2.值标准化\n",
    "在手写数字分类的例子中，开始时图像数据被编码为`0~255`范围内的整数，表示灰度值。将这一数据输入网络之前，你需要将其转换为`0~1`范围内的浮点数。同样，预测房价时，特征有各种不同的取值范围，有些特征是较小的浮点数，有些特征是相对较大的整数。将这一数据输入网络之前，需要对每个特征做标准化，使其均值为0、标准差为1。\n",
    "\n",
    "一般来说，将取值相对较大的数据（比如多位整数，比网络权重的初始值大很多）或异质数据（比如数据的一个特征在`0~1`范围内，另一个特征在`100~200`范围内）输入到神经网络中是不安全的。这么做可能导致较大的梯度更新，进而导致网络无法收敛。为了让网络的学习变得更容易，输入数据应该具有以下特征：\n",
    "+ 取值较小：大部分值都应该在 0~1 范围内\n",
    "+ 同质性（homogenous）：所有特征的取值都应该在大致相同的范围内\n",
    "\n",
    "此外，下面这种更严格的标准化方法也很常见，而且很有用，虽然不一定总是必需的（例如，对于数字分类问题就不需要这么做）：\n",
    "+ 将每个特征分别标准化，使其平均值为0\n",
    "+ 将每个特征分别标准化，使其标准差为1\n",
    "\n",
    "##### 3.处理缺失值\n",
    "你的数据中有时可能会有缺失值。例如在房价的例子中，第一个特征是人均犯罪率。如果不是所有样本都具有这个特征的话，怎么办？\n",
    "\n",
    "一般来说，对于神经网络，将缺失值设置为`0`是安全的，只要`0`不是一个有意义的值。网络能够从数据中学到`0`意味着缺失数据，并且会忽略这个值。\n",
    "\n",
    "**注意**，如果测试数据中可能有缺失值，而网络是在没有缺失值的数据上训练的，那么网络不可能学会忽略缺失值。在这种情况下，你应该人为生成一些有缺失项的训练样本：多次复制一些训练样本，然后删除测试数据中可能缺失的某些特征。\n",
    "\n",
    "### 4.3.2 特征工程\n",
    "`特征工程`（feature engineering）是指将数据输入模型之前，利用你自己关于数据和机器学习算法（这里指神经网络）的知识对数据进行硬编码的变换（不是模型学到的），以改善模型的效果。多数情况下，一个机器学习模型无法从完全任意的数据中进行学习。呈现给模型的数据应该便于模型进行学习。\n",
    "\n",
    "我们来看一个直观的例子。假设你想开发一个模型，输入一个时钟图像，模型能够输出对应的时间：\n",
    "\n",
    "<img src=\"images/04_03.png\" style=\"width:400px;\"/>\n",
    "\n",
    "如果你选择用图像的原始像素作为输入数据，那么这个机器学习问题将非常困难。你需要用卷积神经网络来解决这个问题，而且还需要花费大量的计算资源来训练网络。\n",
    "\n",
    "但如果你从更高的层次理解了这个问题（你知道人们怎么看时钟上的时间），那么可以为机器学习算法找到更好的输入特征，比如找到时钟指针对应的黑色像素并输出每个指针尖的$(x, y)$坐标，然后，一个简单的机器学习算法就可以学会这些坐标与时间的对应关系。\n",
    "\n",
    "你还可以进一步思考：进行坐标变换，将$(x, y)$坐标转换为相对于图像中心的极坐标。这样输入就变成了每个时钟指针的角度$\\theta$。现在的特征使问题变得非常简单，根本不需要机器学习，因为简单的舍入运算和字典查找就足以给出大致的时间。\n",
    "\n",
    "**这就是特征工程的本质：用更简单的方式表述问题，从而使问题变得更容易。它通常需要深入理解问题。**\n",
    "\n",
    "**深度学习出现之前，特征工程曾经非常重要，因为经典的浅层算法没有足够大的假设空间来自己学习有用的表示。将数据呈现给算法的方式对解决问题至关重要**。\n",
    "\n",
    "例如，卷积神经网络在MNIST数字分类问题上取得成功之前，其解决方法通常是基于硬编码的特征，比如数字图像中的圆圈个数、图像中每个数字的高度、像素值的直方图等。对于现代深度学习，大部分特征工程都是不需要的，因为神经网络能够从原始数据中自动提取有用的特征。\n",
    "\n",
    "这是否意味着，只要使用深度神经网络，就无须担心特征工程呢？并不是这样，原因有两点：\n",
    "+ 良好的特征仍然可以让你用更少的资源更优雅地解决问题。例如，使用卷积神经网络来读取钟面上的时间是非常可笑的\n",
    "+ 良好的特征可以让你用更少的数据解决问题。深度学习模型自主学习特征的能力依赖于大量的训练数据。如果只有很少的样本，那么特征的信息价值就变得非常重要"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 过拟合与欠拟合\n",
    "过拟合存在于所有机器学习问题中。学会如何处理过拟合对掌握机器学习至关重要。\n",
    "\n",
    "机器学习的根本问题是`优化`和`泛化`之间的对立：\n",
    "+ 优化（optimization）是指调节模型以在训练数据上得到最佳性能（即机器学习中的学习）\n",
    "+ 泛化（generalization）是指训练好的模型在前所未见的数据上的性能好坏\n",
    "\n",
    "机器学习的目的当然是得到良好的`泛化`，但你无法控制`泛化`，只能基于训练数据调节模型。\n",
    "\n",
    "训练开始时，`优化`和`泛化`是相关的：训练数据上的损失越小，测试数据上的损失也越小。这时的模型是`欠拟合`（underfit）的。但在训练数据上迭代一定次数之后，`泛化`不再提高，验证指标先是不变，然后开始变差，即模型开始`过拟合`。这时模型开始学习仅和训练数据有关的模式，但这种模式对新数据来说是错误的或无关紧要的。\n",
    "\n",
    "为了防止模型从训练数据中学到错误或无关紧要的模式，最优解决方法是获取更多的训练数据。模型的训练数据越多，泛化能力自然也越好。如果无法获取更多数据，次优解决方法是调节模型允许存储的信息量，或对模型允许存储的信息加以约束。如果一个网络只能记住几个模式，那么优化过程会迫使模型集中学习最重要的模式，这样更可能得到良好的泛化。\n",
    "\n",
    "这种降低过拟合的方法叫作`正则化`（regularization）。\n",
    "\n",
    "我们先介绍几种最常见的正则化方法，然后将其应用于实践中，以改进`3.4`节的电影分类模型。\n",
    "\n",
    "### 4.4.1 减小网络大小\n",
    "防止过拟合的最简单的方法就是减小模型大小，即减少模型中可学习参数的个数（这由层数和每层的单元个数决定）。在深度学习中，模型中可学习参数的个数通常被称为模型的`容量`（capacity）。直观上来看，参数更多的模型拥有更大的`记忆容量`（memorization capacity），因此能够在训练样本和目标之间轻松地学会完美的字典式映射，这种映射没有任何泛化能力。例如，拥有500000个二进制参数的模型，能够轻松学会`MNIST`训练集中所有数字对应的类别——我们只需让50000个数字每个都对应10个二进制参数。但这种模型对于新数字样本的分类毫无用处。始终牢记：深度学习模型通常都很擅长拟合训练数据，但真正的挑战在于泛化，而不是拟合。\n",
    "\n",
    "与此相反，如果网络的记忆资源有限，则无法轻松学会这种映射。因此，为了让损失最小化，网络必须学会对目标具有很强预测能力的压缩表示，这也正是我们感兴趣的数据表示。同时请记住，你使用的模型应该具有足够多的参数，以防欠拟合，即模型应避免记忆资源不足。在容量过大与容量不足之间要找到一个折中。\n",
    "\n",
    "不幸的是，没有一个魔法公式能够确定最佳层数或每层的最佳大小。你必须评估一系列不同的网络架构，以便为数据找到最佳的模型大小。要找到合适的模型大小，一般的工作流程是开始时选择相对较少的层和参数，然后逐渐增加层的大小或增加新层，直到这种增加对验证损失的影响变得很小。\n",
    "\n",
    "我们在电影评论分类的网络上试一下。首先加载数据集并向量化："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)\n",
    "\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    # Create an all-zero matrix of shape (len(sequences), dimension)\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.  # set specific indices of results[i] to 1s\n",
    "    return results\n",
    "\n",
    "# Our vectorized training data\n",
    "x_train = vectorize_sequences(train_data)\n",
    "# Our vectorized test data\n",
    "x_test = vectorize_sequences(test_data)\n",
    "# Our vectorized labels\n",
    "y_train = np.asarray(train_labels).astype('float32')\n",
    "y_test = np.asarray(test_labels).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "原始模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/alex/3rd/py-venv/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/alex/3rd/py-venv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/20\n",
      "25000/25000 [==============================] - 4s 172us/step - loss: 0.4981 - acc: 0.7974 - val_loss: 0.3720 - val_acc: 0.8803\n",
      "Epoch 2/20\n",
      "25000/25000 [==============================] - 4s 156us/step - loss: 0.2870 - acc: 0.9062 - val_loss: 0.3011 - val_acc: 0.8877\n",
      "Epoch 3/20\n",
      "25000/25000 [==============================] - 4s 152us/step - loss: 0.2110 - acc: 0.9288 - val_loss: 0.3119 - val_acc: 0.8746\n",
      "Epoch 4/20\n",
      "25000/25000 [==============================] - 3s 139us/step - loss: 0.1765 - acc: 0.9380 - val_loss: 0.2909 - val_acc: 0.8850\n",
      "Epoch 5/20\n",
      "25000/25000 [==============================] - 4s 147us/step - loss: 0.1499 - acc: 0.9484 - val_loss: 0.3050 - val_acc: 0.8802\n",
      "Epoch 6/20\n",
      "25000/25000 [==============================] - 4s 142us/step - loss: 0.1300 - acc: 0.9560 - val_loss: 0.3295 - val_acc: 0.8766\n",
      "Epoch 7/20\n",
      "25000/25000 [==============================] - 4s 151us/step - loss: 0.1125 - acc: 0.9626 - val_loss: 0.3694 - val_acc: 0.8706\n",
      "Epoch 8/20\n",
      "25000/25000 [==============================] - 4s 151us/step - loss: 0.0976 - acc: 0.9676 - val_loss: 0.3810 - val_acc: 0.8700\n",
      "Epoch 9/20\n",
      "25000/25000 [==============================] - 4s 150us/step - loss: 0.0839 - acc: 0.9733 - val_loss: 0.4070 - val_acc: 0.8677\n",
      "Epoch 10/20\n",
      "25000/25000 [==============================] - 4s 148us/step - loss: 0.0722 - acc: 0.9771 - val_loss: 0.4330 - val_acc: 0.8644\n",
      "Epoch 11/20\n",
      "25000/25000 [==============================] - 4s 147us/step - loss: 0.0621 - acc: 0.9808 - val_loss: 0.4611 - val_acc: 0.8640\n",
      "Epoch 12/20\n",
      "25000/25000 [==============================] - 4s 146us/step - loss: 0.0527 - acc: 0.9852 - val_loss: 0.4915 - val_acc: 0.8616\n",
      "Epoch 13/20\n",
      "25000/25000 [==============================] - 4s 150us/step - loss: 0.0461 - acc: 0.9870 - val_loss: 0.5281 - val_acc: 0.8606\n",
      "Epoch 14/20\n",
      "25000/25000 [==============================] - 4s 145us/step - loss: 0.0392 - acc: 0.9895 - val_loss: 0.5602 - val_acc: 0.8578\n",
      "Epoch 15/20\n",
      "25000/25000 [==============================] - 4s 153us/step - loss: 0.0305 - acc: 0.9931 - val_loss: 0.6041 - val_acc: 0.8532\n",
      "Epoch 16/20\n",
      "25000/25000 [==============================] - 4s 157us/step - loss: 0.0260 - acc: 0.9946 - val_loss: 0.6706 - val_acc: 0.8575\n",
      "Epoch 17/20\n",
      "25000/25000 [==============================] - 4s 154us/step - loss: 0.0218 - acc: 0.9953 - val_loss: 0.6764 - val_acc: 0.8484\n",
      "Epoch 18/20\n",
      "25000/25000 [==============================] - 4s 154us/step - loss: 0.0195 - acc: 0.9956 - val_loss: 0.7001 - val_acc: 0.8566\n",
      "Epoch 19/20\n",
      "25000/25000 [==============================] - 4s 151us/step - loss: 0.0130 - acc: 0.9976 - val_loss: 0.7378 - val_acc: 0.8492\n",
      "Epoch 20/20\n",
      "25000/25000 [==============================] - 4s 151us/step - loss: 0.0144 - acc: 0.9963 - val_loss: 0.7732 - val_acc: 0.8488\n"
     ]
    }
   ],
   "source": [
    "original_model = models.Sequential()\n",
    "original_model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "original_model.add(layers.Dense(16, activation='relu'))\n",
    "original_model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "original_model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "original_hist = original_model.fit(x_train, y_train, epochs=20, batch_size=512, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "更小的模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/20\n",
      "25000/25000 [==============================] - 4s 144us/step - loss: 0.6171 - acc: 0.7754 - val_loss: 0.5472 - val_acc: 0.8444\n",
      "Epoch 2/20\n",
      "25000/25000 [==============================] - 4s 145us/step - loss: 0.4679 - acc: 0.8740 - val_loss: 0.4314 - val_acc: 0.8698\n",
      "Epoch 3/20\n",
      "25000/25000 [==============================] - 3s 137us/step - loss: 0.3593 - acc: 0.8942 - val_loss: 0.3558 - val_acc: 0.8806\n",
      "Epoch 4/20\n",
      "25000/25000 [==============================] - 3s 121us/step - loss: 0.2887 - acc: 0.9084 - val_loss: 0.3220 - val_acc: 0.8796\n",
      "Epoch 5/20\n",
      "25000/25000 [==============================] - 3s 136us/step - loss: 0.2438 - acc: 0.9197 - val_loss: 0.2955 - val_acc: 0.8866\n",
      "Epoch 6/20\n",
      "25000/25000 [==============================] - 3s 137us/step - loss: 0.2135 - acc: 0.9274 - val_loss: 0.2819 - val_acc: 0.8908\n",
      "Epoch 7/20\n",
      "25000/25000 [==============================] - 3s 130us/step - loss: 0.1913 - acc: 0.9341 - val_loss: 0.2790 - val_acc: 0.8884\n",
      "Epoch 8/20\n",
      "25000/25000 [==============================] - 3s 134us/step - loss: 0.1746 - acc: 0.9407 - val_loss: 0.2786 - val_acc: 0.8891\n",
      "Epoch 9/20\n",
      "25000/25000 [==============================] - 3s 135us/step - loss: 0.1610 - acc: 0.9449 - val_loss: 0.2812 - val_acc: 0.8902\n",
      "Epoch 10/20\n",
      "25000/25000 [==============================] - 3s 135us/step - loss: 0.1495 - acc: 0.9492 - val_loss: 0.2873 - val_acc: 0.8876\n",
      "Epoch 11/20\n",
      "25000/25000 [==============================] - 3s 136us/step - loss: 0.1391 - acc: 0.9531 - val_loss: 0.2982 - val_acc: 0.8836\n",
      "Epoch 12/20\n",
      "25000/25000 [==============================] - 3s 131us/step - loss: 0.1299 - acc: 0.9567 - val_loss: 0.3056 - val_acc: 0.8833\n",
      "Epoch 13/20\n",
      "25000/25000 [==============================] - 3s 132us/step - loss: 0.1219 - acc: 0.9600 - val_loss: 0.3184 - val_acc: 0.8800\n",
      "Epoch 14/20\n",
      "25000/25000 [==============================] - 3s 127us/step - loss: 0.1144 - acc: 0.9624 - val_loss: 0.3254 - val_acc: 0.8792\n",
      "Epoch 15/20\n",
      "25000/25000 [==============================] - 4s 141us/step - loss: 0.1081 - acc: 0.9650 - val_loss: 0.3426 - val_acc: 0.8761\n",
      "Epoch 16/20\n",
      "25000/25000 [==============================] - 3s 132us/step - loss: 0.1016 - acc: 0.9683 - val_loss: 0.3509 - val_acc: 0.8752\n",
      "Epoch 17/20\n",
      "25000/25000 [==============================] - 3s 128us/step - loss: 0.0965 - acc: 0.9698 - val_loss: 0.3606 - val_acc: 0.8743\n",
      "Epoch 18/20\n",
      "25000/25000 [==============================] - 3s 138us/step - loss: 0.0905 - acc: 0.9715 - val_loss: 0.3747 - val_acc: 0.8721\n",
      "Epoch 19/20\n",
      "25000/25000 [==============================] - 4s 141us/step - loss: 0.0856 - acc: 0.9733 - val_loss: 0.3914 - val_acc: 0.8704\n",
      "Epoch 20/20\n",
      "25000/25000 [==============================] - 3s 136us/step - loss: 0.0808 - acc: 0.9754 - val_loss: 0.4066 - val_acc: 0.8688\n"
     ]
    }
   ],
   "source": [
    "smaller_model = models.Sequential()\n",
    "smaller_model.add(layers.Dense(4, activation='relu', input_shape=(10000,)))\n",
    "smaller_model.add(layers.Dense(4, activation='relu'))\n",
    "smaller_model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "smaller_model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "smaller_model_hist = smaller_model.fit(x_train, y_train, epochs=20, batch_size=512, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "比较了原始网络与更小网络的验证损失。圆点是更小网络的验证损失值，十字是原始网络的验证损失值，更小的验证损失对应更好的模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = range(1, 21)\n",
    "original_val_loss = original_hist.history['val_loss']\n",
    "smaller_model_val_loss = smaller_model_hist.history['val_loss']\n",
    "\n",
    "# b+ is for \"blue cross\"\n",
    "plt.plot(epochs, original_val_loss, 'b+', label='Original model')\n",
    "# \"bo\" is for \"blue dot\"\n",
    "plt.plot(epochs, smaller_model_val_loss, 'bo', label='Smaller model')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如你所见，更小的网络开始过拟合的时间要晚于参考网络（前者6轮后开始过拟合，而后者4轮后开始），而且开始过拟合之后，它的性能变差的速度也更慢。\n",
    "\n",
    "我们再向这个基准中添加一个容量更大的网络（容量远大于问题所需）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/20\n",
      "25000/25000 [==============================] - 12s 474us/step - loss: 0.4612 - acc: 0.7932 - val_loss: 0.3234 - val_acc: 0.8634\n",
      "Epoch 2/20\n",
      "25000/25000 [==============================] - 11s 439us/step - loss: 0.2202 - acc: 0.9144 - val_loss: 0.2923 - val_acc: 0.8799\n",
      "Epoch 3/20\n",
      "25000/25000 [==============================] - 11s 437us/step - loss: 0.1249 - acc: 0.9539 - val_loss: 0.3318 - val_acc: 0.8810\n",
      "Epoch 4/20\n",
      "25000/25000 [==============================] - 11s 448us/step - loss: 0.0741 - acc: 0.9810 - val_loss: 0.4836 - val_acc: 0.8666\n",
      "Epoch 5/20\n",
      "25000/25000 [==============================] - 11s 445us/step - loss: 0.0845 - acc: 0.9873 - val_loss: 0.4823 - val_acc: 0.8821\n",
      "Epoch 6/20\n",
      "25000/25000 [==============================] - 11s 437us/step - loss: 0.0032 - acc: 0.9995 - val_loss: 4.3444 - val_acc: 0.6264\n",
      "Epoch 7/20\n",
      "25000/25000 [==============================] - 11s 431us/step - loss: 0.0781 - acc: 0.9896 - val_loss: 0.6756 - val_acc: 0.8788\n",
      "Epoch 8/20\n",
      "25000/25000 [==============================] - 11s 448us/step - loss: 2.4663e-04 - acc: 1.0000 - val_loss: 0.8663 - val_acc: 0.8777\n",
      "Epoch 9/20\n",
      "25000/25000 [==============================] - 11s 449us/step - loss: 2.7409e-05 - acc: 1.0000 - val_loss: 1.0918 - val_acc: 0.8766\n",
      "Epoch 10/20\n",
      "25000/25000 [==============================] - 11s 449us/step - loss: 1.9223e-06 - acc: 1.0000 - val_loss: 1.2202 - val_acc: 0.8774\n",
      "Epoch 11/20\n",
      "25000/25000 [==============================] - 11s 448us/step - loss: 2.6255e-07 - acc: 1.0000 - val_loss: 1.4102 - val_acc: 0.8762\n",
      "Epoch 12/20\n",
      "25000/25000 [==============================] - 11s 445us/step - loss: 5.4722e-08 - acc: 1.0000 - val_loss: 1.4932 - val_acc: 0.8762\n",
      "Epoch 13/20\n",
      "25000/25000 [==============================] - 11s 445us/step - loss: 2.2618e-08 - acc: 1.0000 - val_loss: 1.5476 - val_acc: 0.8764\n",
      "Epoch 14/20\n",
      "25000/25000 [==============================] - 11s 454us/step - loss: 1.3959e-08 - acc: 1.0000 - val_loss: 1.5823 - val_acc: 0.8761\n",
      "Epoch 15/20\n",
      "25000/25000 [==============================] - 11s 456us/step - loss: 1.0093e-08 - acc: 1.0000 - val_loss: 1.6084 - val_acc: 0.8760\n",
      "Epoch 16/20\n",
      "25000/25000 [==============================] - 11s 436us/step - loss: 7.9315e-09 - acc: 1.0000 - val_loss: 1.6272 - val_acc: 0.8759\n",
      "Epoch 17/20\n",
      "25000/25000 [==============================] - 11s 457us/step - loss: 6.5442e-09 - acc: 1.0000 - val_loss: 1.6426 - val_acc: 0.8760\n",
      "Epoch 18/20\n",
      "25000/25000 [==============================] - 11s 430us/step - loss: 5.5710e-09 - acc: 1.0000 - val_loss: 1.6583 - val_acc: 0.8758\n",
      "Epoch 19/20\n",
      "25000/25000 [==============================] - 11s 449us/step - loss: 4.8817e-09 - acc: 1.0000 - val_loss: 1.6678 - val_acc: 0.8760\n",
      "Epoch 20/20\n",
      "25000/25000 [==============================] - 11s 450us/step - loss: 4.3249e-09 - acc: 1.0000 - val_loss: 1.6776 - val_acc: 0.8758\n"
     ]
    }
   ],
   "source": [
    "bigger_model = models.Sequential()\n",
    "bigger_model.add(layers.Dense(512, activation='relu', input_shape=(10000,)))\n",
    "bigger_model.add(layers.Dense(512, activation='relu'))\n",
    "bigger_model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "bigger_model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "bigger_model_hist = bigger_model.fit(x_train, y_train, epochs=20, batch_size=512, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "比较更大的网络与参考网络的性能："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bigger_model_val_loss = bigger_model_hist.history['val_loss']\n",
    "plt.plot(epochs, original_val_loss, 'b+', label='Original model')\n",
    "plt.plot(epochs, bigger_model_val_loss, 'bo', label='Bigger model')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "更大的网络只过了一轮就开始过拟合，过拟合也更严重。其验证损失的波动也更大。\n",
    "\n",
    "下图同时给出了这两个网络的训练损失。如你所见，更大网络的训练损失很快就接近于零。网络的容量越大，它拟合训练数据的速度就越快，也更容易过拟合。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "original_train_loss = original_hist.history['loss']\n",
    "bigger_model_train_loss = bigger_model_hist.history['loss']\n",
    "\n",
    "plt.plot(epochs, original_train_loss, 'b+', label='Original model')\n",
    "plt.plot(epochs, bigger_model_train_loss, 'bo', label='Bigger model')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Training loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.2 添加权重正则化\n",
    "你可能知道奥卡姆剃刀原理：如果一件事情有两种解释，那么最可能正确的解释就是最简单的那个，即假设更少的那个。这个原理也适用于神经网络学到的模型：给定一些训练数据和一种网络架构，很多组权重值（即很多模型）都可以解释这些数据。简单模型比复杂模型更不容易过拟合。\n",
    "\n",
    "这里的`简单模型`是指参数值分布的熵更小的模型（或参数更少的模型，比如上一节的例子）。因此，一种常见的降低过拟合的方法就是强制让模型权重只能取较小的值，从而限制模型的复杂度，这使得权重值的分布更加`规则`（regular）。这种方法叫作`权重正则化`（weight regularization），其实现方法是向网络损失函数中添加与较大权重值相关的成本。这个成本有两种形式：\n",
    "+ **L1正则化**：添加的成本与权重系数的绝对值（即权重的L1范数）成正比。\n",
    "+ **L2正则化**：添加的成本与权重系数的平方（权重的L2范数）成正比。神经网络的L2正则化也叫`权重衰减`（weight decay）。不要被不同的名称搞混，权重衰减与L2正则化在数学上是完全相同的\n",
    "\n",
    "在`Keras`中，添加权重正则化的方法是向层传递权重正则化项实例作为关键字参数。下列代码将向电影评论分类网络中添加L2权重正则化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/20\n",
      "25000/25000 [==============================] - 3s 123us/step - loss: 0.5494 - acc: 0.7978 - val_loss: 0.4345 - val_acc: 0.8644\n",
      "Epoch 2/20\n",
      "25000/25000 [==============================] - 3s 117us/step - loss: 0.3569 - acc: 0.9009 - val_loss: 0.3553 - val_acc: 0.8848\n",
      "Epoch 3/20\n",
      "25000/25000 [==============================] - 3s 116us/step - loss: 0.2933 - acc: 0.9156 - val_loss: 0.3340 - val_acc: 0.8881\n",
      "Epoch 4/20\n",
      "25000/25000 [==============================] - 3s 115us/step - loss: 0.2664 - acc: 0.9242 - val_loss: 0.3344 - val_acc: 0.8877\n",
      "Epoch 5/20\n",
      "25000/25000 [==============================] - 3s 116us/step - loss: 0.2495 - acc: 0.9294 - val_loss: 0.3485 - val_acc: 0.8802\n",
      "Epoch 6/20\n",
      "25000/25000 [==============================] - 3s 134us/step - loss: 0.2390 - acc: 0.9340 - val_loss: 0.3591 - val_acc: 0.8774\n",
      "Epoch 7/20\n",
      "25000/25000 [==============================] - 3s 117us/step - loss: 0.2307 - acc: 0.9375 - val_loss: 0.3446 - val_acc: 0.8840\n",
      "Epoch 8/20\n",
      "25000/25000 [==============================] - 3s 110us/step - loss: 0.2254 - acc: 0.9398 - val_loss: 0.3548 - val_acc: 0.8801\n",
      "Epoch 9/20\n",
      "25000/25000 [==============================] - 3s 108us/step - loss: 0.2183 - acc: 0.9436 - val_loss: 0.3650 - val_acc: 0.8773\n",
      "Epoch 10/20\n",
      "25000/25000 [==============================] - 3s 111us/step - loss: 0.2147 - acc: 0.9438 - val_loss: 0.3766 - val_acc: 0.8733\n",
      "Epoch 11/20\n",
      "25000/25000 [==============================] - 3s 108us/step - loss: 0.2121 - acc: 0.9448 - val_loss: 0.3743 - val_acc: 0.8758\n",
      "Epoch 12/20\n",
      "25000/25000 [==============================] - 3s 107us/step - loss: 0.2062 - acc: 0.9467 - val_loss: 0.3768 - val_acc: 0.8756\n",
      "Epoch 13/20\n",
      "25000/25000 [==============================] - 3s 109us/step - loss: 0.2052 - acc: 0.9476 - val_loss: 0.3768 - val_acc: 0.8760\n",
      "Epoch 14/20\n",
      "25000/25000 [==============================] - 3s 108us/step - loss: 0.2014 - acc: 0.9486 - val_loss: 0.3887 - val_acc: 0.8716\n",
      "Epoch 15/20\n",
      "25000/25000 [==============================] - 3s 110us/step - loss: 0.1991 - acc: 0.9504 - val_loss: 0.3875 - val_acc: 0.8738\n",
      "Epoch 16/20\n",
      "25000/25000 [==============================] - 3s 109us/step - loss: 0.1945 - acc: 0.9510 - val_loss: 0.3976 - val_acc: 0.8708\n",
      "Epoch 17/20\n",
      "25000/25000 [==============================] - 3s 109us/step - loss: 0.1955 - acc: 0.9504 - val_loss: 0.4116 - val_acc: 0.8672\n",
      "Epoch 18/20\n",
      "25000/25000 [==============================] - 3s 111us/step - loss: 0.1918 - acc: 0.9523 - val_loss: 0.4100 - val_acc: 0.8674\n",
      "Epoch 19/20\n",
      "25000/25000 [==============================] - 3s 115us/step - loss: 0.1893 - acc: 0.9520 - val_loss: 0.4708 - val_acc: 0.8508\n",
      "Epoch 20/20\n",
      "25000/25000 [==============================] - 3s 108us/step - loss: 0.1886 - acc: 0.9525 - val_loss: 0.4101 - val_acc: 0.8685\n"
     ]
    }
   ],
   "source": [
    "l2_model = models.Sequential()\n",
    "l2_model.add(layers.Dense(16, kernel_regularizer=regularizers.l2(0.001), activation='relu', input_shape=(10000,)))\n",
    "l2_model.add(layers.Dense(16, kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "l2_model.add(layers.Dense(1, activation='sigmoid'))\n",
    "l2_model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "l2_model_hist = l2_model.fit(x_train, y_train, epochs=20, batch_size=512, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`l2(0.001)`的意思是该层权重矩阵的每个系数都会使网络总损失增加`0.001 * weight_coefficient_value`。**注意**，由于这个惩罚项只在训练时添加，所以这个网络的训练损失会比测试损失大很多。\n",
    "\n",
    "下图显示了`L2正则化`惩罚的影响，即使两个模型的参数个数相同，具有`L2正则化`的模型更不容易过拟合。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "l2_model_val_loss = l2_model_hist.history['val_loss']\n",
    "\n",
    "plt.plot(epochs, original_val_loss, 'b+', label='Original model')\n",
    "plt.plot(epochs, l2_model_val_loss, 'bo', label='L2-regularized model')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你还可以用`Keras`中以下这些权重正则化项来代替`L2正则化`：\n",
    "```python\n",
    "# L1正则化\n",
    "regularizers.l1(0.001) \n",
    "# 同时做L1和L2正则化\n",
    "regularizers.l1_l2(l1=0.001, l2=0.001)\n",
    "```\n",
    "\n",
    "### 4.4.3 添加dropout正则化\n",
    "`dropout`是神经网络最有效也最常用的正则化方法之一，它是由多伦多大学的`Geoffrey Hinton`和他的学生开发的。对某一层使用`dropout`，就是在训练过程中随机将该层的一些输出特征舍弃（设置为0）。\n",
    "\n",
    "假设在训练过程中，某一层对给定输入样本的返回值应该是向量`[0.2, 0.5, 1.3, 0.8, 1.1]`。使用`dropout`后，这个向量会有几个随机的元素变成0，比如`[0, 0.5, 1.3, 0, 1.1]`。`dropout比率`是被设为0的特征所占的比例，通常在`0.2~0.5`范围内。测试时没有单元被舍弃，而该层的输出值需要按`dropout`比率缩小，因为这时比训练时有更多的单元被激活，需要加以平衡。\n",
    "\n",
    "假设有一个包含某层输出的`Numpy`矩阵`layer_output`，其形状为`(batch_size, features)`。训练时，我们随机将矩阵中一部分值设为0：\n",
    "```python\n",
    "layer_output *= np.random.randint(0, high=2, size=layer_output.shape)\n",
    "```\n",
    "\n",
    "测试时，我们将输出按`dropout`比率缩小。这里我们乘以`0.5`（因为前面舍弃了一半的单元）：\n",
    "```python\n",
    "layer_output *= 0.5\n",
    "```\n",
    "\n",
    "注意，为了实现这一过程，还可以让两个运算都在训练时进行，而测试时输出保持不变：\n",
    "```python\n",
    "# 训练时\n",
    "layer_output *= np.random.randint(0, high=2, size=layer_output.shape)\n",
    "# 注意，是成比例放大而不是成比例缩小\n",
    "layer_output /= 0.5\n",
    "```\n",
    "\n",
    "这通常也是实践中的实现方式（见`图4-8`）。\n",
    "\n",
    "<img src=\"images/04_08.png\" style=\"width:600px;\"/>\n",
    "\n",
    "这一方法可能看起来有些奇怪和随意。它为什么能够降低过拟合？`Geoffrey Hinton`说他的灵感之一来自于银行的防欺诈机制。用他自己的话来说：“我去银行办理业务。柜员不停地换人，于是我问其中一人这是为什么。他说他不知道，但他们经常换来换去。我猜想，银行工作人员要想成功欺诈银行，他们之间要互相合作才行。这让我意识到，在每个样本中随机删除不同的部分神经元，可以阻止它们的阴谋，因此可以降低过拟合。”\n",
    "\n",
    "其核心思想是在层的输出值中引入噪声，打破不显著的偶然模式。如果没有噪声的话，网络将会记住这些偶然模式。\n",
    "\n",
    "> 参见Reddit网站上的讨论“AMA: We are the Google Brain team. We'd love to answer your questions about machine learning”\n",
    "\n",
    "在`Keras`中，你可以通过`Dropout`层向网络中引入`dropout`，`dropout`将被应用于前面一层的输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/20\n",
      "25000/25000 [==============================] - 1154s 46ms/step - loss: 0.5912 - acc: 0.6847 - val_loss: 0.4401 - val_acc: 0.8557\n",
      "Epoch 2/20\n",
      "25000/25000 [==============================] - 4s 169us/step - loss: 0.4353 - acc: 0.8141 - val_loss: 0.3342 - val_acc: 0.8800\n",
      "Epoch 3/20\n",
      "25000/25000 [==============================] - 4s 151us/step - loss: 0.3474 - acc: 0.8614 - val_loss: 0.2877 - val_acc: 0.8875\n",
      "Epoch 4/20\n",
      "25000/25000 [==============================] - 4s 142us/step - loss: 0.3053 - acc: 0.8846 - val_loss: 0.2753 - val_acc: 0.8904\n",
      "Epoch 5/20\n",
      "25000/25000 [==============================] - 4s 151us/step - loss: 0.2637 - acc: 0.9022 - val_loss: 0.2794 - val_acc: 0.8899\n",
      "Epoch 6/20\n",
      "25000/25000 [==============================] - 4s 142us/step - loss: 0.2350 - acc: 0.9152 - val_loss: 0.2897 - val_acc: 0.8860\n",
      "Epoch 7/20\n",
      "25000/25000 [==============================] - 3s 133us/step - loss: 0.2152 - acc: 0.9231 - val_loss: 0.3030 - val_acc: 0.8866\n",
      "Epoch 8/20\n",
      "25000/25000 [==============================] - 3s 137us/step - loss: 0.1957 - acc: 0.9323 - val_loss: 0.3226 - val_acc: 0.8862\n",
      "Epoch 9/20\n",
      "25000/25000 [==============================] - 3s 136us/step - loss: 0.1761 - acc: 0.9406 - val_loss: 0.3417 - val_acc: 0.8836\n",
      "Epoch 10/20\n",
      "25000/25000 [==============================] - 3s 133us/step - loss: 0.1708 - acc: 0.9419 - val_loss: 0.3643 - val_acc: 0.8836\n",
      "Epoch 11/20\n",
      "25000/25000 [==============================] - 3s 132us/step - loss: 0.1573 - acc: 0.9455 - val_loss: 0.3809 - val_acc: 0.8809\n",
      "Epoch 12/20\n",
      "25000/25000 [==============================] - 3s 132us/step - loss: 0.1434 - acc: 0.9498 - val_loss: 0.4169 - val_acc: 0.8732\n",
      "Epoch 13/20\n",
      "25000/25000 [==============================] - 3s 137us/step - loss: 0.1444 - acc: 0.9510 - val_loss: 0.4318 - val_acc: 0.8804\n",
      "Epoch 14/20\n",
      "25000/25000 [==============================] - 3s 135us/step - loss: 0.1356 - acc: 0.9509 - val_loss: 0.4769 - val_acc: 0.8744\n",
      "Epoch 15/20\n",
      "25000/25000 [==============================] - 4s 144us/step - loss: 0.1335 - acc: 0.9548 - val_loss: 0.4567 - val_acc: 0.8761\n",
      "Epoch 16/20\n",
      "25000/25000 [==============================] - 3s 139us/step - loss: 0.1278 - acc: 0.9548 - val_loss: 0.4865 - val_acc: 0.8758\n",
      "Epoch 17/20\n",
      "25000/25000 [==============================] - 3s 129us/step - loss: 0.1251 - acc: 0.9562 - val_loss: 0.5189 - val_acc: 0.8758\n",
      "Epoch 18/20\n",
      "25000/25000 [==============================] - 3s 130us/step - loss: 0.1245 - acc: 0.9546 - val_loss: 0.5424 - val_acc: 0.8757\n",
      "Epoch 19/20\n",
      "25000/25000 [==============================] - 3s 132us/step - loss: 0.1143 - acc: 0.9586 - val_loss: 0.5755 - val_acc: 0.8756\n",
      "Epoch 20/20\n",
      "25000/25000 [==============================] - 3s 133us/step - loss: 0.1130 - acc: 0.9594 - val_loss: 0.5756 - val_acc: 0.8723\n"
     ]
    }
   ],
   "source": [
    "dpt_model = models.Sequential()\n",
    "dpt_model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "dpt_model.add(layers.Dropout(0.5))\n",
    "dpt_model.add(layers.Dense(16, activation='relu'))\n",
    "dpt_model.add(layers.Dropout(0.5))\n",
    "dpt_model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "dpt_model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "dpt_model_hist = dpt_model.fit(x_train, y_train, epochs=20, batch_size=512, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "比较`dropout`模型和参考网络："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dpt_model_val_loss = dpt_model_hist.history['val_loss']\n",
    "\n",
    "plt.plot(epochs, original_val_loss, 'b+', label='Original model')\n",
    "plt.plot(epochs, dpt_model_val_loss, 'bo', label='Dropout-regularized model')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "总结一下，防止神经网络过拟合的常用方法包括：\n",
    "+ 获取更多的训练数据 \n",
    "+ 减小网络容量\n",
    "+ 添加权重正则化\n",
    "+ 添加dropout\n",
    "\n",
    "\n",
    "## 4.5 机器学习的通用工作流程\n",
    "本节将介绍一种可用于解决任何机器学习问题的通用模板。这一模板将你在本章学到的这些概念串在一起：问题定义、评估、特征工程和解决过拟合。\n",
    "\n",
    "### 4.5.1 定义问题，收集数据集\n",
    "首先，你必须定义所面对的问题：\n",
    "+ 你的输入数据是什么？你要预测什么？只有拥有可用的训练数据，你才能学习预测某件事情。比如，只有同时拥有电影评论和情感标注，你才能学习对电影评论进行情感分类。因此，数据可用性通常是这一阶段的限制因素\n",
    "+ 你面对的是什么类型的问题？是二分类问题、多分类问题、标量回归问题、向量回归问题，还是多分类、多标签问题？或者是其他问题，比如聚类、生成或强化学习？确定问题类型有助于你选择模型架构、损失函数等\n",
    "\n",
    "只有明确了输入、输出以及所使用的数据，你才能进入下一阶段。注意你在这一阶段所做的假设：\n",
    "+ 假设输出是可以根据输入进行预测的\n",
    "+ 假设可用数据包含足够多的信息，足以学习输入和输出之间的关系\n",
    "\n",
    "在开发出工作模型之前，这些只是假设，等待验证真假。并非所有问题都可以解决。你收集了包含输入$X$和目标$Y$的很多样例，并不意味着$X$包含足够多的信息来预测$Y$。例如，如果你想根据某支股票最近的历史价格来预测其股价走势，那你成功的可能性不大，因为历史价格并没有包含很多可用于预测的信息。\n",
    "\n",
    "有一类无法解决的问题你应该知道，那就是`非平稳问题`（nonstationary problem）。假设你想要构建一个服装推荐引擎，并在一个月（八月）的数据上训练，然后在冬天开始生成推荐结果。一个大问题是，人们购买服装的种类是随着季节变化的，即服装购买在几个月的尺度上是一个非平稳现象。你想要建模的对象随着时间推移而改变。在这种情况下，正确的做法是不断地利用最新数据重新训练模型，或者在一个问题是平稳的时间尺度上收集数据。对于服装购买这种周期性问题，几年的数据足以捕捉到季节性变化，但一定要记住，要将一年中的时间作为模型的一个输入。\n",
    "\n",
    "请记住，**机器学习只能用来记忆训练数据中存在的模式**。你只能识别出曾经见过的东西。在过去的数据上训练机器学习来预测未来，这里存在一个假设，就是未来的规律与过去相同。但事实往往并非如此。\n",
    "\n",
    "### 4.5.2 选择衡量成功的指标\n",
    "要控制一件事物，就需要能够观察它。要取得成功，就必须给出成功的定义：精度？准确率（precision）和召回率（recall）？客户保留率？衡量成功的指标将指引你选择损失函数，即模型要优化什么。它应该直接与你的目标（如业务成功）保持一致。\n",
    "\n",
    "对于平衡分类问题（每个类别的可能性相同），`精度`和`接收者操作特征曲线下面积`（area under the receiver operating characteristic curve，ROC AUC）是常用的指标。对于类别不平衡的问题，你可以使用`准确率`和`召回率`。对于排序问题或多标签分类，你可以使用`平均准确率均值`（mean average precision）。自定义衡量成功的指标也很常见。\n",
    "\n",
    "要想了解各种机器学习的成功衡量指标以及这些指标与不同问题域的关系，你可以浏览Kaggle网站上的数据科学竞赛，上面展示了各种各样的问题和评估指标。\n",
    "\n",
    "### 4.5.3 确定评估方法\n",
    "一旦明确了目标，你必须确定如何衡量当前的进展。前面介绍了三种常见的评估方法。\n",
    "+ 留出验证集。数据量很大时可以采用这种方法\n",
    "+ K折交叉验证。如果留出验证的样本量太少，无法保证可靠性，那么应该选择这种方法\n",
    "+ 重复的K折验证。如果可用的数据很少，同时模型评估又需要非常准确，那么应该使用这种方法。\n",
    "\n",
    "只需选择三者之一。大多数情况下，第一种方法足以满足要求。\n",
    "\n",
    "### 4.5.4 准备数据\n",
    "一旦知道了要训练什么、要优化什么以及评估方法，那么你就几乎已经准备好训练模型了。但首先你应该将数据格式化，使其可以输入到机器学习模型中（这里假设模型为深度神经网络）：\n",
    "+ 如前所述，应该将数据格式化为张量\n",
    "+ 这些张量的取值通常应该缩放为较小的值，比如在`[-1, 1]`区间或`[0, 1]`区间\n",
    "+ 如果不同的特征具有不同的取值范围（异质数据），那么应该做数据标准化\n",
    "+ 你可能需要做特征工程，尤其是对于小数据问题\n",
    "\n",
    "准备好输入数据和目标数据的张量后，你就可以开始训练模型了。\n",
    "\n",
    "### 4.5.5 开发比基准更好的模型\n",
    "这一阶段的目标是获得`统计功效`（statistical power），即开发一个小型模型，它能够打败纯随机的基准（dumb baseline）。在`MNIST`数字分类的例子中，任何精度大于0.1的模型都可以说具有统计功效；在`IMDB`的例子中，任何精度大于0.5的模型都可以说具有统计功效。\n",
    "\n",
    "注意，不一定总是能获得统计功效。如果你尝试了多种合理架构之后仍然无法打败随机基准，那么原因可能是问题的答案并不在输入数据中。要记住你所做的两个假设：\n",
    "+ 假设输出是可以根据输入进行预测的\n",
    "+ 假设可用的数据包含足够多的信息，足以学习输入和输出之间的关系\n",
    "\n",
    "这些假设很可能是错误的，这样的话你需要从头重新开始。\n",
    "\n",
    "如果一切顺利，你还需要选择三个关键参数来构建第一个工作模型：\n",
    "+ 最后一层的激活。它对网络输出进行有效的限制。例如，`IMDB`分类的例子在最后一层使用了`sigmoid`，回归的例子在最后一层没有使用激活，等等\n",
    "+ 损失函数。它应该匹配你要解决的问题的类型。例如，`IMDB`的例子使用`binary_crossentropy`、回归的例子使用`mse`，等等\n",
    "+ 优化配置。你要使用哪种优化器？学习率是多少？大多数情况下，使用`rmsprop`及其默认的学习率是稳妥的\n",
    "\n",
    "关于损失函数的选择，需要注意，直接优化衡量问题成功的指标不一定总是可行的。有时难以将指标转化为损失函数，要知道，损失函数需要在只有小批量数据时即可计算（理想情况下，只有一个数据点时，损失函数应该也是可计算的），而且还必须是可微的（否则无法用反向传播来训练网络）。例如，广泛使用的分类指标`ROC AUC`就不能被直接优化。因此在分类任务中，常见的做法是优化`ROC AUC`的替代指标，比如交叉熵。一般来说，你可以认为交叉熵越小，`ROC AUC`越大。\n",
    "\n",
    "`表4-1`列出了常见问题类型的最后一层激活和损失函数，可以帮你进行选择。\n",
    "\n",
    "<img src=\"images/t_04_01.png\" style=\"width:600px;\"/>\n",
    "\n",
    "### 4.5.6 扩大模型规模：开发过拟合的模型\n",
    "一旦得到了具有统计功效的模型，问题就变成了：模型是否足够强大？它是否具有足够多的层和参数来对问题进行建模？例如，只有单个隐藏层且只有两个单元的网络，在`MNIST`问题上具有统计功效，但并不足以很好地解决问题。请记住，机器学习中无处不在的对立是优化和泛化的对立，理想的模型是刚好在欠拟合和过拟合的界线上，在容量不足和容量过大的界线上。为了找到这条界线，你必须穿过它。\n",
    "\n",
    "要搞清楚你需要多大的模型，就必须开发一个过拟合的模型，这很简单：\n",
    "1. 添加更多的层\n",
    "2. 让每一层变得更大\n",
    "3. 训练更多的轮次\n",
    "\n",
    "要始终监控训练损失和验证损失，以及你所关心的指标的训练值和验证值。如果你发现模型在验证数据上的性能开始下降，那么就出现了过拟合。\n",
    "\n",
    "下一阶段将开始正则化和调节模型，以便尽可能地接近理想模型，既不过拟合也不欠拟合。\n",
    "\n",
    "### 4.5.7 模型正则化与调节超参数\n",
    "这一步是最费时间的：你将不断地调节模型、训练、在验证数据上评估（这里不是测试数据）、再次调节模型，然后重复这一过程，直到模型达到最佳性能。你应该尝试以下几项：\n",
    "+ 添加`dropout`\n",
    "+ 尝试不同的架构：增加或减少层数\n",
    "+ 添加L1和/或L2正则化\n",
    "+ 尝试不同的超参数（比如每层的单元个数或优化器的学习率），以找到最佳配置\n",
    "+ 反复做特征工程：添加新特征或删除没有信息量的特征（可选）\n",
    "\n",
    "请注意：每次使用验证过程的反馈来调节模型，都会将有关验证过程的信息泄露到模型中。如果只重复几次，那么无关紧要；但如果系统性地迭代许多次，最终会导致模型对验证过程过拟合（即使模型并没有直接在验证数据上训练）。这会降低验证过程的可靠性。\n",
    "\n",
    "一旦开发出令人满意的模型配置，你就可以在所有可用数据（训练数据 + 验证数据）上训练最终的生产模型，然后在测试集上最后评估一次。如果测试集上的性能比验证集上差很多，那么这可能意味着你的验证流程不可靠，或者你在调节模型参数时在验证数据上出现了过拟合。在这种情况下，你可能需要换用更加可靠的评估方法，比如重复的K折验证。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
