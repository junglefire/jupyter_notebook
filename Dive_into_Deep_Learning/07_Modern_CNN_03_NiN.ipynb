{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "import d2l\n",
    "import os\n",
    "\n",
    "from mxnet import autograd, np, npx, gluon, init\n",
    "from mxnet.gluon import loss as gloss\n",
    "from mxnet.gluon import nn\n",
    "npx.set_np()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  07. Modern Convolutional Neural Networks\n",
    "Now that we understand the basics of wiring together convolutional neural networks, we will take you through a tour of modern deep learning. In this chapter, each section will correspond to a significant neural network architecture that was at some point (or currently) the base model upon which an enormous amount of research and projects were built. Each of these networks was at briefly a dominant architecture and many were at one point winners or runners-up in the famous `ImageNet` competition, which has served as a barometer of progress on supervised learning in computer vision since 2010.\n",
    "\n",
    "These models include \n",
    "+ `AlexNet`: the first large-scale network deployed to beat conventional computer vision methods on a large-scale vision challenge; \n",
    "+ `VGG`: makes use of a number of repeating blocks of elements\n",
    "+ `NiN`: network in network, which convolves whole neural networks patch-wise over inputs\n",
    "+ `GoogLeNet`: makes use of networks with parallel concatenations\n",
    "+ `ResNet`: residual networks, which are the most popular go-to architecture today\n",
    "+ `DenseNet`: densely connected networks, which are expensive to compute but have set some recent benchmarks\n",
    "\n",
    "\n",
    "## 7.3 Network in Network (NiN)\n",
    "`LeNet`, `AlexNet`, and `VGG` all share a common design pattern: extract features exploiting spatial structure via a sequence of convolutions and pooling layers and then post-process the representations via fully-connected layers. The improvements upon `LeNet` by `AlexNet` and `VGG` mainly lie in how these later networks widen and deepen these two modules. Alternatively, one could imagine using fully-connected layers earlier in the process. However, a careless use of dense layers might give up the spatial structure of the representation entirely, `NiN` (`Network in Network`) blocks offer an alternative. They were proposed in (`Lin et al., 2013`) based on a very simple insight---to use an MLP on the channels for each pixel separately.\n",
    "\n",
    "### 7.3.1 NiN Blocks\n",
    "Recall that the inputs and outputs of convolutional layers consist of four-dimensional arrays with axes corresponding to the batch, channel, height, and width. Also recall that the inputs and outputs of fully-connected layers are typically two-dimensional arrays corresponding to the batch, and features. The idea behind `NiN` is to apply a fully-connected layer at each pixel location (for each height and width). If we tie the weights across each spatial location, we could think of this as a $1\\times 1$ convolutional layer (as described in `Section 6.4`) or as a fully-connected layer acting independently on each pixel location. Another way to view this is to think of each element in the spatial dimension (height and width) as equivalent to an example and the channel as equivalent to a feature. `Fig. 7.3.1` illustrates the main structural differences between `NiN` and `AlexNet`, `VGG`, and other networks.\n",
    "\n",
    "<img src=\"images/07_04.png\" style=\"width:700px;\"/>\n",
    "\n",
    "The `NiN` block consists of one convolutional layer followed by two $1\\times 1$ convolutional layers that act as per-pixel fully-connected layers with ReLU activations. The convolution width of the first layer is typically set by the user. The subsequent widths are fixed to $1 \\times 1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nin_block(num_channels, kernel_size, strides, padding):\n",
    "    blk = nn.Sequential()\n",
    "    blk.add(nn.Conv2D(num_channels, kernel_size, strides, padding, activation='relu'),\n",
    "            nn.Conv2D(num_channels, kernel_size=1, activation='relu'),\n",
    "            nn.Conv2D(num_channels, kernel_size=1, activation='relu'))\n",
    "    return blk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3.2 NiN Model\n",
    "The original `NiN` network was proposed shortly after `AlexNet` and clearly draws some inspiration. `NiN` uses convolutional layers with window shapes of $11\\times 11$, $5\\times 5$, and $3\\times 3$, and the corresponding numbers of output channels are the same as in `AlexNet`. Each `NiN` block is followed by a maximum pooling layer with a stride of 2 and a window shape of $3\\times 3$.\n",
    "\n",
    "One significant difference between `NiN` and `AlexNet` is that `NiN` avoids dense connections altogether. Instead, `NiN` uses an `NiN` block with a number of output channels equal to the number of label classes, followed by a `global average pooling layer`, yielding a vector of logits. One advantage of `NiN`'s design is that it significantly reduces the number of required model parameters. However, in practice, this design sometimes requires increased model training time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential()\n",
    "net.add(nin_block(96, kernel_size=11, strides=4, padding=0),\n",
    "        nn.MaxPool2D(pool_size=3, strides=2),\n",
    "        nin_block(256, kernel_size=5, strides=1, padding=2),\n",
    "        nn.MaxPool2D(pool_size=3, strides=2),\n",
    "        nin_block(384, kernel_size=3, strides=1, padding=1),\n",
    "        nn.MaxPool2D(pool_size=3, strides=2),\n",
    "        nn.Dropout(0.5),\n",
    "        # There are 10 label classes\n",
    "        nin_block(10, kernel_size=3, strides=1, padding=1),\n",
    "        # The global average pooling layer automatically sets the window shape\n",
    "        # to the height and width of the input\n",
    "        nn.GlobalAvgPool2D(),\n",
    "        # Transform the four-dimensional output into two-dimensional output\n",
    "        # with a shape of (batch size, 10)\n",
    "        nn.Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a data example to see the output shape of each block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequential1 output shape:\t (1, 96, 54, 54)\n",
      "pool0 output shape:\t (1, 96, 26, 26)\n",
      "sequential2 output shape:\t (1, 256, 26, 26)\n",
      "pool1 output shape:\t (1, 256, 12, 12)\n",
      "sequential3 output shape:\t (1, 384, 12, 12)\n",
      "pool2 output shape:\t (1, 384, 5, 5)\n",
      "dropout0 output shape:\t (1, 384, 5, 5)\n",
      "sequential4 output shape:\t (1, 10, 5, 5)\n",
      "pool3 output shape:\t (1, 10, 1, 1)\n",
      "flatten0 output shape:\t (1, 10)\n"
     ]
    }
   ],
   "source": [
    "X = np.random.uniform(size=(1, 1, 224, 224))\n",
    "net.initialize()\n",
    "for layer in net:\n",
    "    X = layer(X)\n",
    "    print(layer.name, 'output shape:\\t', X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3.3 Data Acquisition and Training\n",
    "As before we use `Fashion-MNIST` to train the model. `NiN`'s training is similar to that for `AlexNet` and `VGG`, but it often uses a larger learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr, num_epochs, batch_size = 0.1, 10, 64\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=224)\n",
    "d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Summary\n",
    "+ `NiN` uses blocks consisting of a convolutional layer and multiple $1\\times 1$ convolutional layer. This can be used within the convolutional stack to allow for more per-pixel nonlinearity.\n",
    "+ `NiN` removes the fully connected layers and replaces them with global average pooling (i.e., summing over all locations) after reducing the number of channels to the desired number of outputs (e.g., 10 for `Fashion-MNIST`).\n",
    "+ Removing the dense layers reduces overfitting. `NiN` has dramatically fewer parameters.\n",
    "+ The NiN design influenced many subsequent convolutional neural networks designs.\n",
    "\n",
    "##### Exercises\n",
    "1. Tune the hyper-parameters to improve the classification accuracy.\n",
    "2. Why are there two $1\\times 1$ convolutional layers in the NiN block? Remove one of them, and then observe and analyze the experimental phenomena.\n",
    "3. Calculate the resource usage for NiN\n",
    "    + What is the number of parameters?\n",
    "    + What is the amount of computation?\n",
    "    + What is the amount of memory needed during training?\n",
    "    + What is the amount of memory needed during inference?\n",
    "4. What are possible problems with reducing the $384 \\times 5 \\times 5$ representation to a $10 \\times 5 \\times 5$ representation in one step?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
