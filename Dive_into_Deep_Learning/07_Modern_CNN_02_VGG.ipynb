{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "import d2l\n",
    "import os\n",
    "\n",
    "from mxnet import autograd, np, npx, gluon, init\n",
    "from mxnet.gluon import loss as gloss\n",
    "from mxnet.gluon import nn\n",
    "npx.set_np()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  07. Modern Convolutional Neural Networks\n",
    "Now that we understand the basics of wiring together convolutional neural networks, we will take you through a tour of modern deep learning. In this chapter, each section will correspond to a significant neural network architecture that was at some point (or currently) the base model upon which an enormous amount of research and projects were built. Each of these networks was at briefly a dominant architecture and many were at one point winners or runners-up in the famous `ImageNet` competition, which has served as a barometer of progress on supervised learning in computer vision since 2010.\n",
    "\n",
    "These models include \n",
    "+ `AlexNet`: the first large-scale network deployed to beat conventional computer vision methods on a large-scale vision challenge; \n",
    "+ `VGG`: makes use of a number of repeating blocks of elements\n",
    "+ `NiN`: network in network, which convolves whole neural networks patch-wise over inputs\n",
    "+ `GoogLeNet`: makes use of networks with parallel concatenations\n",
    "+ `ResNet`: residual networks, which are the most popular go-to architecture today\n",
    "+ `DenseNet`: densely connected networks, which are expensive to compute but have set some recent benchmarks\n",
    "\n",
    "\n",
    "## 7.2 Networks Using Blocks (VGG)\n",
    "While `AlexNet` proved that deep convolutional neural networks can achieve good results, it did not offer a general template to guide subsequent researchers in designing new networks. In the following sections, we will introduce several heuristic concepts commonly used to design deep networks.\n",
    "\n",
    "Progress in this field mirrors that in chip design where engineers went from placing transistors to logical elements to logic blocks. Similarly, the design of neural network architectures had grown progressively more abstract, with researchers moving from thinking in terms of individual neurons to whole layers, and now to blocks, repeating patterns of layers.\n",
    "\n",
    "The idea of using blocks first emerged from the `Visual Geometry Group` (`VGG`) at `Oxford University`, in their eponymously-named `VGG` network. It is easy to implement these repeated structures in code with any modern deep learning framework by using loops and subroutines.\n",
    "\n",
    "### 7.2.1 VGG Blocks\n",
    "The basic building block of classic convolutional networks is a sequence of the following layers:\n",
    "1. a convolutional layer (with padding to maintain the resolution)\n",
    "2. a nonlinearity such as a ReLU\n",
    "3. a pooling layer such as a max pooling layer\n",
    "\n",
    "One `VGG` block consists of a sequence of convolutional layers, followed by a max pooling layer for spatial downsampling. In the original `VGG` paper (`Simonyan & Zisserman, 2014`), the authors employed convolutions with $3\\times3$ kernels and $2 \\times 2$ max pooling with stride of $2$ (halving the resolution after each block). In the code below, we define a function called `vgg_block` to implement one `VGG` block. The function takes two arguments corresponding to the number of convolutional layers `num_convs` and the number of output channels `num_channels`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg_block(num_convs, num_channels):\n",
    "    blk = nn.Sequential()\n",
    "    for _ in range(num_convs):\n",
    "        blk.add(nn.Conv2D(num_channels, kernel_size=3, padding=1, activation='relu'))\n",
    "    blk.add(nn.MaxPool2D(pool_size=2, strides=2))\n",
    "    return blk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.2 VGG Network\n",
    "Like `AlexNet` and `LeNet`, the `VGG` Network can be partitioned into two parts: \n",
    "+ the first consisting mostly of convolutional and pooling layers \n",
    "+ a second consisting of fully-connected layers\n",
    "\n",
    "The convolutional portion of the net connects several `vgg_block` modules in succession. In `Fig. 7.2.1`, the variable `conv_arch` consists of a list of tuples (one per block), where each contains two values: the number of convolutional layers and the number of output channels, which are precisely the arguments requires to call the `vgg_block` function. The fully-connected module is identical to that covered in `AlexNet`.\n",
    "\n",
    "<img src=\"images/07_03.png\" style=\"width:500px;\"/>\n",
    "\n",
    "The original `VGG` network had 5 convolutional blocks, among which the first two have one convolutional layer each and the latter three contain two convolutional layers each. The first block has 64 output channels and each subsequent block doubles the number of output channels, until that number reaches $512$. Since this network uses $8$ convolutional layers and $3$ fully-connected layers, it is often called `VGG-11`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_arch = ((1, 64), (1, 128), (2, 256), (2, 512), (2, 512))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code implements `VGG-11`. This is a simple matter of executing a for loop over `conv_arch`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg(conv_arch):\n",
    "    net = nn.Sequential()\n",
    "    # The convolutional layer part\n",
    "    for (num_convs, num_channels) in conv_arch:\n",
    "        net.add(vgg_block(num_convs, num_channels))\n",
    "    # The fully connected layer part\n",
    "    net.add(nn.Dense(4096, activation='relu'), nn.Dropout(0.5),\n",
    "            nn.Dense(4096, activation='relu'), nn.Dropout(0.5),\n",
    "            nn.Dense(10))\n",
    "    return net\n",
    "\n",
    "net = vgg(conv_arch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will construct a single-channel data example with a height and width of 224 to observe the output shape of each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequential1 output shape:\t (1, 64, 112, 112)\n",
      "sequential2 output shape:\t (1, 128, 56, 56)\n",
      "sequential3 output shape:\t (1, 256, 28, 28)\n",
      "sequential4 output shape:\t (1, 512, 14, 14)\n",
      "sequential5 output shape:\t (1, 512, 7, 7)\n",
      "dense0 output shape:\t (1, 4096)\n",
      "dropout0 output shape:\t (1, 4096)\n",
      "dense1 output shape:\t (1, 4096)\n",
      "dropout1 output shape:\t (1, 4096)\n",
      "dense2 output shape:\t (1, 10)\n"
     ]
    }
   ],
   "source": [
    "net.initialize()\n",
    "X = np.random.uniform(size=(1, 1, 224, 224))\n",
    "for blk in net:\n",
    "    X = blk(X)\n",
    "    print(blk.name, 'output shape:\\t', X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we halve height and width at each block, finally reaching a height and width of 7 before flattening the representations for processing by the fully-connected layer.\n",
    "\n",
    "### 7.2.3 Model Training\n",
    "Since `VGG-11` is more computationally-heavy than `AlexNet` we construct a network with a smaller number of channels. This is more than sufficient for training on `Fashion-MNIST`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = 4\n",
    "small_conv_arch = [(pair[0], pair[1] // ratio) for pair in conv_arch]\n",
    "net = vgg(small_conv_arch)\n",
    "# net.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequential19 output shape:\t (1, 16, 112, 112)\n",
      "sequential20 output shape:\t (1, 32, 56, 56)\n",
      "sequential21 output shape:\t (1, 64, 28, 28)\n",
      "sequential22 output shape:\t (1, 128, 14, 14)\n",
      "sequential23 output shape:\t (1, 128, 7, 7)\n",
      "dense9 output shape:\t (1, 4096)\n",
      "dropout6 output shape:\t (1, 4096)\n",
      "dense10 output shape:\t (1, 4096)\n",
      "dropout7 output shape:\t (1, 4096)\n",
      "dense11 output shape:\t (1, 10)\n"
     ]
    }
   ],
   "source": [
    "net.initialize()\n",
    "X = np.random.uniform(size=(1, 1, 224, 224))\n",
    "for blk in net:\n",
    "    X = blk(X)\n",
    "    print(blk.name, 'output shape:\\t', X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apart from using a slightly larger learning rate, the model training process is similar to that of `AlexNet` in the last section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr, num_epochs, batch_size = 0.05, 10, 128,\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=224)\n",
    "d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Summary\n",
    "+ `VGG-11` constructs a network using reusable convolutional blocks. Different `VGG` models can be defined by the differences in the number of convolutional layers and output channels in each block.\n",
    "+ The use of blocks leads to very compact representations of the network definition. It allows for efficient design of complex networks.\n",
    "+ In their work Simonyan and Ziserman experimented with various architectures. In particular, they found that several layers of deep and narrow convolutions (i.e., $3 \\times 3$) were more effective than fewer layers of wider convolutions.\n",
    "\n",
    "##### Exercises\n",
    "1. When printing out the dimensions of the layers we only saw 8 results rather than 11. Where did the remaining 3 layer informations go?\n",
    "2. Compared with `AlexNet`, `VGG` is much slower in terms of computation, and it also needs more GPU memory. Try to analyze the reasons for this.\n",
    "3. Try to change the height and width of the images in Fashion-MNIST from 224 to 96. What influence does this have on the experiments?\n",
    "4. Refer to Table 1 in (`Simonyan & Zisserman, 2014`) to construct other common models, such as `VGG-16` or `VGG-19`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
