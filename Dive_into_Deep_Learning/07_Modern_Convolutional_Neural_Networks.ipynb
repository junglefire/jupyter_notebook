{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "import d2l\n",
    "import os\n",
    "\n",
    "from mxnet import autograd, np, npx, gluon, init\n",
    "from mxnet.gluon import loss as gloss\n",
    "from mxnet.gluon import nn\n",
    "npx.set_np()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  07. Modern Convolutional Neural Networks\n",
    "Now that we understand the basics of wiring together convolutional neural networks, we will take you through a tour of modern deep learning. In this chapter, each section will correspond to a significant neural network architecture that was at some point (or currently) the base model upon which an enormous amount of research and projects were built. Each of these networks was at briefly a dominant architecture and many were at one point winners or runners-up in the famous `ImageNet` competition, which has served as a barometer of progress on supervised learning in computer vision since 2010.\n",
    "\n",
    "These models include \n",
    "+ `AlexNet`: the first large-scale network deployed to beat conventional computer vision methods on a large-scale vision challenge; \n",
    "+ `VGG`: makes use of a number of repeating blocks of elements\n",
    "+ `NiN`: network in network, which convolves whole neural networks patch-wise over inputs\n",
    "+ `GoogLeNet`: makes use of networks with parallel concatenations\n",
    "+ `ResNet`: residual networks, which are the most popular go-to architecture today\n",
    "+ `DenseNet`: densely connected networks, which are expensive to compute but have set some recent benchmarks\n",
    "\n",
    "\n",
    "## 7.1 Deep Convolutional Neural Networks (AlexNet)\n",
    "Although convolutional neural networks were well known in the computer vision and machine learning communities following the introduction of `LeNet`, they did not immediately dominate the field. Although `LeNet` achieved good results on early small datasets, the performance and feasibility of training convolutional networks on larger, more realistic datasets had yet to be established. In fact, for much of the intervening time between the early 1990s and the watershed results of 2012, neural networks were often surpassed by other machine learning methods, such as `support vector machines`.\n",
    "\n",
    "For computer vision, this comparison is perhaps not fair. That is although the inputs to convolutional networks consist of raw or lightly-processed (e.g., by centering) pixel values, practitioners would never feed raw pixels into traditional models. Instead, typical computer vision pipelines consisted of manually engineering feature extraction pipelines. Rather than learn the features, the features were crafted. Most of the progress came from having more clever ideas for features, and the learning algorithm was often relegated to an afterthought.\n",
    "\n",
    "Although some neural network accelerators were available in the 1990s, they were not yet sufficiently powerful to make deep multichannel, multilayer convolutional neural networks with a large number of parameters. Moreover, datasets were still relatively small. Added to these obstacles, key tricks for training neural networks including parameter initialization heuristics, clever variants of stochastic gradient descent, non-squashing activation functions, and effective regularization techniques were still missing.\n",
    "\n",
    "Thus, rather than training `end-to-end` (pixel to classification) systems, classical pipelines looked more like this:\n",
    "1. Obtain an interesting dataset. In early days, these datasets required expensive sensors (at the time, 1 megapixel images were state of the art).\n",
    "2. Preprocess the dataset with hand-crafted features based on some knowledge of optics, geometry, other analytic tools, and occasionally on the serendipitous discoveries of lucky graduate students.\n",
    "3. Feed the data through a standard set of feature extractors such as SIFT, the Scale-Invariant Feature Transform, or SURF, the Speeded-Up Robust Features, or any number of other hand-tuned pipelines.\n",
    "4. Dump the resulting representations into your favorite classifier, likely a linear model or kernel method, to train a classifier.\n",
    "\n",
    "If you spoke to machine learning researchers, they believed that machine learning was both important and beautiful. Elegant theories proved the properties of various classifiers. The field of machine learning was thriving, rigorous and eminently useful. However, if you spoke to a computer vision researcher, you’d hear a very different story. The dirty truth of image recognition, they’d tell you, is that features, not learning algorithms, drove progress. Computer vision researchers justifiably believed that a slightly bigger or cleaner dataset or a slightly improved feature-extraction pipeline mattered far more to the final accuracy than any learning algorithm.\n",
    "\n",
    "Learning Feature Representation\n",
    "\n",
    "Another way to cast the state of affairs is that the most important part of the pipeline was the representation. And up until 2012 the representation was calculated mechanically. In fact, engineering a new set of feature functions, improving results, and writing up the method was a prominent genre of paper. SIFT, SURF, HOG, Bags of visual words and similar feature extractors ruled the roost.\n",
    "\n",
    "Another group of researchers, including Yann LeCun, Geoff Hinton, Yoshua Bengio, Andrew Ng, Shun-ichi Amari, and Juergen Schmidhuber, had different plans. They believed that features themselves ought to be learned. Moreover, they believed that to be reasonably complex, the features ought to be hierarchically composed with multiple jointly learned layers, each with learnable parameters. In the case of an image, the lowest layers might come to detect edges, colors, and textures. Indeed, :cite:Krizhevsky.Sutskever.Hinton.2012 proposed a new variant of a convolutional neural network which achieved excellent performance in the ImageNet challenge.\n",
    "\n",
    "Interestingly in the lowest layers of the network, the model learned feature extractors that resembled some traditional filters. :numref:fig_filters is reproduced from this paper and describes lower-level image descriptors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
