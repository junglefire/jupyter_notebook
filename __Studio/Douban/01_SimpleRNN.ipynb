{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import jieba as jb\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 数据探索\n",
    "先用100条的小数据集进行探索："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Movie_Name_EN</th>\n",
       "      <th>Movie_Name_CN</th>\n",
       "      <th>Crawl_Date</th>\n",
       "      <th>Number</th>\n",
       "      <th>Username</th>\n",
       "      <th>Date</th>\n",
       "      <th>Star</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Like</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Avengers Age of Ultron</td>\n",
       "      <td>复仇者联盟2</td>\n",
       "      <td>2017-01-22</td>\n",
       "      <td>1</td>\n",
       "      <td>然潘</td>\n",
       "      <td>2015-05-13</td>\n",
       "      <td>3</td>\n",
       "      <td>连奥创都知道整容要去韩国。</td>\n",
       "      <td>2404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Avengers Age of Ultron</td>\n",
       "      <td>复仇者联盟2</td>\n",
       "      <td>2017-01-22</td>\n",
       "      <td>2</td>\n",
       "      <td>更深的白色</td>\n",
       "      <td>2015-04-24</td>\n",
       "      <td>2</td>\n",
       "      <td>非常失望，剧本完全敷衍了事，主线剧情没突破大家可以理解，可所有的人物都缺乏动机，正邪之间、...</td>\n",
       "      <td>1231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Avengers Age of Ultron</td>\n",
       "      <td>复仇者联盟2</td>\n",
       "      <td>2017-01-22</td>\n",
       "      <td>3</td>\n",
       "      <td>有意识的贱民</td>\n",
       "      <td>2015-04-26</td>\n",
       "      <td>2</td>\n",
       "      <td>2015年度最失望作品。以为面面俱到，实则画蛇添足；以为主题深刻，实则老调重弹；以为推陈出...</td>\n",
       "      <td>1052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Avengers Age of Ultron</td>\n",
       "      <td>复仇者联盟2</td>\n",
       "      <td>2017-01-22</td>\n",
       "      <td>4</td>\n",
       "      <td>不老的李大爷耶</td>\n",
       "      <td>2015-04-23</td>\n",
       "      <td>4</td>\n",
       "      <td>《铁人2》中勾引钢铁侠，《妇联1》中勾引鹰眼，《美队2》中勾引美国队长，在《妇联2》中终于...</td>\n",
       "      <td>1045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Avengers Age of Ultron</td>\n",
       "      <td>复仇者联盟2</td>\n",
       "      <td>2017-01-22</td>\n",
       "      <td>5</td>\n",
       "      <td>ZephyrO</td>\n",
       "      <td>2015-04-22</td>\n",
       "      <td>2</td>\n",
       "      <td>虽然从头打到尾，但是真的很无聊啊。</td>\n",
       "      <td>723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID           Movie_Name_EN Movie_Name_CN  Crawl_Date  Number Username  \\\n",
       "0   0  Avengers Age of Ultron        复仇者联盟2  2017-01-22       1       然潘   \n",
       "1   1  Avengers Age of Ultron        复仇者联盟2  2017-01-22       2    更深的白色   \n",
       "2   2  Avengers Age of Ultron        复仇者联盟2  2017-01-22       3   有意识的贱民   \n",
       "3   3  Avengers Age of Ultron        复仇者联盟2  2017-01-22       4  不老的李大爷耶   \n",
       "4   4  Avengers Age of Ultron        复仇者联盟2  2017-01-22       5  ZephyrO   \n",
       "\n",
       "         Date  Star                                            Comment  Like  \n",
       "0  2015-05-13     3                                      连奥创都知道整容要去韩国。  2404  \n",
       "1  2015-04-24     2   非常失望，剧本完全敷衍了事，主线剧情没突破大家可以理解，可所有的人物都缺乏动机，正邪之间、...  1231  \n",
       "2  2015-04-26     2   2015年度最失望作品。以为面面俱到，实则画蛇添足；以为主题深刻，实则老调重弹；以为推陈出...  1052  \n",
       "3  2015-04-23     4   《铁人2》中勾引钢铁侠，《妇联1》中勾引鹰眼，《美队2》中勾引美国队长，在《妇联2》中终于...  1045  \n",
       "4  2015-04-22     2                                  虽然从头打到尾，但是真的很无聊啊。   723  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./dataset/douban_100.csv', encoding='utf-8')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "按星级分成正面评论和负面评论两个部分，同时删除各种符号："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.700 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([list(['奥创', '知道', '整容', '韩国']),\n",
       "       list(['非常', '失望', '剧本', '完全', '敷衍了事', '主线', '剧情', '没', '突破', '理解', '人物', '缺乏', '动机', '正邪', '之间', '妇联', '内部', '没什么', '火花', '团结', '分裂', '团结', '三段式', '老套', '其实', '利用', '积攒', '下来', '形象', '魅力', '搞', '出', '意思', '剧本', '写得', '非常', '肤浅', '平面', '场面', '调度', '混乱', '呆板', '满屏', '铁甲', '审美疲劳', '笑', '点算', '差强人意']),\n",
       "       list(['2015', '年度', '失望', '作品', '面面俱到', '实则', '画蛇添足', '主题深刻', '实则', '老调重弹', '推陈出新', '实则', '俗不可耐', '场面', 'high', '实则', 'high', '劲', '不足', '气', '一集', '趣味', '全无', '这集', '笑', '点', '明显', '刻意', '心虚', '全片', '没有', '片段', '紧张', '激动', '太弱', '奥创'])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def wash(str_original, replace_by_space = True):\n",
    "    # 要清洗删除的字符\n",
    "    ls_delete = ['\\u3000', '\\\\n', ',', '。', ':', '：', '，', '“', '”', \n",
    "                 '（', '）', '《', '》', '！', '!', '、', '(', ')', '·',\n",
    "                '.', '？', '…', '>', '「', '」', '|', '\\\\', '\\/', '←',\n",
    "                '【', '】', '[', ']', '-', '√']\n",
    "    for k in range(len(ls_delete)):\n",
    "        # 用空格替代，相当于标点符号处都固定分词，免得后面分词混淆\n",
    "        if replace_by_space:\n",
    "            str_original = str(str_original).replace(ls_delete[k], ' ')  \n",
    "        else:\n",
    "            str_original = str(str_original).replace(ls_delete[k], '')\n",
    "    return str_original\n",
    "\n",
    "def get_stopwords():\n",
    "    stopwords = [line.strip() for line in open('dataset/stopwords.txt',encoding='UTF-8').readlines()]\n",
    "    return stopwords\n",
    "\n",
    "stopwords = get_stopwords()\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "# 遍历所有评论条目，将正面和负面评论存入对应list中\n",
    "for k in range(len(df['Comment'])): \n",
    "    s = wash(df.loc[k, 'Comment'])\n",
    "    l = [e for e in jb.lcut(s) if (e!=' ' and e not in stopwords)]\n",
    "    x.append(l)\n",
    "    if df.loc[k, 'Star'] < 3: \n",
    "        y.append(0)\n",
    "    else:\n",
    "        y.append(1)\n",
    "       \n",
    "x0 = np.array(x)\n",
    "y0 = np.array(y)\n",
    "x0[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用`Keras`的`Tokenizer`类将文本转换成数字。对于中文来说，每个词需要用空格隔开："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['奥创 知道 整容 韩国',\n",
       " '非常 失望 剧本 完全 敷衍了事 主线 剧情 没 突破 理解 人物 缺乏 动机 正邪 之间 妇联 内部 没什么 火花 团结 分裂 团结 三段式 老套 其实 利用 积攒 下来 形象 魅力 搞 出 意思 剧本 写得 非常 肤浅 平面 场面 调度 混乱 呆板 满屏 铁甲 审美疲劳 笑 点算 差强人意',\n",
       " '2015 年度 失望 作品 面面俱到 实则 画蛇添足 主题深刻 实则 老调重弹 推陈出新 实则 俗不可耐 场面 high 实则 high 劲 不足 气 一集 趣味 全无 这集 笑 点 明显 刻意 心虚 全片 没有 片段 紧张 激动 太弱 奥创',\n",
       " '铁人 中 勾引 钢铁 侠 妇联 中 勾引 鹰眼 美队 中 勾引 美国 队长 妇联 中 终于 绿巨人 表白 黑寡妇 实际行动 告诉 忠贞不二 治疗 不孕 不育 作战 武器 变成 两支 验孕 棒 坚决 相信 快银 没有 死 后面 回来',\n",
       " '从头 打到 尾 真的 无聊']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def join_text_by_tag(sentences, tag=' '):\n",
    "    a = []\n",
    "    for l in sentences:\n",
    "        a.append(tag.join(str(w) for w in l))\n",
    "    return a\n",
    "        \n",
    "x1 = join_text_by_tag(x0)\n",
    "x1[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将文本转换成数字："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 98, 369, 178],\n",
       " [38,\n",
       "  21,\n",
       "  99,\n",
       "  66,\n",
       "  370,\n",
       "  371,\n",
       "  11,\n",
       "  12,\n",
       "  372,\n",
       "  373,\n",
       "  6,\n",
       "  100,\n",
       "  374,\n",
       "  375,\n",
       "  376,\n",
       "  26,\n",
       "  377,\n",
       "  179,\n",
       "  378,\n",
       "  180,\n",
       "  379,\n",
       "  180,\n",
       "  380,\n",
       "  381,\n",
       "  67,\n",
       "  382,\n",
       "  383,\n",
       "  181,\n",
       "  384,\n",
       "  385,\n",
       "  68,\n",
       "  69,\n",
       "  386,\n",
       "  99,\n",
       "  387,\n",
       "  38,\n",
       "  101,\n",
       "  388,\n",
       "  15,\n",
       "  389,\n",
       "  182,\n",
       "  390,\n",
       "  391,\n",
       "  392,\n",
       "  183,\n",
       "  102,\n",
       "  393,\n",
       "  394],\n",
       " [395,\n",
       "  396,\n",
       "  21,\n",
       "  397,\n",
       "  398,\n",
       "  70,\n",
       "  399,\n",
       "  400,\n",
       "  70,\n",
       "  401,\n",
       "  402,\n",
       "  70,\n",
       "  403,\n",
       "  15,\n",
       "  103,\n",
       "  70,\n",
       "  103,\n",
       "  184,\n",
       "  404,\n",
       "  405,\n",
       "  71,\n",
       "  185,\n",
       "  406,\n",
       "  186,\n",
       "  102,\n",
       "  72,\n",
       "  104,\n",
       "  105,\n",
       "  407,\n",
       "  106,\n",
       "  2,\n",
       "  408,\n",
       "  409,\n",
       "  187,\n",
       "  410,\n",
       "  1]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tk = tf.keras.preprocessing.text.Tokenizer(char_level=False)\n",
    "tk.fit_on_texts(x1)\n",
    "# tk.word_counts\n",
    "# tk.word_docs\n",
    "# tk.word_index\n",
    "x2 = tk.texts_to_sequences(x1)\n",
    "x2[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
